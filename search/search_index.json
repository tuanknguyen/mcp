{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to AWS MCP Servers","text":"<p>A suite of specialized MCP servers that help you get the most out of AWS, wherever you use MCP.</p>"},{"location":"#available-mcp-servers","title":"Available MCP Servers","text":""},{"location":"#core-mcp-server","title":"Core MCP Server","text":"<p>The Core MCP Server manages and coordinates other MCP servers in your environment, providing automatic installation, configuration, and management.</p> <p>Features:</p> <ul> <li>Automatic MCP Server Management</li> <li>Planning and guidance to orchestrate MCP Servers</li> <li>UVX Installation Support</li> <li>Centralized Configuration</li> </ul> <p>Learn more about the Core MCP Server</p>"},{"location":"#aws-documentation-mcp-server","title":"AWS Documentation MCP Server","text":"<p>The AWS Documentation MCP Server provides access to AWS documentation and best practices.</p> <p>Features:</p> <ul> <li>Search Documentation using the official AWS search API</li> <li>Get content recommendations for AWS documentation pages</li> <li>Convert documentation to markdown format</li> </ul> <p>Learn more about the AWS Documentation MCP Server</p>"},{"location":"#aws-cdk-mcp-server","title":"AWS CDK MCP Server","text":"<p>The CDK MCP Server provides AWS Cloud Development Kit (CDK) best practices, infrastructure as code patterns, and security compliance with CDK Nag.</p> <p>Features:</p> <ul> <li>CDK Best Practices</li> <li>CDK Nag Integration</li> <li>AWS Solutions Constructs</li> <li>GenAI CDK Constructs</li> </ul> <p>Learn more about the CDK MCP Server</p>"},{"location":"#amazon-nova-canvas-mcp-server","title":"Amazon Nova Canvas MCP Server","text":"<p>The Nova Canvas MCP Server enables AI assistants to generate images using Amazon Nova Canvas.</p> <p>Features:</p> <ul> <li>Text-based image generation</li> <li>Color-guided image generation</li> <li>Workspace integration</li> </ul> <p>Learn more about the Amazon Nova Canvas MCP Server</p>"},{"location":"#amazon-kendra-index-mcp-server","title":"Amazon Kendra Index MCP Server","text":"<p>The Amazon Kendra Index MCP Server enables AI assistants to retrieve additional context from a specified Amazon Kendra index.</p> <p>Features:</p> <ul> <li>Query a specified Kendra index</li> </ul> <p>Learn more about the Amazon Kendra Index MCP Server</p>"},{"location":"#amazon-q-index-mcp-server","title":"Amazon Q index MCP Server","text":"<p>The Amazon Q index MCP Server enables AI assistants to search through enterprise customers' Q index and access relevant content across their data sources using specific authentication and authorization flows.</p> <p>Features:</p> <ul> <li> <p>Authentication Tools -- AuthorizeQIndex: Generates OIDC authorization URLs for Q index authentication -- CreateTokenWithIAM: Creates authentication tokens using authorization codes -- AssumeRoleWithIdentityContext: Assumes IAM roles using identity context from tokens</p> </li> <li> <p>Search Tools -- SearchRelevantContent: Searches and retrieves content from Q Business applications</p> </li> </ul> <p>Learn more about the Amazon Q index MCP Server</p>"},{"location":"#amazon-bedrock-knowledge-base-retrieval-mcp-server","title":"Amazon Bedrock Knowledge Base Retrieval MCP Server","text":"<p>The Bedrock Knowledge Base Retrieval MCP Server enables AI assistants to retrieve information from Amazon Bedrock Knowledge Bases.</p> <p>Features:</p> <ul> <li>Discover knowledge bases and their data sources</li> <li>Query knowledge bases with natural language</li> <li>Filter results by data source</li> <li>Rerank results</li> </ul> <p>Learn more about the Bedrock Knowledge Base Retrieval MCP Server</p>"},{"location":"#aws-pricing-mcp-server","title":"AWS Pricing MCP Server","text":"<p>The AWS Pricing MCP Server enables AI assistants to analyze the cost of AWS services.</p> <p>Features:</p> <ul> <li>Analyze and predict AWS costs before deployment</li> <li>Query cost data with natural language</li> <li>Generate cost reports and insights</li> </ul> <p>Learn more about the AWS Pricing MCP Server</p>"},{"location":"#aws-lambda-tool-mcp-server","title":"AWS Lambda Tool MCP Server","text":"<p>The AWS Lambda Tool MCP Server enables AI assistants to select and run AWS Lambda functions as MCP tools.</p> <p>Features:</p> <ul> <li>Select and run AWS Lambda functions as MCP tools</li> <li>Tool names and descriptions are taken from the AWS Lambda function configuration</li> <li>Filter functions by name, tag, or both</li> <li>Use AWS credentials to invoke the Lambda functions</li> </ul> <p>Learn more about the AWS Lambda Tool MCP Server</p>"},{"location":"#aws-iam-mcp-server","title":"AWS IAM MCP Server","text":"<p>The AWS IAM MCP Server provides comprehensive AWS Identity and Access Management (IAM) operations with security best practices and read-only mode support.</p> <p>Features:</p> <ul> <li>User Management: Create, list, retrieve, and delete IAM users</li> <li>Role Management: Create, list, and manage IAM roles with trust policies</li> <li>Policy Management: List and manage IAM policies (managed and inline)</li> <li>Permission Management: Attach/detach policies to users and roles</li> <li>Access Key Management: Create and delete access keys for users</li> <li>Security Simulation: Test policy permissions before applying them</li> <li>Read-Only Mode: Run server in read-only mode to prevent modifications</li> </ul> <p>Learn more about the AWS IAM MCP Server</p>"},{"location":"#amazon-aurora-dsql-mcp-server","title":"Amazon Aurora DSQL MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Aurora DSQL</p> <p>Features:</p> <ul> <li>Execute read only queries</li> <li>Fetch table schema</li> <li>Write or modify data using SQL, in a transaction</li> </ul> <p>Learn more about the Amazon Aurora DSQL MCP Server</p>"},{"location":"#aws-diagram-mcp-server","title":"AWS Diagram MCP Server","text":"<p>This MCP server that seamlessly creates diagrams using the Python diagrams package DSL. This server allows you to generate AWS diagrams, sequence diagrams, flow diagrams, and class diagrams using Python code.</p> <p>Features:</p> <p>The Diagrams MCP Server provides the following capabilities:</p> <ol> <li>Generate Diagrams: Create professional diagrams using Python code</li> <li>Multiple Diagram Types: Support for AWS architecture, sequence diagrams, flow charts, class diagrams, and more</li> <li>Customization: Customize diagram appearance, layout, and styling</li> <li>Security: Code scanning to ensure secure diagram generation</li> </ol> <p>Learn more about the AWS Diagram MCP Server</p>"},{"location":"#aws-terraform-mcp-server","title":"AWS Terraform MCP Server","text":"<p>The Terraform MCP Server enables AWS best practices, infrastructure as code patterns, and security compliance with Checkov.</p> <p>Features:</p> <p>The Terraform MCP Server provides the following capabilities:</p> <ul> <li>Terraform Best Practices</li> <li>Security-First Development Workflow</li> <li>Checkov Integration</li> <li>AWS and AWSCC Provider Documentation</li> <li>AWS-IA GenAI Modules</li> <li>Terraform Workflow Execution</li> </ul> <p>Learn more about the AWS Terraform MCP Server</p>"},{"location":"#frontend-mcp-server","title":"Frontend MCP Server","text":"<p>The Frontend MCP Server provides specialized tools for prototyping web applications with React and AWS Amplify.</p> <p>Features:</p> <ul> <li>Create a web application using React, Tailwind, and shadcn</li> <li>Customize the application based on functional requirements, deconstructing high-level application goals into features, pages, and components</li> <li>Automatic application naming, branding (customized theme) and thematic image generation (splash images, fav icon) using Nova Canvas MCP</li> <li>Integrated authentication flows with AWS Amplify auth</li> </ul> <p>Learn more about the Frontend MCP Server</p>"},{"location":"#amazon-elasticachememorydb-for-valkey-mcp-server","title":"Amazon ElastiCache/MemoryDB for Valkey MCP Server","text":"<p>The Amazon ElastiCache/MemoryDB Valkey MCP Server provides a natural language interface to interact with Valkey datastores, enabling AI assistants to work with various data structures and perform complex data operations.</p> <p>Features:</p> <ul> <li>Support for multiple data types (Strings, Lists, Sets, Sorted Sets, Hashes, Streams, etc.)</li> <li>Advanced features like cluster support</li> <li>JSON document storage and querying</li> <li>Secure connections with SSL/TLS support</li> <li>Connection pooling for efficient resource management</li> </ul> <p>Learn more about the Amazon ElastiCache for Valkey MCP Server</p>"},{"location":"#amazon-elasticache-for-memcached-mcp-server","title":"Amazon ElastiCache for Memcached MCP Server","text":"<p>A server that provides natural language interface to interact with Amazon ElastiCache  Memcached caches, enabling AI agents to efficiently manage and search cached data.</p> <p>Features:</p> <ul> <li>Natural language interface for cache operations</li> <li>Comprehensive command support (Get, Set, Remove, Touch, CAS, Increment, Decrement)</li> <li>Secure connections with SSL/TLS</li> <li>Connection pooling and efficient resource management</li> </ul> <p>Learn more about the Amazon ElastiCache for Memcached MCP Server</p>"},{"location":"#code-documentation-generation-mcp-server","title":"Code Documentation Generation MCP Server","text":"<p>The Code Documentation Generation MCP Server automatically generates comprehensive documentation for code repositories.</p> <p>Features:</p> <ul> <li>Automated documentation generation based on repository analysis</li> <li>AWS architecture diagram integration</li> <li>Multiple document types (README, API, Backend, Frontend)</li> <li>Interactive documentation creation workflow</li> </ul> <p>Learn more about the Code Documentation Generation MCP Server</p>"},{"location":"#aws-location-service-mcp-server","title":"AWS Location Service MCP Server","text":"<p>A server for accessing AWS Location Service capabilities, focusing on place search, geographical coordinates, and route planning.</p> <p>Features:</p> <ul> <li>Search for places using geocoding</li> <li>Get details for specific places by PlaceId</li> <li>Reverse geocode coordinates to addresses</li> <li>Search for places near a location</li> <li>Search for places that are currently open</li> <li>Calculate routes between locations with turn-by-turn directions</li> <li>Optimize waypoints for efficient routing</li> </ul> <p>Learn more about the AWS Location Service MCP Server</p>"},{"location":"#aws-openapi-mcp-server","title":"AWS OpenAPI MCP Server","text":"<p>The OpenAPI MCP Server dynamically creates Model Context Protocol (MCP) tools and resources from OpenAPI specifications, allowing LLMs to interact with APIs through the Model Context Protocol.</p> <p>Features:</p> <ul> <li>Dynamic Tool Generation: Automatically creates MCP tools from OpenAPI endpoints</li> <li>Intelligent Route Mapping: Maps GET operations with query parameters to TOOLS</li> <li>Dynamic Prompt Generation: Creates helpful prompts based on API structure</li> <li>Transport Options: Supports stdio transport</li> <li>Flexible Configuration via environment variables or command line arguments</li> <li>Authentication Support: Works with multiple authentication methods (Basic, Bearer Token, API Key, Cognito)</li> <li>AWS Best Practices: Implements AWS best practices for caching, resilience, and observability</li> </ul> <p>Learn more about the AWS OpenAPI MCP Server</p>"},{"location":"#aws-cloudformation-mcp-server","title":"AWS CloudFormation MCP Server","text":"<p>A server for managing your AWS resources directly and through cloudformation.</p> <p>Features:</p> <ul> <li>Create/Update/Delete your resources with the resource access tools</li> <li>List/Read your resources with the resource access tools</li> </ul> <p>Learn more about the AWS CloudFormation MCP Server</p>"},{"location":"#git-repo-research-mcp-server","title":"Git Repo Research MCP Server","text":"<p>A server for researching Git repositories using semantic search.</p> <p>Features:</p> <ul> <li>Repository Indexing with FAISS and Amazon Bedrock embeddings</li> <li>Semantic Search within repositories</li> <li>Repository Structure Analysis</li> <li>GitHub Repository Search in AWS organizations</li> <li>File Access with text and binary support</li> </ul> <p>Learn more about the Git Repo Research MCP Server</p>"},{"location":"#amazon-aurora-postgres-mcp-server","title":"Amazon Aurora Postgres MCP Server","text":"<p>A server for Aurora Postgres.</p> <p>Features:</p> <ul> <li>Converting human-readable questions and commands into structured Postgres-compatible SQL queries and executing them against the configured Aurora Postgres database</li> <li>Fetch table columns and comments from Postgres using RDS Data API</li> </ul> <p>Learn more about the Amazon Aurora Postgres MCP Server</p>"},{"location":"#amazon-aurora-mysql-mcp-server","title":"Amazon Aurora MySql MCP Server","text":"<p>A server for Aurora MySql.</p> <p>Features:</p> <ul> <li>Converting human-readable questions and commands into structured MySQL-compatible SQL queries and executing them against the configured Aurora MySQL database.</li> <li>Fetch table schema</li> </ul> <p>Learn more about the Amazon Aurora MySql MCP Server</p>"},{"location":"#amazon-cloudwatch-mcp-server","title":"Amazon CloudWatch MCP Server","text":"<p>This AWS Labs Model Context Protocol (MCP) server for CloudWatch enables your troubleshooting agents to use CloudWatch data to do AI-powered root cause analysis and provide recommendations. It offers comprehensive observability tools that simplify monitoring, reduce context switching, and help teams quickly diagnose and resolve service issues. This server will provide AI agents with seamless access to CloudWatch telemetry data through standardized MCP interfaces, eliminating the need for custom API integrations and reducing context switching during troubleshooting workflows. By consolidating access to all CloudWatch capabilities, we enable powerful cross-service correlations and insights that accelerate incident resolution and improve operational visibility.</p> <p>Features: The CloudWatch MCP Server provides specialized tools to address common operational scenarios including alarm troubleshooting, understand metrics definitions, alarm recommendations and log analysis. Each tool encapsulates one or multiple CloudWatch APIs into task-oriented operations.</p> <ul> <li> <p>Alarm Based Troubleshooting - Identifies active alarms, retrieves related metrics and logs, and analyzes historical alarm patterns to determine root causes of triggered alerts. Provides context-aware recommendations for remediation.</p> </li> <li> <p>Log Analyzer - Analyzes a CloudWatch log group for anomalies, message patterns, and error patterns within a specified time window.</p> </li> <li> <p>Metric Definition Analyzer - Provides comprehensive descriptions of what metrics represent, how they're calculated, recommended statistics to use for metric data retrieval</p> </li> <li> <p>Alarm Recommendations - Suggests recommended alarm configurations for CloudWatch metrics, including thresholds, evaluation periods, and other alarm settings.</p> </li> </ul> <p>Learn more about the Amazon CloudWatch MCP Server</p>"},{"location":"#amazon-cloudwatch-logs-mcp-server-deprecated","title":"Amazon CloudWatch Logs MCP Server (DEPRECATED)","text":"<p>DEPRECATED. Please use the Amazon CloudWatch MCP Server instead.</p> <p>An AWS Labs Model Context Protocol (MCP) server for Amazon Cloudwatch Logs.</p> <p>Features:</p> <ul> <li>Discover log groups and their metadata</li> <li>Execute CloudWatch Log Insights queries against log groups</li> </ul> <p>Use this MCP server to first discover available logs groups, then run queries on them to filter, analyze, aggregate, etc. logs.</p> <p>Learn more about the Amazon CloudWatch Logs MCP Server</p>"},{"location":"#aws-managed-prometheus-mcp-server","title":"AWS Managed Prometheus MCP Server","text":"<p>The Prometheus MCP Server provides a robust interface for interacting with AWS Managed Prometheus.</p> <p>Features:</p> <ul> <li>Execute instant PromQL queries against AWS Managed Prometheus</li> <li>Execute range queries with start time, end time, and step interval</li> <li>List all available metrics in your Prometheus instance</li> <li>Get server configuration information</li> <li>AWS SigV4 authentication for secure access</li> </ul> <p>Learn more about the AWS Managed Prometheus MCP Server</p>"},{"location":"#amazon-cloudwatch-application-signals-mcp-server","title":"Amazon CloudWatch Application Signals MCP Server","text":"<p>The CloudWatch Application Signals MCP Server provides tools for monitoring and analyzing AWS services using AWS Application Signals.</p> <p>Features:</p> <ul> <li>List all services monitored by AWS Application Signals</li> <li>Get detailed information about specific services including configuration, metrics, and log groups</li> <li>View service names, types, and key attributes</li> <li>Access available CloudWatch metrics and dimensions</li> <li>Find associated log groups for debugging</li> </ul> <p>Learn more about the Amazon CloudWatch Application Signals MCP Server</p>"},{"location":"#amazon-dynamodb-mcp-server","title":"Amazon DynamoDB MCP Server","text":"<p>A server for interacting with Amazon DynamoDB</p> <p>Features:</p> <ul> <li>Control Plane operations like table creation, table update, global secondary index, streams, global table management, backup, restore, etc.</li> <li>Data Plane operations like put, get, update, query and scan.</li> </ul> <p>Learn more about the Amazon DynamoDB MCP Server</p>"},{"location":"#amazon-elasticache-mcp-server","title":"Amazon ElastiCache MCP Server","text":"<p>A server for managing and interacting with Amazon ElastiCache resources.</p> <p>Features:</p> <ul> <li>Replication Group Operations (create, delete, modify, describe)</li> <li>Cache Cluster Operations (create, delete, modify, describe)</li> <li>Serverless Cache Operations (create, delete, modify, describe)</li> <li>Jump Host Configuration for secure access</li> <li>Service Updates and Engine Management</li> <li>Comprehensive monitoring and event tracking</li> </ul> <p>Learn more about the Amazon ElastiCache MCP Server</p>"},{"location":"#amazon-documentdb-mcp-server","title":"Amazon DocumentDB MCP Server","text":"<p>The DocumentDB MCP Server enables AI assistants to interact with Amazon DocumentDB databases, providing secure query capabilities and database operations.</p> <p>Features:</p> <ul> <li>Connection management for DocumentDB clusters</li> <li>Query documents with filtering and projection</li> <li>Execute MongoDB aggregation pipelines</li> <li>Optional read-only mode for enhanced security</li> <li>Automatic connection cleanup and resource management</li> </ul> <p>Learn more about the Amazon DocumentDB MCP Server</p>"},{"location":"#amazon-eks-mcp-server","title":"Amazon EKS MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon EKS that enables generative AI models to create and manage Kubernetes clusters on AWS through MCP tools.</p> <p>Features:</p> <ul> <li>EKS Cluster Management: Create and manage EKS clusters with dedicated VPCs, proper networking, and CloudFormation templates for reliable, repeatable deployments</li> <li>Kubernetes Resource Management: Create, read, update, delete, and list Kubernetes resources with support for applying YAML manifests</li> <li>Application Deployment: Generate and deploy Kubernetes manifests with customizable parameters for containerized applications</li> <li>Operational Support: Access pod logs, Kubernetes events, and monitor cluster resources</li> <li>CloudWatch Integration: Retrieve logs and metrics from CloudWatch for comprehensive monitoring</li> <li>Security-First Design: Configurable read-only mode, sensitive data access controls, and IAM integration for proper permissions management</li> </ul> <p>Learn more about the Amazon EKS MCP Server</p>"},{"location":"#synthetic-data-mcp-server","title":"Synthetic Data MCP Server","text":"<p>A server for generating, validating, and managing synthetic data.</p> <ul> <li>Business-Driven Generation: Generate synthetic data instructions based on business descriptions</li> <li>Safe Pandas Code Execution: Run pandas code in a restricted environment with automatic DataFrame detection</li> <li>JSON Lines Validation: Validate and convert JSON Lines data to CSV format</li> <li>Data Validation: Validate data structure, referential integrity, and save as CSV files</li> <li>Referential Integrity Checking: Validate relationships between tables</li> <li>Data Quality Assessment: Identify potential issues in data models (3NF validation)</li> <li>Storage Integration: Load data to various storage targets (S3) with support for multiple formats and configurations</li> </ul> <p>Learn more about the Synthetic Data MCP Server</p>"},{"location":"#amazon-neptune-mcp-server","title":"Amazon Neptune MCP Server","text":"<p>A server for interacting with Amazon Neptune graph database.</p> <ul> <li>Run openCypher/Gremlin queries on a Neptune Database</li> <li>Run openCypher queries on Neptune Analytics</li> <li>Get the schema of the graph</li> </ul> <p>Learn more about the Amazon Neptune MCP Server</p>"},{"location":"#aws-bedrock-data-automation-mcp-server","title":"AWS Bedrock Data Automation MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon Bedrock Data Automation that enables AI assistants to analyze documents, images, videos, and audio files using Amazon Bedrock Data Automation projects.</p> <p>Features:</p> <ul> <li>Project Management: List and get details about Bedrock Data Automation projects</li> <li>Asset Analysis: Extract insights from unstructured content using Bedrock Data Automation</li> <li>Support for Multiple Content Types: Process documents, images, videos, and audio files</li> <li>Integration with Amazon S3: Seamlessly upload and download assets and results</li> </ul> <p>Learn more about the AWS Bedrock Data Automation MCP Server</p>"},{"location":"#amazon-keyspaces-for-apache-cassandra-mcp-server","title":"Amazon Keyspaces (for Apache Cassandra) MCP Server","text":"<p>An Amazon Keyspaces (for Apache Cassandra) MCP server enables AI assistants to interact with Amazon Keyspaces and Apache Cassandra.</p> <p>Features: - Explore keyspaces and tables. - Execute CQL SELECT queries against the configured database. - Get feedback and suggestions for improving query performance. - Use with Amazon Keyspaces, or with Apache Cassandra.</p> <p>Learn more about the Amazon Keysapces MCP Server</p>"},{"location":"#amazon-timestream-for-influxdb-mcp-server","title":"Amazon Timestream for InfluxDB MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon Timestream for InfluxDB that enables AI assistants to help create, list, store, and query time-series data using InfluxDB.</p> <p>** Features ** - Create, update, list, describe, and delete Timestream for InfluxDB database instances - Create, update, list, describe, and delete Timestream for InfluxDB database clusters - Manage DB parameter groups - Tag management for Timestream for InfluxDB resources - Write and query data using InfluxDB's APIs</p> <p>Learn more about the Amazon Timestream for InfluxDB MCP Server</p>"},{"location":"#amazon-data-processing-mcp-server","title":"Amazon Data Processing MCP Server","text":"<p>The AWS DataProcessing MCP server provides AI code assistants with comprehensive data processing tools and real-time pipeline visibility across AWS Glue and Amazon EMR-EC2.</p> <p>Features:</p> <ul> <li>Data Catalog Management: Explore, create, and manage databases, tables, and partitions through natural language requests</li> <li>AWS Glue Integration: Manage AWS Glue Data Catalog operations including databases, tables, connections, and partitions</li> <li>Secure Operations: Configurable read-only mode and sensitive data access controls</li> <li>Comprehensive ETL Support: Streamline ETL job creation with intelligent code generation and best practice recommendations</li> </ul> <p>Learn more about the Amazon Data Processing MCP Server</p>"},{"location":"#amazon-rekognition-mcp-server","title":"Amazon Rekognition MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon Rekognition that enables AI assistants to analyze images using Amazon Rekognition's powerful computer vision capabilities.</p> <p>Features:</p> <ul> <li>Face Collection Management: Create and manage collections of faces</li> <li>Face Recognition: Index and search for faces in images</li> <li>Object and Scene Detection: Identify objects, scenes, and activities in images</li> <li>Content Moderation: Detect unsafe or inappropriate content</li> <li>Celebrity Recognition: Identify celebrities in images</li> <li>Face Comparison: Compare faces between images for similarity</li> <li>Text Detection: Extract text from images</li> </ul> <p>Learn more about the Amazon Rekognition MCP Server</p>"},{"location":"#aws-cost-explorer-mcp-server","title":"AWS Cost Explorer MCP Server","text":"<p>A server for interacting with AWS Cost Explorer to analyze AWS costs and usage data.</p> <p>Features:</p> <ul> <li>Get detailed breakdowns of AWS costs by service, region, and other dimensions</li> <li>Understand how costs are distributed across various services</li> <li>Query historical cost data for specific time periods</li> <li>Filter costs by various dimensions, tags, and cost categories</li> <li>Ask natural language questions about AWS costs</li> </ul> <p>Learn more about the AWS Cost Explorer MCP Server</p>"},{"location":"#aws-healthomics-mcp-server","title":"AWS HealthOmics MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for AWS HealthOmics</p> <p>Features:</p> <ul> <li>Workflow Management: Create, validate, and manage genomic workflows</li> <li>Workflow Execution: Start runs, monitor status, and manage tasks</li> <li>Analysis and Troubleshooting: Analyze run performance and diagnose failures</li> <li>Log Access: Retrieve run, engine, task, and manifest logs</li> <li>Region Management: Get supported AWS regions for HealthOmics</li> </ul> <p>Instructions for using this aws-healthomics MCP server. This can be used by clients to improve the LLM's understanding of available tools, resources, etc. for the AWS HealthOmics service</p> <p>Learn more about the aws-healthomics MCP Server</p>"},{"location":"#installation-and-setup","title":"Installation and Setup","text":"<p>Please refer to the README files in each server's directory for specific installation instructions.</p>"},{"location":"#samples","title":"Samples","text":"<p>Please refer to the samples directory for examples of how to use the MCP Servers.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see the contributing guidelines for more information.</p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>Before using an MCP Server, you should consider conducting your own independent assessment to ensure that your use would comply with your own specific security and quality control practices and standards, as well as the laws, rules, and regulations that govern you and your content.</p>"},{"location":"samples/","title":"AWS MCP Servers - Samples","text":"<p>This directory contains a collection of examples demonstrating how to use the AWS MCP Servers provided in the <code>src</code> directory. Each sample is organized into its own folder with relevant documentation and code.</p>"},{"location":"samples/#structure","title":"Structure","text":"<pre><code>samples/\n\u251c\u2500\u2500 project-name/\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2514\u2500\u2500 (sample code and resources)\n</code></pre>"},{"location":"samples/#purpose","title":"Purpose","text":"<p>The samples in this directory provide:</p> <ul> <li>Working examples for each AWS MCP Server</li> <li>Integration patterns and best practices</li> <li>Code snippets for common use cases</li> <li>Step-by-step guides</li> </ul>"},{"location":"samples/#guidelines","title":"Guidelines","text":"<ul> <li>Each sample directory should focus on demonstrating one or more MCP servers</li> <li>All samples must include a README.md with clear instructions</li> <li>Samples should not introduce new MCP servers, but only demonstrate usage of existing ones</li> </ul>"},{"location":"samples/#available-samples","title":"Available Samples","text":""},{"location":"samples/#mcp-integration-with-kb","title":"MCP Integration with KB","text":"<p>A client that integrates with the Amazon Bedrock Knowledge Base MCP server. Code can be found in the mcp-integration-with-kb folder.</p>"},{"location":"samples/#aws-step-functions-tool-mcp-server","title":"AWS Step Functions Tool MCP Server","text":"<p>A server that enables AI models to execute AWS Step Functions state machines as tools, allowing seamless integration with existing workflows. The server supports both Standard and Express workflows, and integrates with EventBridge Schema Registry for input validation. Code can be found in the src/stepfunctions-tool-mcp-server folder.</p>"},{"location":"samples/#coming-soon","title":"Coming Soon","text":""},{"location":"samples/#contributing","title":"Contributing","text":"<p>We welcome contributions of additional samples. Please ensure your sample follows the guidelines above and demonstrates real-world usage of the MCP servers.</p>"},{"location":"samples/mcp-integration-with-kb/","title":"MCP Integration with Amazon Bedrock Knowledge Bases","text":"<p>This repository outlines a basic implementation of the Model Context Protocol integration with Amazon Bedrock Knowledge Bases</p>"},{"location":"samples/mcp-integration-with-kb/#overview","title":"Overview","text":"<p>There are two parts to this implementation:</p> <ol> <li>The <code>user_interfaces/chat_bedrock_st.py</code> file, which handles the Streamlit/User Interface for the chatbot</li> <li>The <code>client_server.py</code> file, which handles the MCP client and server implementation</li> </ol> <p>The exact MCP server code used in this implementation can be found in the src/bedrock-kb-retrieval-mcp-server folder.</p>"},{"location":"samples/mcp-integration-with-kb/#architecture","title":"Architecture","text":""},{"location":"samples/mcp-integration-with-kb/#setup","title":"Setup","text":""},{"location":"samples/mcp-integration-with-kb/#prerequisites","title":"Prerequisites","text":"<ul> <li>The uv package manager</li> <li>AWS Account with Bedrock access and proper IAM permissions - Getting Started with Amazon Bedrock</li> <li>A Bedrock Knowledge Base</li> <li>For a quick reference Knowledge Base setup, check out the e2e RAG solution via CDK repo. This will set you up with everything you need - IAM roles, vector storage (either OpenSearch Serverless or Aurora PostgreSQL), and a fully configured Knowledge Base with sample data. The Knowledge Base is the only component you'll really need for this implementation.</li> </ul> <p>Note: Reranking for Amazon Bedrock is not supported in us-east-1. For more information about supported regions and models for reranking, see Supported Regions and models for reranking in Amazon Bedrock.</p>"},{"location":"samples/mcp-integration-with-kb/#installation","title":"Installation","text":"<ol> <li>Clone the repository.</li> </ol> <pre><code>git clone https://github.com/awslabs/mcp.git\n</code></pre> <ol> <li>Navigate to the sample directory and copy the .env.example file to .env and add your AWS credentials.</li> </ol> <pre><code>cd mcp/samples/mcp-integration-with-kb\ncp .env.example .env\n</code></pre> <ol> <li>Open two different terminals and install the dependencies in each.</li> </ol> <pre><code>uv sync\n</code></pre> <p>then activate the virtual environment</p> <pre><code>source .venv/bin/activate\n</code></pre> <ol> <li>In one of the terminals, run the FastAPI server</li> </ol> <pre><code>uvicorn clients.client_server:app --reload\n</code></pre> <ol> <li>In the other terminal, run the Streamlit app</li> </ol> <pre><code>streamlit run user_interfaces/chat_bedrock_st.py\n</code></pre> <ol> <li>The chatbot should now be running on http://localhost:8501/</li> </ol>"},{"location":"samples/mcp-integration-with-kb/#usage","title":"Usage","text":"<p>Grab your Bedrock Knowledge Base ID from the Bedrock Knowledge Base console and add it to the UI first on the left hand side menu.</p> <p>Ask away!</p>"},{"location":"samples/mcp-integration-with-kb/#troubleshooting","title":"Troubleshooting","text":"<p>Logs are available in the terminal where you ran the FastAPI server, outlining various steps and actions taken by the server.</p> <p>If you see an error about <code>boto3</code> or <code>streamlit</code> not being found, it is likely because you did not activate the virtual environment:</p> <pre><code>uv sync\nsource .venv/bin/activate\n</code></pre>"},{"location":"servers/amazon-keyspaces-mcp-server/","title":"AWS Labs amazon-keyspaces MCP Server","text":"<p>An Amazon Keyspaces (for Apache Cassandra) MCP server for interacting with Amazon Keyspaces and Apache Cassandra.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#overview","title":"Overview","text":"<p>The Amazon Keyspaces MCP server implements the Model Context Protocol (MCP) to enable AI assistants like Amazon Q to interact with Amazon Keyspaces or Apache Cassandra databases through natural language. This server allows you to explore  database schemas, execute queries, and analyze query performance without having to write CQL code directly.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#features","title":"Features","text":"<p>The Amazon Keyspaces (for Apache Cassandra) MCP server provides the following capabilities: 1. Schema: Explore keyspaces and tables. 2. Run Queries: Execute CQL SELECT queries against the configured database. 3. Query Analysis: Get feedback and suggestions for improving query performance. 4. Cassandra-Compatible: Use with Amazon Keyspaces, or with Apache Cassandra.</p> <p>Here are some example prompts that this MCP server can help with: - \"List all keyspaces in my Cassandra database\" - \"Show me the tables in the 'sales' keyspace\" - \"Describe the 'users' table in the 'sales' keyspace\" - \"What's the schema of the 'products' table?\" - \"Run a SELECT query to get all users from the 'users' table in 'sales'\" - \"Query the first 10 records from the 'events' table\" - \"Analyze the performance of this query: SELECT * FROM users WHERE last_name = 'Smith'\" - \"Is this query efficient: SELECT * FROM orders WHERE order_date &gt; '2023-01-01'?\"</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#installation","title":"Installation","text":""},{"location":"servers/amazon-keyspaces-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or 3.11 (Python 3.12+ is not fully supported due to asyncore module removal)</li> <li>Access to an Amazon Keyspaces instance or Apache Cassandra cluster that supports password authentication</li> <li>Appropriate Cassandra log-in credentials</li> <li>Starfield digital certificate (required for Amazon Keyspaces)</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install awslabs.amazon-keyspaces-mcp-server\n</code></pre>"},{"location":"servers/amazon-keyspaces-mcp-server/#install-from-source","title":"Install from Source","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/awslabs/mcp.git\ncd mcp/src/amazon-keyspaces-mcp-server\n</code></pre></p> </li> <li> <p>Create a virtual environment:    <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install the package:    <pre><code>pip install -e .\n</code></pre></p> </li> </ol>"},{"location":"servers/amazon-keyspaces-mcp-server/#configuration","title":"Configuration","text":"<p>Create a <code>.keyspaces-mcp</code> directory in your home directory. In the <code>.keyspaces-mcp</code> directory, create an <code>env</code> file with your database connection settings:</p> <pre><code># Set to true for Amazon Keyspaces, false for Apache Cassandra\nDB_USE_KEYSPACES=true\n\n# Cassandra configuration (for native Cassandra)\nDB_CASSANDRA_CONTACT_POINTS=127.0.0.1\nDB_CASSANDRA_PORT=9042\nDB_CASSANDRA_LOCAL_DATACENTER=datacenter1\nDB_CASSANDRA_USERNAME=\nDB_CASSANDRA_PASSWORD=\n\n# Keyspaces configuration (for Amazon Keyspaces)\nDB_KEYSPACES_ENDPOINT=cassandra.us-west-2.amazonaws.com\nDB_KEYSPACES_REGION=us-west-2\n</code></pre> <p>Note that all of these settings can be set directly as environment variables, if you prefer that to using a configuration file.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#authentication-credentials","title":"Authentication Credentials","text":"<p>This MCP server uses username and password authentication for both Amazon Keyspaces and Apache Cassandra:</p> <ul> <li> <p>For Amazon Keyspaces: Set the <code>DB_CASSANDRA_USERNAME</code> and <code>DB_CASSANDRA_PASSWORD</code> environment variables with your Keyspaces username and password. These are the same service-specific credentials you would use to access Keyspaces via the Cassandra Query Language (CQL) shell.</p> </li> <li> <p>For Apache Cassandra: Set the <code>DB_CASSANDRA_USERNAME</code> and <code>DB_CASSANDRA_PASSWORD</code> environment variables with your Cassandra username and password.</p> </li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#starfield-digital-certificate-for-amazon-keyspaces","title":"Starfield Digital Certificate for Amazon Keyspaces","text":"<p>Before connecting to Amazon Keyspaces, you need to download and install the Starfield digital certificate that Amazon Keyspaces uses for TLS connections:</p> <ol> <li> <p>Download the Starfield digital certificate:    <pre><code>curl -O https://certs.secureserver.net/repository/sf-class2-root.crt\n</code></pre></p> </li> <li> <p>Place the certificate in the correct location:    <pre><code>mkdir -p ~/.keyspaces-mcp/certs\ncp sf-class2-root.crt ~/.keyspaces-mcp/certs/\n</code></pre></p> </li> </ol>"},{"location":"servers/amazon-keyspaces-mcp-server/#running-the-mcp-server","title":"Running the MCP Server","text":"<p>After installation, you can run the server directly:</p> <pre><code>awslabs.amazon-keyspaces-mcp-server\n</code></pre>"},{"location":"servers/amazon-keyspaces-mcp-server/#configuring-amazon-q-to-use-the-mcp-server","title":"Configuring Amazon Q to Use the MCP Server","text":"<p>To use the Amazon Keyspaces MCP server with Amazon Q CLI, you need to configure it in your Q configuration file.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#configuration-for-amazon-q-cli","title":"Configuration for Amazon Q CLI","text":"<p>Edit the Q configuration file at <code>~/.aws/amazonq/mcp.json</code>:</p> <pre><code>{\n  \"mcpServers\": [\n    {\n      \"name\": \"keyspaces-mcp\",\n      \"command\": \"awslabs.amazon-keyspaces-mcp-server\",\n      \"args\": [],\n      \"env\": {}\n    }\n  ]\n}\n</code></pre> <p>If the file doesn't exist yet or doesn't have an <code>mcpServers</code> section, create it with the structure shown above.</p> <p>Now when you use Q Chat by running <code>q chat</code>, it will automatically connect to your Keyspaces MCP server.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#available-tools","title":"Available Tools","text":"<p>The Amazon Keyspaces MCP server provides the following tools that AI assistants can use:</p> <ul> <li><code>listKeyspaces</code>: Lists all keyspaces in the database</li> <li><code>listTables</code>: Lists all tables in a specified keyspace</li> <li><code>describeKeyspace</code>: Gets detailed information about a keyspace</li> <li><code>describeTable</code>: Gets detailed information about a table</li> <li><code>executeQuery</code>: Executes a read-only SELECT query against the database</li> <li><code>analyzeQueryPerformance</code>: Analyzes the performance characteristics of a CQL query</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#security-considerations","title":"Security Considerations","text":"<ul> <li>When using Amazon Keyspaces, ensure your IAM policies follow the principle of least privilege. While this MCP server does not mutate Keyspaces data or resources, it cannot prevent agent-driven attempts to (for example) invoke AWS SDK operations on your behalf, including mutating operations.</li> <li>This MCP server only allows read-only SELECT queries to protect your data.</li> <li>Queries are validated to prevent potentially harmful operations.</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#troubleshooting","title":"Troubleshooting","text":""},{"location":"servers/amazon-keyspaces-mcp-server/#connection-issues","title":"Connection Issues","text":"<ul> <li>Verify your database connection settings in the <code>.keyspaces-mcp/env</code> file in your home directory.</li> <li>Ensure your logged-in user has the necessary permissions for the operations performed by this server.</li> <li>Check that your database is accessible from your network.</li> <li>For Amazon Keyspaces, verify that the Starfield certificate is correctly installed in the <code>.keyspaces-mcp/certs</code> directory.</li> <li>If you get SSL/TLS errors, check that the certificate path is correct and the certificate is valid.</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#python-version-compatibility","title":"Python Version Compatibility","text":"<ul> <li>The MCP server works best with Python 3.10 or 3.11.</li> <li>Python 3.12+ may have issues due to the removal of the asyncore module which the Cassandra driver depends on.</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#cassandra-driver-issues","title":"Cassandra Driver Issues","text":"<p>If you encounter issues with the Cassandra driver:</p> <ol> <li>Ensure you have the necessary C dependencies installed for the Cassandra driver.</li> <li>Try installing the driver with: <code>pip install cassandra-driver --no-binary :all:</code></li> </ol>"},{"location":"servers/amazon-keyspaces-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"servers/amazon-mq-mcp-server/","title":"Amazon MQ MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon MQ that enables generative AI models to manage RabbitMQ and ActiveMQ message brokers through MCP tools.</p>"},{"location":"servers/amazon-mq-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and Amazon MQ, allowing generative AI models to create, configure, and manage message brokers. The server provides a secure way to interact with Amazon MQ resources while maintaining proper access controls and resource tagging.</p> <pre><code>graph LR\n    A[Model] &lt;--&gt; B[MCP Client]\n    B &lt;--&gt; C[\"Amazon MQ MCP Server\"]\n    C &lt;--&gt; D[Amazon MQ Service]\n    D --&gt; E[RabbitMQ Brokers]\n    D --&gt; F[ActiveMQ Brokers]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:4px\n    style D fill:#fbb,stroke:#333,stroke-width:2px\n    style E fill:#fbf,stroke:#333,stroke-width:2px\n    style F fill:#dff,stroke:#333,stroke-width:2px</code></pre> <p>From a security perspective, this server implements resource tagging to ensure that only resources created through the MCP server can be modified by it. This prevents unauthorized modifications to existing Amazon MQ resources that were not created by the MCP server.</p>"},{"location":"servers/amazon-mq-mcp-server/#key-capabilities","title":"Key Capabilities","text":"<ul> <li>Create and manage Amazon MQ brokers (RabbitMQ and ActiveMQ)</li> <li>Configure broker settings and parameters</li> <li>List and describe existing brokers</li> <li>Reboot and update brokers</li> <li>Create and manage broker configurations</li> <li>Automatic resource tagging for security</li> </ul>"},{"location":"servers/amazon-mq-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>AWS account with permissions to create and manage Amazon MQ resources</li> </ol>"},{"location":"servers/amazon-mq-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/amazon-mq-mcp-server/#iam-configuration","title":"IAM Configuration","text":"<p>The authorization between AmazonMQ MCP server and your AWS accounts are performed with AWS profile you setup on the host. There are several ways to setup a AWS profile, however we recommend creating a new IAM role that has <code>AmazonMQReadOnlyAccess</code> permission following the principle of \"least privilege\". Note, if you want to use tools that mutate your tagged resources, you need to grant <code>AmazonMQFullAccess</code>. Finally, configure a AWS profile on the host that assumes the new role (for more information, check out the AWS CLI help page).</p>"},{"location":"servers/amazon-mq-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon-mq-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-mq-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre> <p>If you would like to specify a flag (for example, to allow creation of resources), you can pass it to the args</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon-mq-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-mq-mcp-server@latest\", \"--allow-resource-creation\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/amazon-mq-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.amazon-mq-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/amazon-mq-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/amazon-mq-mcp-server/#server-configuration-options","title":"Server Configuration Options","text":"<p>The Amazon MQ MCP Server supports several command-line arguments that can be used to configure its behavior:</p>"},{"location":"servers/amazon-mq-mcp-server/#-allow-resource-creation","title":"<code>--allow-resource-creation</code>","text":"<p>Allow tools that create resources in the user's AWS account. When this flag is enabled, the <code>create_broker</code> and <code>create_configuration</code> tools will be created for the MCP client, preventing the creation of new Amazon MQ resources. Default is False.</p> <p>This flag is particularly useful for: - Testing environments where resource creation should be restricted - Limiting the scope of actions available to the AI model</p> <p>Example: <pre><code>uv run awslabs.amazon-mq-mcp-server --allow-resource-creation\n</code></pre></p>"},{"location":"servers/amazon-mq-mcp-server/#security-features","title":"Security Features","text":"<p>The MCP server implements a security mechanism that only allows modification of resources that were created by the MCP server itself. This is achieved by:</p> <ol> <li>Automatically tagging all created resources with a <code>mcp_server_version</code> tag</li> <li>Validating this tag before allowing any mutative actions (update, delete, reboot)</li> <li>Rejecting operations on resources that don't have the appropriate tag</li> </ol>"},{"location":"servers/amazon-mq-mcp-server/#best-practices","title":"Best Practices","text":"<ul> <li>Use descriptive broker names to easily identify resources</li> <li>Follow the principle of least privilege when setting up IAM permissions</li> <li>Use separate AWS profiles for different environments (dev, test, prod)</li> <li>Monitor broker metrics and logs for performance and issues</li> <li>Implement proper error handling in your client applications</li> </ul>"},{"location":"servers/amazon-mq-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, consider:</p> <ul> <li>The MCP server needs permissions to create and manage Amazon MQ resources</li> <li>Only resources created by the MCP server can be modified by it</li> <li>Ensure proper network security for your brokers (use <code>publicly_accessible: false</code> when possible)</li> <li>Implement strong authentication for broker users</li> <li>Review and rotate credentials regularly</li> </ul>"},{"location":"servers/amazon-mq-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter permission errors, verify your IAM user has the correct policies attached</li> <li>For connection issues, check network configurations and security groups</li> <li>If resource modification fails with a tag validation error, it means the resource was not created by the MCP server</li> <li>For general Amazon MQ issues, consult the Amazon MQ documentation</li> </ul>"},{"location":"servers/amazon-mq-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 1.0.0</p>"},{"location":"servers/amazon-neptune-mcp-server/","title":"Amazon neptune mcp server","text":"<pre><code>---\ntitle: Amazon Neptune MCP Server\n---\n\n# AWS Labs Amazon Neptune MCP Server\n\nAn Amazon Neptune MCP server that allows for fetching status, schema, and querying using openCypher and Gremlin for Neptune Database and openCypher for Neptune Analytics.\n\n## Features\n\nThe Amazon Neptune MCP Server provides the following capabilities:\n\n1. **Run Queries**: Execute openCypher and/or Gremlin queries against the configured database\n2. **Schema**: Get the schema in the configured graph as a text string\n3. **Status**: Find if the graph is \"Available\" or \"Unavailable\" to your server.  This is useful in helping to ensure that the graph is connected.\n\n### AWS Requirements\n\n1. **AWS CLI Configuration**: You must have the AWS CLI configured with credentials and an AWS_PROFILE that has access to Amazon Neptune\n2. **Amazon Neptune**: You must have at least one Amazon Neptune Database or Amazon Neptune Analytics graph.\n3. **IAM Permissions**: Your IAM role/user must have appropriate permissions to:\n   - Access Amazon Neptune\n   - Query Amazon Neptune\n4. **Access**: The location where you are running the server must have access to the Amazon Neptune instance.  Neptune Database resides in a private VPC so access into the private VPC.  Neptune Analytics can be access either using a public endpoint, if configured, or the access will be needed to the private endpoint.\n\nNote: This server will run any query sent to it, which could include both mutating and read-only actions.  Properly configuring the permissions of the role to allow/disallow specific data plane actions as specified here:\n* [Neptune Database](https://docs.aws.amazon.com/neptune/latest/userguide/security.html)\n* [Neptune Analytics](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/security.html)\n\n\n## Prerequisites\n\n1. Install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the [GitHub README](https://github.com/astral-sh/uv#installation)\n2. Install Python using `uv python install 3.10`\n\n## Installation\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.com/install-mcp?name=Neptune%20Query&amp;config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1hem9uLW5lcHR1bmUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwiOiJJTkZPIiwiTkVQVFVORV9FTkRQT0lOVCI6IjxJTlNFUlQgTkVQVFVORSBFTkRQT0lOVCBJTiBGT1JNQVQgU1BFQ0lGSUVEIEJFTE9XPiJ9fQ%3D%3D)\n\nBelow is an example of how to configure your MCP client, although different clients may require a different format.\n\n\n```json\n{\n  \"mcpServers\": {\n    \"Neptune Query\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-neptune-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"INFO\",\n        \"NEPTUNE_ENDPOINT\": \"&lt;INSERT NEPTUNE ENDPOINT IN FORMAT SPECIFIED BELOW&gt;\"\n      }\n    }\n  }\n}\n\n```\n### Docker Configuration\nAfter building with `docker build -t awslabs/amazon-neptune-mcp-server .`:\n\n```\n{\n  \"mcpServers\": {\n    \"awslabs.amazon-neptune-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"-i\",\n          \"awslabs/amazon-neptune-mcp-server\"\n        ],\n        \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"INFO\",\n        \"NEPTUNE_ENDPOINT\": \"&lt;INSERT NEPTUNE ENDPOINT IN FORMAT SPECIFIED BELOW&gt;\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n```\n\nWhen specifying the Neptune Endpoint the following formats are expected:\n\nFor Neptune Database:\n`neptune-db://&lt;Cluster Endpoint&gt;`\n\nFor Neptune Analytics:\n`neptune-graph://&lt;graph identifier&gt;`\n</code></pre>"},{"location":"servers/amazon-qindex-mcp-server/","title":"AWS Labs amazon-qindex MCP Server","text":"<p>The AWS Labs amazon-qindex MCP Server is a Model Context Protocol (MCP) server designed to facilitate integration with Amazon Q Business's SearchRelevantContent API. While the server provides essential tools and functions for authentication and search capabilities using Amazon Q index, it currently serves for Independent Software Vendors (ISVs) who are AWS registered data accessors. The server enables cross-account search capabilities, allowing ISVs who are data accessors to search through enterprise customers' Q index and access relevant content across their data sources using specific authentication and authorization flows.</p> <p>For Amazon Q Business application owners, direct integration support is not yet available. This MCP server represents a comprehensive solution that aims to serve ISVs.</p>"},{"location":"servers/amazon-qindex-mcp-server/#features","title":"Features","text":"<ul> <li>Boto3 client implementation for Q Business interactions</li> <li>Support for various authentication methods (IAM credentials, profile-based)</li> <li>MCP server implementation for handling Q index requests</li> <li>Token-based authorization support</li> <li>Error handling and mapping for Q Business API responses</li> </ul>"},{"location":"servers/amazon-qindex-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/amazon-qindex-mcp-server/#authorizeqindex","title":"AuthorizeQIndex","text":"<ul> <li>Generates OIDC authorization URL for Q index authentication</li> <li>Required Parameters:</li> <li>idc_region (str): AWS region for IAM Identity Center (e.g., us-west-2)</li> <li>isv_redirect_url (str): Redirect URL registered during ISV registration</li> <li>oauth_state (str): Random string for CSRF protection</li> <li>idc_application_arn (str): Amazon Q Business application ID</li> <li>Returns: Authorization URL for user authentication</li> </ul>"},{"location":"servers/amazon-qindex-mcp-server/#createtokenwithiam","title":"CreateTokenWithIAM","text":"<ul> <li>Creates authentication token using authorization code through IAM</li> <li>Required Parameters:</li> <li>idc_application_arn (str): Amazon Q Business application ID</li> <li>redirect_uri (str): Registered redirect URL</li> <li>code (str): Authorization code from OIDC endpoint</li> <li>idc_region (str): AWS region for IAM Identity Center</li> <li>role_arn (str): IAM role ARN to assume</li> <li>Returns: Token information including access token, refresh token, and expiration</li> </ul>"},{"location":"servers/amazon-qindex-mcp-server/#assumerolewithidentitycontext","title":"AssumeRoleWithIdentityContext","text":"<ul> <li>Assumes IAM role using identity context from token</li> <li>Required Parameters:</li> <li>role_arn (str): IAM role ARN to assume</li> <li>identity_context (str): Identity context from decoded token</li> <li>role_session_name (str): Session identifier (default: \"qbusiness-session\")</li> <li>idc_region (str): AWS region for IAM Identity Center</li> <li>Returns: Temporary AWS credentials</li> </ul>"},{"location":"servers/amazon-qindex-mcp-server/#searchrelevantcontent","title":"SearchRelevantContent","text":"<ul> <li>Searches content within Amazon Q Business application</li> <li>Required Parameters:</li> <li>application_id (str): Q Business application identifier</li> <li>query_text (str): Search query text</li> <li>Optional Parameters:</li> <li>attribute_filter (AttributeFilter): Document attribute filters</li> <li>content_source (ContentSource): Content source configuration</li> <li>max_results (int): Maximum results to return (1-100)</li> <li>next_token (str): Pagination token</li> <li>qbuiness_region (str): AWS region (default: us-east-1)</li> <li>aws_credentials: Temporary AWS credentials</li> <li>Returns: Search results with relevant content matches</li> </ul>"},{"location":"servers/amazon-qindex-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/amazon-qindex-mcp-server/#pre-requisites","title":"Pre-Requisites","text":"<ul> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li> <p>Install Python using <code>uv python install 3.10</code></p> </li> <li> <p>Two AWS Accounts (one account as ISV running this tester application, another account acting as enterprise customer running Amazon Q Business)</p> </li> <li>Data accessor registered for your ISV</li> <li>IAM Identity Center (IDC) instance setup with user added on enterprise customer AWS account</li> <li>Amazon Q Business application setup with IAM IDC as access management on enterprise customer AWS account</li> </ul>"},{"location":"servers/amazon-qindex-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon_qindex_mcp_server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon_qindex_mcp_server\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre> <pre><code># Clone the repository\ngit clone [repository-url]\n\n# Go to root directory of this server\ncd &lt;your repo path&gt;/mcp/src/amazon-qindex-mcp-server/\n\n# Install dependencies\npip install -e .\n</code></pre>"},{"location":"servers/amazon-qindex-mcp-server/#usage","title":"Usage","text":"<ol> <li>Enter a text prompt describing what you want to query from enterprise data</li> </ol> <pre><code>search &lt;your query&gt; on enterprise data\n</code></pre> <ol> <li>You also need to provide the following details to proceed with the authentication flow in order to process SearchRelevantContent API</li> </ol> <pre><code>application id - (enterprise account's Amazon Q Business application ID)\nretriever id - (enterprise account's Amazon Q Business retriever ID)\niam idc arn - (enterprise account's IdC application ARN)\nidc region - (Region for the IAM Identity Center instance)\nqbuiness region - (enterprise account's Amazon Q Business application region)\nredirect url - (ISV's redirect url - this could be anything within allowlisted for the data accessor - ie https://localhost:8081)\niam role arn - (ISV's IAM Role ARN registered with the data accessor)\n</code></pre> <ol> <li>After providing the data through above two steps, you will be asked to visit the authorization URL on your browser and after successfully authenticated and taken to redirect url with an authorization code in the URL parameters (it will look like ?code=ABC123...&amp;state=xxx), copy and paste the code portion to the client to resume the process.</li> </ol> <pre><code>code is &lt;your authorization code&gt;\n</code></pre> <ol> <li>This MCP server will then process CreateTokenWithIAM to create authentication token, AssumeRoleWithIdentityContext to assume the role and get temporary credentials, then finally call SearchRelevantContent to searches user queried content within Amazon Q Business application.</li> </ol>"},{"location":"servers/amazon-qindex-mcp-server/#testing","title":"Testing","text":"<p>Run tests using pytest: <pre><code>pytest --cache-clear -v\n</code></pre></p>"},{"location":"servers/amazon-qindex-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>This MCP server implementation is for demonstration purposes only to showcase how to access the SearchRelevantContent API through an MCP server with user-aware authentication. For production use, please consider the following security measures:</p>"},{"location":"servers/amazon-qindex-mcp-server/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<ul> <li>Never hardcode credentials or sensitive information in the code</li> <li>Implement proper session management and token refresh mechanisms</li> <li>Use strong CSRF protection mechanisms for the OAuth flow</li> <li>Implement proper validation of all authorization codes and tokens</li> <li>Store tokens securely and never log them</li> <li>Implement proper token revocation when sessions end</li> </ul>"},{"location":"servers/amazon-rekognition-mcp-server/","title":"Amazon Rekognition MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon Rekognition that enables AI assistants to analyze images using Amazon Rekognition's powerful computer vision capabilities.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#features","title":"Features","text":"<ul> <li>Face Collection Management: Create and manage collections of faces</li> <li>Face Recognition: Index and search for faces in images</li> <li>Object and Scene Detection: Identify objects, scenes, and activities in images</li> <li>Content Moderation: Detect unsafe or inappropriate content</li> <li>Celebrity Recognition: Identify celebrities in images</li> <li>Face Comparison: Compare faces between images for similarity</li> <li>Text Detection: Extract text from images</li> </ul>"},{"location":"servers/amazon-rekognition-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to Amazon Rekognition</li> <li>You need an AWS account with Amazon Rekognition enabled</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to use Amazon Rekognition</li> </ol>"},{"location":"servers/amazon-rekognition-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon-rekognition-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-rekognition-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"BASE_DIR\": \"/path/to/base/directory\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/amazon-rekognition-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon-rekognition-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"AWS_PROFILE\",\n        \"--env\",\n        \"AWS_REGION\",\n        \"--env\",\n        \"BASE_DIR\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL\",\n        \"awslabs/amazon-rekognition-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"BASE_DIR\": \"/path/to/base/directory\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/amazon-rekognition-mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>AWS_PROFILE</code>: AWS CLI profile to use for credentials</li> <li><code>AWS_REGION</code>: AWS region to use (default: us-east-1)</li> <li><code>BASE_DIR</code>: Base directory for file operations (optional)</li> <li><code>FASTMCP_LOG_LEVEL</code>: Logging level (ERROR, WARNING, INFO, DEBUG)</li> </ul>"},{"location":"servers/amazon-rekognition-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the default credential provider chain.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\",\n  \"AWS_REGION\": \"us-east-1\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access Amazon Rekognition services. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/amazon-rekognition-mcp-server/#list_collections","title":"list_collections","text":"<p>Returns a list of collection IDs in your account.</p> <pre><code>list_collections() -&gt; dict\n</code></pre> <p>Returns a dictionary containing a list of collection IDs and face model versions.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#index_faces","title":"index_faces","text":"<p>Detects faces in an image and adds them to the specified collection.</p> <pre><code>index_faces(collection_id: str, image_path: str) -&gt; dict\n</code></pre> <p>Parameters: - <code>collection_id</code>: ID of the collection to add the face to - <code>image_path</code>: Path to the image file</p> <p>Returns a dictionary containing information about the indexed faces.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#search_faces_by_image","title":"search_faces_by_image","text":"<p>Searches for faces in a collection that match a supplied face.</p> <pre><code>search_faces_by_image(collection_id: str, image_path: str) -&gt; dict\n</code></pre> <p>Parameters: - <code>collection_id</code>: ID of the collection to search - <code>image_path</code>: Path to the image file</p> <p>Returns a dictionary containing information about the matching faces.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#detect_labels","title":"detect_labels","text":"<p>Detects instances of real-world entities within an image.</p> <pre><code>detect_labels(image_path: str) -&gt; dict\n</code></pre> <p>Parameters: - <code>image_path</code>: Path to the image file</p> <p>Returns a dictionary containing detected labels and other metadata.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#detect_moderation_labels","title":"detect_moderation_labels","text":"<p>Detects unsafe content in an image.</p> <pre><code>detect_moderation_labels(image_path: str) -&gt; dict\n</code></pre> <p>Parameters: - <code>image_path</code>: Path to the image file</p> <p>Returns a dictionary containing detected moderation labels and other metadata.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#recognize_celebrities","title":"recognize_celebrities","text":"<p>Recognizes celebrities in an image.</p> <pre><code>recognize_celebrities(image_path: str) -&gt; dict\n</code></pre> <p>Parameters: - <code>image_path</code>: Path to the image file</p> <p>Returns a dictionary containing recognized celebrities and other metadata.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#compare_faces","title":"compare_faces","text":"<p>Compares a face in the source input image with faces in the target input image.</p> <pre><code>compare_faces(source_image_path: str, target_image_path: str) -&gt; dict\n</code></pre> <p>Parameters: - <code>source_image_path</code>: Path to the source image file - <code>target_image_path</code>: Path to the target image file</p> <p>Returns a dictionary containing information about the face matches.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#detect_text","title":"detect_text","text":"<p>Detects text in an image.</p> <pre><code>detect_text(image_path: str) -&gt; dict\n</code></pre> <p>Parameters: - <code>image_path</code>: Path to the image file</p> <p>Returns a dictionary containing detected text elements and their metadata.</p>"},{"location":"servers/amazon-rekognition-mcp-server/#example-usage","title":"Example Usage","text":"<pre><code># List available face collections\ncollections = await list_collections()\n\n# Index a face in a collection\nindexed_face = await index_faces(\n    collection_id=\"my-collection\",\n    image_path=\"/path/to/face.jpg\"\n)\n\n# Search for a face in a collection\nmatches = await search_faces_by_image(\n    collection_id=\"my-collection\",\n    image_path=\"/path/to/face.jpg\"\n)\n\n# Detect labels in an image\nlabels = await detect_labels(\n    image_path=\"/path/to/image.jpg\"\n)\n\n# Detect moderation labels in an image\nmoderation = await detect_moderation_labels(\n    image_path=\"/path/to/image.jpg\"\n)\n\n# Recognize celebrities in an image\ncelebrities = await recognize_celebrities(\n    image_path=\"/path/to/celebrity.jpg\"\n)\n\n# Compare faces between two images\ncomparison = await compare_faces(\n    source_image_path=\"/path/to/source.jpg\",\n    target_image_path=\"/path/to/target.jpg\"\n)\n\n# Detect text in an image\ntext = await detect_text(\n    image_path=\"/path/to/image_with_text.jpg\"\n)\n</code></pre>"},{"location":"servers/amazon-rekognition-mcp-server/#security-considerations","title":"Security Considerations","text":"<ul> <li>Use AWS IAM roles with appropriate permissions</li> <li>Store credentials securely</li> <li>Use temporary credentials when possible</li> <li>Be aware of Amazon Rekognition service quotas and limits</li> </ul>"},{"location":"servers/amazon-rekognition-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License, Version 2.0. See the LICENSE file for details.</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/","title":"Amazon SNS / SQS MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon SNS / SQS that enables generative AI models to manage SNS Topics and SQS Queues through MCP tools.</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and Amazon SNS / SQS, allowing generative AI models to create, configure, and manage Topics / Queues. The server provides a secure way to interact with Amazon SNS / SQS resources while maintaining proper access controls and resource tagging.</p> <pre><code>graph LR\n    A[Model] &lt;--&gt; B[MCP Client]\n    B &lt;--&gt; C[\"Amazon SNS / SQS MCP Server\"]\n    C &lt;--&gt; D[Amazon SNS / SQS Service]\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:4px\n    style D fill:#fbb,stroke:#333,stroke-width:2px</code></pre> <p>From a security perspective, this server implements resource tagging to ensure that only resources created through the MCP server can be modified by it. This prevents unauthorized modifications to existing Amazon SNS/SQS resources that were not created by the MCP server.</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#key-capabilities","title":"Key Capabilities","text":"<p>This MCP server provides tools to: - Create, list, and manage Amazon SNS topics - Create, list, and manage Amazon SNS subscriptions - Create, list, and manage Amazon SQS queues - Send and receive messages using SNS and SQS</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>AWS account with permissions to create and manage Amazon SNS / SQS resources</li> </ol>"},{"location":"servers/amazon-sns-sqs-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/amazon-sns-sqs-mcp-server/#iam-configuration","title":"IAM Configuration","text":"<p>The authorization between the MCP server and your AWS accounts are performed with AWS profile you setup on the host. There are several ways to setup a AWS profile, however we recommend creating a new IAM role that has <code>AmazonSQSReadOnlyAccess</code> and <code>AmazonSNSReadOnlyAccess</code> permission following the principle of \"least privilege\". Note, if you want to use tools that mutate your tagged resources, you need to grant <code>AmazonSNSFullAccess</code> and <code>AmazonSQSFullAccess</code>. Finally, configure a AWS profile on the host that assumes the new role (for more information, check out the AWS CLI help page).</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon-sns-sqs-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-sns-sqs-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/amazon-sns-sqs-mcp-server.</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.sns-sqs-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/amazon-sns-sqs-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/amazon-sns-sqs-mcp-server/#server-configuration-options","title":"Server Configuration Options","text":"<p>The Amazon SNS / SQS MCP Server supports several command-line arguments that can be used to configure its behavior:</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#-allow-resource-creation","title":"<code>--allow-resource-creation</code>","text":"<p>Enables tools that create resources in the user's AWS account. When this flag is not enabled, the create new resources tools will be hidden from the MCP client, preventing the creation of new Amazon SNS / SQS resources. It also currently prevents deletion of any topics / queues. Default is False.</p> <p>This flag is particularly useful for: - Testing environments where resource creation should be restricted - Limiting the scope of actions available to the AI model</p> <p>Example: <pre><code>uv run awslabs.amazon-sns-sqs-mcp-server --disallow-resource-creation\n</code></pre></p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#security-features","title":"Security Features","text":"<p>The MCP server implements a security mechanism that only allows modification of resources that were created by the MCP server itself. This is achieved by:</p> <ol> <li>Automatically tagging all created resources with a <code>mcp_server_version</code> tag</li> <li>Validating this tag before allowing any mutative actions (update, delete) - this is a deterministic check that ensures only resources created by the MCP server can be modified</li> <li>Rejecting operations on resources that don't have the appropriate tag</li> <li>Application-to-Person (A2P) messaging mutative operations are not enabled by default for security reasons</li> </ol>"},{"location":"servers/amazon-sns-sqs-mcp-server/#best-practices","title":"Best Practices","text":"<ul> <li>Use descriptive topic and queue names to easily identify resources</li> <li>Follow the principle of least privilege when setting up IAM permissions</li> <li>Use separate AWS profiles for different environments (dev, test, prod)</li> <li>Implement proper error handling in your client applications</li> </ul>"},{"location":"servers/amazon-sns-sqs-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, consider:</p> <ul> <li>The MCP server needs permissions to create and manage Amazon SNS / SQS resources</li> <li>Only resources created by the MCP server can be modified by it since they are tagged</li> <li>Resource creation is disabled by default, enable it by setting the <code>--allow-resource-creation</code> flag on</li> </ul>"},{"location":"servers/amazon-sns-sqs-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter permission errors, verify your IAM user has the correct policies attached</li> <li>For connection issues, check network configurations and security groups</li> <li>If resource modification fails with a tag validation error, it means the resource was not created by the MCP server</li> <li>For general Amazon SNS / SQS issues, consult the Amazon SNS documentation , Amazon SQS documentation</li> </ul>"},{"location":"servers/amazon-sns-sqs-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 1.0.0</p>"},{"location":"servers/aurora-dsql-mcp-server/","title":"AWS Labs Aurora DSQL MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Aurora DSQL</p>"},{"location":"servers/aurora-dsql-mcp-server/#features","title":"Features","text":"<ul> <li>Converting human-readable questions and commands into structured Postgres-compatible SQL queries and executing them against the configured Aurora DSQL database.</li> <li>Read-only by default, transactions enabled with <code>--allow-writes</code></li> <li>Connection reuse between requests for improved performance</li> </ul>"},{"location":"servers/aurora-dsql-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>An AWS account with an Aurora DSQL Cluster</li> <li>This MCP server can only be run locally on the same host as your LLM client.</li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/aurora-dsql-mcp-server/#installation","title":"Installation","text":""},{"location":"servers/aurora-dsql-mcp-server/#using-uv","title":"Using <code>uv</code>","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol> <p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aurora-dsql-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.aurora-dsql-mcp-server@latest\",\n        \"--cluster_endpoint\",\n        \"[your dsql cluster endpoint]\",\n        \"--region\",\n        \"[your dsql cluster region, e.g. us-east-1]\",\n        \"--database_user\",\n        \"[your dsql username]\",\n        \"--profile\", \"default\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aurora-dsql-mcp-server/#using-docker","title":"Using Docker","text":"<ol> <li>'git clone https://github.com/awslabs/mcp.git'</li> <li>Go to sub-directory 'src/aurora-dsql-mcp-server/'</li> <li>Run 'docker build -t awslabs/aurora-dsql-mcp-server:latest .'</li> <li>Create a env file with temporary credentials:</li> </ol> <p>Either manually: <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n</code></pre></p> <p>Or using <code>aws configure</code>:</p> <pre><code>aws configure export-credentials --profile your-profile-name --format env &gt; temp_aws_credentials.env | sed 's/^export //' &gt; temp_aws_credentials.env\n</code></pre> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aurora-dsql-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--env-file\",\n        \"/full/path/to/file/above/.env\",\n        \"awslabs/aurora-dsql-mcp-server:latest\",\n        \"--cluster_endpoint\", \"[your data]\",\n        \"--database_user\", \"[your data]\",\n        \"--region\", \"[your data]\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aurora-dsql-mcp-server/#server-configuration-options","title":"Server Configuration options","text":""},{"location":"servers/aurora-dsql-mcp-server/#-allow-writes","title":"<code>--allow-writes</code>","text":"<p>By default, the dsql mcp server does not allow write operations (\"read-only mode\"). Any invocations of transact tool will fail in this mode. To use transact tool, allow writes by passing <code>--allow-writes</code> parameter.</p> <p>We recommend using least-privilege access when connecting to DSQL. For example, users should use a role that is read-only when possible. The read-only mode has a best-effort client-side enforcement to reject mutations.</p>"},{"location":"servers/aurora-dsql-mcp-server/#-cluster_endpoint","title":"<code>--cluster_endpoint</code>","text":"<p>This is mandatory parameter to specify the cluster to connect to. This should be the full endpoint of your cluster, e.g., <code>01abc2ldefg3hijklmnopqurstu.dsql.us-east-1.on.aws</code></p>"},{"location":"servers/aurora-dsql-mcp-server/#-database_user","title":"<code>--database_user</code>","text":"<p>This is a mandatory parameter to specify the user to connect as. For example <code>admin</code>, or <code>my_user</code>. Note that the AWS credentials you are using must have permission to login as that user. For more information on setting up and using database roles in DSQL, see Using database roles with IAM roles.</p>"},{"location":"servers/aurora-dsql-mcp-server/#-profile","title":"<code>--profile</code>","text":"<p>You can specify the aws profile to use for your credentials. Note that this is not supported for docker installation.</p> <p>Using the <code>AWS_PROFILE</code> environment variable in your MCP configuration is also supported:</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>If neither is provided, the MCP server defaults to using the \"default\" profile in your AWS configuration file.</p>"},{"location":"servers/aurora-dsql-mcp-server/#-region","title":"<code>--region</code>","text":"<p>This is a mandatory parameter to specify the region of your DSQL database.</p>"},{"location":"servers/aurora-dsql-mcp-server/#development-and-testing","title":"Development and Testing","text":""},{"location":"servers/aurora-dsql-mcp-server/#running-tests","title":"Running Tests","text":"<p>This project includes comprehensive tests to validate the readonly enforcement mechanisms. To run the tests:</p> <pre><code># Install dependencies and run tests\nuv run pytest tests/test_readonly_enforcement.py -v\n\n# Run all tests\nuv run pytest -v\n\n# Run tests with coverage\nuv run pytest --cov=awslabs.aurora_dsql_mcp_server tests/ -v\n</code></pre>"},{"location":"servers/aurora-dsql-mcp-server/#local-docker-testing","title":"Local Docker Testing","text":"<p>To test the MCP server locally using Docker:</p> <ol> <li> <p>Build the Docker image: <pre><code>cd src/aurora-dsql-mcp-server\ndocker build -t awslabs/aurora-dsql-mcp-server:latest .\n</code></pre></p> </li> <li> <p>Create AWS credentials file:</p> </li> </ol> <p>Option A - Manual creation:    <pre><code># Create .env file with your AWS credentials\ncat &gt; .env &lt;&lt; EOF\nAWS_ACCESS_KEY_ID=your_access_key_here\nAWS_SECRET_ACCESS_KEY=your_secret_key_here\nAWS_SESSION_TOKEN=your_session_token_here\nEOF\n</code></pre></p> <p>Option B - Export from AWS CLI:    <pre><code>aws configure export-credentials --profile your-profile-name --format env &gt; temp_aws_credentials.env\nsed 's/^export //' temp_aws_credentials.env &gt; .env\nrm temp_aws_credentials.env\n</code></pre></p> <ol> <li> <p>Test the container directly: <pre><code>docker run -i --rm \\\n  --env-file .env \\\n  awslabs/aurora-dsql-mcp-server:latest \\\n  --cluster_endpoint \"your-dsql-cluster-endpoint\" \\\n  --database_user \"your-username\" \\\n  --region \"us-east-1\"\n</code></pre></p> </li> <li> <p>Test with write operations enabled: <pre><code>docker run -i --rm \\\n  --env-file .env \\\n  awslabs/aurora-dsql-mcp-server:latest \\\n  --cluster_endpoint \"your-dsql-cluster-endpoint\" \\\n  --database_user \"your-username\" \\\n  --region \"us-east-1\" \\\n  --allow-writes\n</code></pre></p> </li> </ol> <p>Note: Replace the placeholder values with your actual DSQL cluster endpoint, username, and region.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/","title":"AWS Bedrock Data Automation MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon Bedrock Data Automation that enables AI assistants to analyze documents, images, videos, and audio files using Amazon Bedrock Data Automation projects.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#features","title":"Features","text":"<ul> <li>Project Management: List and get details about Bedrock Data Automation projects</li> <li>Asset Analysis: Extract insights from unstructured content using Bedrock Data Automation</li> <li>Support for Multiple Content Types: Process documents, images, videos, and audio files</li> <li>Integration with Amazon S3: Seamlessly upload and download assets and results</li> </ul>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to Amazon Bedrock Data Automation</li> <li>You need an AWS account with Amazon Bedrock Data Automation enabled</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to use Amazon Bedrock Data Automation</li> <li>Create an AWS S3 Bucket</li> <li>Example AWS CLI command to create the bucket</li> <li><code>bash       aws s3 create-bucket &lt;bucket-name&gt;</code></li> </ol>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"bedrock-data-automation-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-bedrock-data-automation-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"AWS_BUCKET_NAME\": \"your-s3-bucket-name\",\n        \"BASE_DIR\": \"/path/to/base/directory\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/aws-bedrock-data-automation-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"bedrock-data-automation-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"AWS_PROFILE\",\n        \"--env\",\n        \"AWS_REGION\",\n        \"--env\",\n        \"AWS_BUCKET_NAME\",\n        \"--env\",\n        \"BASE_DIR\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL\",\n        \"awslabs/aws-bedrock-data-automation-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"AWS_BUCKET_NAME\": \"your-s3-bucket-name\",\n        \"BASE_DIR\": \"/path/to/base/directory\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>AWS_PROFILE</code>: AWS CLI profile to use for credentials</li> <li><code>AWS_REGION</code>: AWS region to use (default: us-east-1)</li> <li><code>AWS_BUCKET_NAME</code>: S3 bucket name for storing assets and results</li> <li><code>BASE_DIR</code>: Base directory for file operations (optional)</li> <li><code>FASTMCP_LOG_LEVEL</code>: Logging level (ERROR, WARNING, INFO, DEBUG)</li> </ul>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the default credential provider chain.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\",\n  \"AWS_REGION\": \"us-east-1\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access Amazon Bedrock Data Automation services. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Amazon Bedrock Data Automation services is currently available in the following regions: us-east-1 and us-west-2.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/aws-bedrock-data-automation-mcp-server/#getprojects","title":"getprojects","text":"<p>Get a list of data automation projects.</p> <pre><code>getprojects() -&gt; list\n</code></pre> <p>Returns a list of available Bedrock Data Automation projects.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#getprojectdetails","title":"getprojectdetails","text":"<p>Get details of a specific data automation project.</p> <pre><code>getprojectdetails(projectArn: str) -&gt; dict\n</code></pre> <p>Returns detailed information about a specific Bedrock Data Automation project.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#analyzeasset","title":"analyzeasset","text":"<p>Analyze an asset using a data automation project.</p> <pre><code>analyzeasset(assetPath: str, projectArn: Optional[str] = None) -&gt; dict\n</code></pre> <p>Extracts insights from unstructured content (documents, images, videos, audio) using Amazon Bedrock Data Automation.</p> <ul> <li><code>assetPath</code>: Path to the asset file to analyze</li> <li><code>projectArn</code>: ARN of the Bedrock Data Automation project to use (optional, uses default public project if not provided)</li> </ul>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#example-usage","title":"Example Usage","text":"<pre><code># List available projects\nprojects = await getprojects()\n\n# Get details of a specific project\nproject_details = await getprojectdetails(projectArn=\"arn:aws:bedrock:us-east-1:123456789012:data-automation-project/my-project\")\n\n# Analyze a document\nresults = await analyzeasset(assetPath=\"/path/to/document.pdf\")\n\n# Analyze an image with a specific project\nresults = await analyzeasset(\n    assetPath=\"/path/to/image.jpg\",\n    projectArn=\"arn:aws:bedrock:us-east-1:123456789012:data-automation-project/my-project\"\n)\n</code></pre>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#security-considerations","title":"Security Considerations","text":"<ul> <li>Use AWS IAM roles with appropriate permissions</li> <li>Store credentials securely</li> <li>Use temporary credentials when possible</li> <li>Ensure S3 bucket permissions are properly configured</li> </ul>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License, Version 2.0. See the LICENSE file for details.</p>"},{"location":"servers/aws-dataprocessing-mcp-server/","title":"Amazon Data Processing MCP Server","text":"<p>The AWS DataProcessing MCP server provides AI code assistants with comprehensive data processing tools and real-time pipeline visibility across AWS Glue and Amazon EMR-EC2. This integration equips large language models (LLMs) with essential data engineering capabilities and contextual awareness, enabling AI code assistants to streamline data processing workflows through intelligent guidance \u2014 from initial data discovery and cataloging through complex ETL pipeline orchestration and big data analytics optimization.</p> <p>Integrating the DataProcessing MCP server into AI code assistants transforms data engineering workflows across all phases, from simplifying data catalog management with automated schema discovery and data quality validation. Additionally, it streamlines ETL job creation with intelligent code generation and best practice recommendations. It accelerates big data processing through automated EMR cluster provisioning and workload optimization. Finally, it enhances troubleshooting through intelligent debugging tools and operational insights. All of this simplifies complex data operations through natural language interactions in AI code assistants.</p>"},{"location":"servers/aws-dataprocessing-mcp-server/#key-features","title":"Key features","text":""},{"location":"servers/aws-dataprocessing-mcp-server/#aws-glue-integration","title":"AWS Glue Integration","text":"<ul> <li>Data Catalog Management: Enables users to explore, create, and manage databases, tables, and partitions through natural language requests, automatically translating them into appropriate AWS Glue Data Catalog operations.</li> <li>Interactive Sessions: Provides interactive development environment for Spark and Ray workloads, enabling data exploration, debugging, and iterative development through managed Jupyter-like sessions.</li> <li>Workflows and Triggers: Orchestrates complex ETL activities through visual workflows and automated triggers, supporting scheduled, conditional, and event-based execution patterns.</li> <li>Commons: Enables users to create and manage usage profiles, security configurations, catalog encryption settings and resource policies, which provide users with the ability to manage the configuration and encryption of several Glue resources like ETL jobs, catalogs, etc.</li> <li>ETL Job Orchestration: Provides the ability to create, monitor, and manage Glue ETL jobs with automatic script generation, job scheduling, and workflow coordination based on user-defined data transformation requirements.</li> <li>Crawler Management: Enables intelligent data discovery through automated crawler configuration, scheduling, and metadata extraction from various data sources.</li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#amazon-emr-integration","title":"Amazon EMR Integration","text":"<ul> <li>Cluster Management: Enables users to create, configure, monitor, and terminate EMR clusters with comprehensive control over instance types, applications, and configurations through natural language requests.</li> <li>Instance Management: Provides the ability to add, modify, and monitor instance fleets and instance groups within EMR clusters, supporting both on-demand and spot instances with auto-scaling capabilities.</li> <li>Step Execution: Orchestrates data processing workflows through EMR steps, allowing users to submit, monitor, and manage Hadoop, Spark, and other application jobs on running clusters.</li> <li>Security Configuration: Manages EMR security settings including encryption, authentication, and authorization policies to ensure secure data processing environments.</li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#amazon-athena-integration","title":"Amazon Athena Integration","text":"<ul> <li>Query Execution: Enables users to execute, monitor, and manage SQL queries with comprehensive control over query lifecycle, including starting queries, retrieving results, monitoring performance statistics, and canceling running queries through natural language requests.</li> <li>Named Query Management: Provides the ability to create, update, retrieve, and delete saved SQL queries, enabling users to build reusable query libraries with proper organization and team collaboration capabilities.</li> <li>Data Catalog Operations: Manages Athena data catalogs with support for multiple catalog types (LAMBDA, GLUE, HIVE, FEDERATED), enabling users to create, configure, and maintain data source connections for cross-platform querying.</li> <li>Database and Table Discovery: Facilitates data exploration through comprehensive database and table metadata retrieval, allowing users to discover available data sources, understand schema structures, and navigate data catalogs efficiently.</li> <li>Workgroup Administration: Orchestrates query execution environments through workgroup management, providing cost control, access management, and query result configuration with support for different user groups and organizational policies.</li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install Python 3.10+</li> <li>Install the <code>uv</code> package manager</li> <li>Install and configure the AWS CLI with credentials</li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#setup","title":"Setup","text":"<p>Add these IAM policies to the IAM role or user that you use to manage your Glue, EMR-EC2 or Athena resources.</p>"},{"location":"servers/aws-dataprocessing-mcp-server/#read-only-operations-policy","title":"Read-Only Operations Policy","text":"<p>For read operations, the following permissions are required:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"glue:GetDatabase*\",\n        \"glue:GetTable*\",\n        \"glue:GetPartition*\",\n        \"glue:GetCrawler*\",\n        \"glue:GetConnection*\",\n        \"glue:GetDatabases\",\n        \"glue:GetTables\",\n        \"glue:ListCrawlers\",\n        \"glue:SearchTables\",\n        \"glue:GetJobRun\",\n        \"glue:GetJobRuns\",\n        \"glue:GetJob\",\n        \"glue:GetJobs\",\n        \"glue:GetJobBookmark\",\n        \"glue:GetUsageProfile\",\n        \"glue:GetSecurityConfiguration\",\n        \"glue:GetDataCatalogEncryptionSettings\",\n        \"glue:GetResourcePolicy\",\n        \"glue:GetSession\",\n        \"glue:ListSessions\",\n        \"glue:GetStatement\",\n        \"glue:ListStatements\",\n        \"glue:GetSession\",\n        \"glue:ListSessions\",\n        \"glue:GetStatement\",\n        \"glue:ListStatements\",\n        \"glue:GetWorkflow\",\n        \"glue:ListWorkflows\",\n        \"glue:GetTrigger\",\n        \"glue:GetTriggers\",\n        \"cloudwatch:GetMetricData\",\n        \"logs:DescribeLogGroups\",\n        \"logs:DescribeLogStreams\",\n        \"emr:DescribeCluster\",\n        \"emr:ListClusters\",\n        \"emr:DescribeStep\",\n        \"emr:ListSteps\",\n        \"emr:ListInstances\",\n        \"emr:GetManagedScalingPolicy\",\n        \"emr:DescribeStudio\",\n        \"emr:ListStudios\",\n        \"emr:DescribeNotebookExecution\",\n        \"emr:ListNotebookExecutions\",\n        \"athena:BatchGetQueryExecution\",\n        \"athena:GetQueryExecution\",\n        \"athena:GetQueryResults\",\n        \"athena:GetQueryRuntimeStatistics\",\n        \"athena:ListQueryExecutions\",\n        \"athena:BatchGetNamedQuery\",\n        \"athena:GetNamedQuery\",\n        \"athena:ListNamedQueries\",\n        \"athena:GetDataCatalog\",\n        \"athena:ListDataCatalogs\",\n        \"athena:GetDatabase\",\n        \"athena:GetTableMetadata\",\n        \"athena:ListDatabases\",\n        \"athena:ListTableMetadata\",\n        \"athena:GetWorkGroup\",\n        \"athena:ListWorkGroups\"\n        \"sts:GetCallerIdentity\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"servers/aws-dataprocessing-mcp-server/#write-operations-policy","title":"Write Operations Policy","text":"<p>For write operations, we recommend the following IAM policies:</p> <ul> <li>AWSGlueServiceRole: Enables Glue service operations including job execution, crawler runs, and data catalog modifications</li> </ul> <p>Important Security Note: Users should exercise caution when --allow-write and --allow-sensitive-data-access modes are enabled with these broad permissions, as this combination grants significant privileges to the MCP server. Only enable these flags when necessary and in trusted environments.</p> <p>Resource Management Limitation: The DataProcessing MCP Server can only update or delete resources that were originally created through it. Resources created by other means cannot be modified or deleted using the DataProcessing MCP Server.</p>"},{"location":"servers/aws-dataprocessing-mcp-server/#quickstart","title":"Quickstart","text":"<p>This quickstart guide walks you through the steps to configure the Amazon Data Processing MCP Server for use with both the Cursor IDE and the Amazon Q Developer CLI. By following these steps, you'll setup your development environment to leverage the Data Processing MCP Server's tools for managing your Glue, EMR and Athena resources.</p> <p>Set up Cursor</p> <ol> <li>Open Cursor.</li> <li>Click the gear icon (\u2699\ufe0f) in the top right to open the settings panel, click MCP, Add new global MCP server.</li> <li>Paste your MCP server definition. For example, this example shows how to configure the Data Processing MCP Server, including enabling mutating actions by adding the <code>--allow-write</code> flag to the server arguments:</li> </ol> <p><pre><code>{\n  \"mcpServers\": {\n    \"aws.aws-dataprocessing-mcp-server\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"command\": \"uvx\",\n      \"args\": [\n        \"aws.aws-dataprocessing-mcp-server@latest\",\n        \"--allow-write\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_REGION\": \"us-east-1\"\n      },\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n</code></pre> After a few minutes, you should see a green indicator if your MCP server definition is valid.</p> <ol> <li>Open a chat panel in Cursor (e.g., <code>Ctrl/\u2318 + L</code>).  In your Cursor chat window, enter your prompt. For example, \"Look at all the tables from my account federated across GDC\"</li> </ol> <p>Set up the Amazon Q Developer CLI</p> <ol> <li>Install the Amazon Q Developer CLI .</li> <li>The Q Developer CLI supports MCP servers for tools and prompts out-of-the-box. Edit your Q developer CLI's MCP configuration file named mcp.json following these instructions. For example:</li> </ol> <pre><code>{\n  \"mcpServers\": {\n    \"aws.aws-dataprocessing-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"aws.aws-dataprocessing-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <ol> <li>Verify your setup by running the <code>/tools</code> command in the Q Developer CLI to see the available Data Processing MCP tools.</li> </ol> <p>Note that this is a basic quickstart. You can enable additional capabilities, such as running MCP servers in containers or combining more MCP servers like the AWS Documentation MCP Server into a single MCP server definition. To view an example, see the Installation and Setup guide in AWS MCP Servers on GitHub. To view a real-world implementation with application code in context with an MCP server, see the Server Developer guide in Anthropic documentation.</p>"},{"location":"servers/aws-dataprocessing-mcp-server/#configurations","title":"Configurations","text":""},{"location":"servers/aws-dataprocessing-mcp-server/#arguments","title":"Arguments","text":"<p>The <code>args</code> field in the MCP server definition specifies the command-line arguments passed to the server when it starts. These arguments control how the server is executed and configured. For example:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-dataprocessing-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"aws.aws-dataprocessing-mcp-server@latest\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-dataprocessing-mcp-server/#awslabsaws-dataprocessing-mcp-serverlatest-required","title":"<code>awslabs.aws-dataprocessing-mcp-server@latest</code> (required)","text":"<p>Specifies the latest package/version specifier for the MCP client config.</p> <ul> <li>Enables MCP server startup and tool registration.</li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#-allow-write-optional","title":"<code>--allow-write</code> (optional)","text":"<p>Enables write access mode, which allows mutating operations (e.g., create, update, delete resources)</p> <ul> <li>Default: false (The server runs in read-only mode by default)</li> <li>Example: Add <code>--allow-write</code> to the <code>args</code> list in your MCP server definition.</li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#-allow-sensitive-data-access-optional","title":"<code>--allow-sensitive-data-access</code> (optional)","text":"<p>Enables access to sensitive data such as logs, events, and Kubernetes Secrets.</p> <ul> <li>Default: false (Access to sensitive data is restricted by default)</li> <li>Example: Add <code>--allow-sensitive-data-access</code> to the <code>args</code> list in your MCP server definition.</li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#environment-variables","title":"Environment variables","text":"<p>The <code>env</code> field in the MCP server definition allows you to configure environment variables that control the behavior of the DataProcessing MCP server.  For example:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-dataprocessing-mcp-server\": {\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"my-profile\",\n        \"AWS_REGION\": \"us-west-2\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-dataprocessing-mcp-server/#fastmcp_log_level-optional","title":"<code>FASTMCP_LOG_LEVEL</code> (optional)","text":"<p>Sets the logging level verbosity for the server.</p> <ul> <li>Valid values: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"</li> <li>Default: \"WARNING\"</li> <li>Example: <code>\"FASTMCP_LOG_LEVEL\": \"ERROR\"</code></li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#aws_profile-optional","title":"<code>AWS_PROFILE</code> (optional)","text":"<p>Specifies the AWS profile to use for authentication.</p> <ul> <li>Default: None (If not set, uses default AWS credentials).</li> <li>Example: <code>\"AWS_PROFILE\": \"my-profile\"</code></li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#aws_region-optional","title":"<code>AWS_REGION</code> (optional)","text":"<p>Specifies the AWS region where Glue,EMR clusters or Athena are managed, which will be used for all AWS service operations.</p> <ul> <li>Default: None (If not set, uses default AWS region).</li> <li>Example: <code>\"AWS_REGION\": \"us-west-2\"</code></li> </ul>"},{"location":"servers/aws-dataprocessing-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/aws-dataprocessing-mcp-server/#glue-data-catalog-handler-tools","title":"Glue Data Catalog Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_glue_databases Manage AWS Glue Data Catalog databases create-database, delete-database, get-database, list-databases, update-database --allow-write flag for create/delete/update operations, appropriate AWS permissions manage_aws_glue_tables Manage AWS Glue Data Catalog tables create-table, delete-table, get-table, list-tables, update-table, search-tables --allow-write flag for create/delete/update operations, database must exist, appropriate AWS permissions manage_aws_glue_connections Manage AWS Glue Data Catalog connections create-connection, delete-connection, get-connection, list-connections, update-connection --allow-write flag for create/delete/update operations, appropriate AWS permissions manage_aws_glue_partitions Manage AWS Glue Data Catalog partitions create-partition, delete-partition, get-partition, list-partitions, update-partition --allow-write flag for create/delete/update operations, database and table must exist, appropriate AWS permissions manage_aws_glue_catalog Manage AWS Glue Data Catalog create-catalog, delete-catalog, get-catalog, list-catalogs, import-catalog-to-glue --allow-write flag for create/delete/import operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#glue-interactive-sessions-handler-tools","title":"Glue Interactive Sessions Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_glue_sessions Manage AWS Glue Interactive Sessions for Spark and Ray workloads create-session, delete-session, get-session, list-sessions, stop-session --allow-write flag for create/delete/stop operations, appropriate AWS permissions manage_aws_glue_statements Execute and manage code statements within Glue Interactive Sessions run-statement, cancel-statement, get-statement, list-statements --allow-write flag for run/cancel operations, active session required"},{"location":"servers/aws-dataprocessing-mcp-server/#glue-workflows-and-triggers-handler-tools","title":"Glue Workflows and Triggers Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_glue_workflows Orchestrate complex ETL activities through visual workflows create-workflow, delete-workflow, get-workflow, list-workflows, start-workflow-run --allow-write flag for create/delete/start operations, appropriate AWS permissions manage_aws_glue_triggers Automate workflow and job execution with scheduled or event-based triggers create-trigger, delete-trigger, get-trigger, get-triggers, start-trigger, stop-trigger --allow-write flag for create/delete/start/stop operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#emr-cluster-handler-tools","title":"EMR Cluster Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_emr_clusters Manage Amazon EMR clusters with comprehensive control over cluster lifecycle create-cluster, describe-cluster, modify-cluster, modify-cluster-attributes, terminate-clusters, list-clusters, create-security-configuration, delete-security-configuration, describe-security-configuration, list-security-configurations --allow-write flag for create/modify/terminate operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#emr-instance-handler-tools","title":"EMR Instance Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_emr_ec2_instances Manage Amazon EMR EC2 instances with both read and write operations add-instance-fleet, add-instance-groups, modify-instance-fleet, modify-instance-groups, list-instance-fleets, list-instances, list-supported-instance-types --allow-write flag for add/modify operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#emr-steps-handler-tools","title":"EMR Steps Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_emr_ec2_steps Manage Amazon EMR steps for processing data on EMR clusters add-steps, cancel-steps, describe-step, list-steps --allow-write flag for add/cancel operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#athena-query-handler-tools","title":"Athena Query Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_athena_query_executions Execute and manage AWS Athena SQL queries batch-get-query-execution, get-query-execution, get-query-results, get-query-runtime-statistics, list-query-executions, start-query-execution, stop-query-execution --allow-write flag for start/stop operations, appropriate AWS permissions manage_aws_athena_named_queries Manage saved SQL queries in AWS Athena batch-get-named-query, create-named-query, delete-named-query, get-named-query, list-named-queries, update-named-query --allow-write flag for create/delete/update operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#athena-data-catalog-handler-tools","title":"Athena Data Catalog Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_athena_data_catalogs Manage AWS Athena data catalogs create-data-catalog, delete-data-catalog, get-data-catalog, list-data-catalogs, update-data-catalog --allow-write flag for create/delete/update operations, appropriate AWS permissions manage_aws_athena_databases_and_tables Manage AWS Athena databases and tables get-database, get-table-metadata, list-databases, list-table-metadata Appropriate AWS permissions for Athena database operations"},{"location":"servers/aws-dataprocessing-mcp-server/#athena-workgroup-handler-tools","title":"Athena WorkGroup Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_athena_workgroups Manage AWS Athena workgroups create-work-group, delete-work-group, get-work-group, list-work-groups, update-work-group --allow-write flag for create/delete/update operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#glue-commons-handler-tools","title":"Glue Commons Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_glue_usage_profiles Manage AWS Glue Usage Profiles for resource allocation and cost management create-profile, delete-profile, get-profile, update-profile --allow-write flag for create/delete/update operations, appropriate AWS permissions manage_aws_glue_security_configurations Manage AWS Glue Security Configurations for data encryption create-security-configuration, delete-security-configuration, get-security-configuration --allow-write flag for create/delete operations, appropriate AWS permissions manage_aws_glue_encryption Manage AWS Glue catalog encryption settings get-catalog-encryption-settings, put-catalog-encryption-settings --allow-write flag for put operations, appropriate AWS permissions manage_aws_glue_resource_policies Manage resource policies for AWS Glue catalogs, databases and tables get-resource-policy, put-resource-policy, delete-resource-policy --allow-write flag for put/delete operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#glue-etl-handler-tools","title":"Glue ETL Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_glue_jobs Manage AWS Glue ETL jobs and job runs create-job, delete-job, get-job, get-jobs, update-job, start-job-run, stop-job-run, get-job-run, get-job-runs, batch-stop-job-run, get-job-bookmark, reset-job-bookmark --allow-write flag for create/delete/update/start/stop operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#glue-crawler-handler-tools","title":"Glue Crawler Handler Tools","text":"Tool Name Description Key Operations Requirements manage_aws_glue_crawlers Manage AWS Glue crawlers to discover and catalog data sources create-crawler, delete-crawler, get-crawler, get-crawlers, start-crawler, stop-crawler, batch-get-crawlers, list-crawlers, update-crawler --allow-write flag for create/delete/start/stop/update operations, appropriate AWS permissions manage_aws_glue_classifiers Manage AWS Glue classifiers to determine data formats and schemas create-classifier, delete-classifier, get-classifier, get-classifiers, update-classifier --allow-write flag for create/delete/update operations, appropriate AWS permissions manage_aws_glue_crawler_management Manage AWS Glue crawler schedules and monitor performance metrics get-crawler-metrics, start-crawler-schedule, stop-crawler-schedule, update-crawler-schedule --allow-write flag for schedule operations, appropriate AWS permissions"},{"location":"servers/aws-dataprocessing-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 0.1.0</p>"},{"location":"servers/aws-diagram-mcp-server/","title":"AWS Diagram MCP Server","text":"<p>Model Context Protocol (MCP) server for AWS Diagrams</p> <p>This MCP server that seamlessly creates diagrams using the Python diagrams package DSL. This server allows you to generate AWS diagrams, sequence diagrams, flow diagrams, and class diagrams using Python code.</p> <p></p>"},{"location":"servers/aws-diagram-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install GraphViz https://www.graphviz.org/</li> </ol>"},{"location":"servers/aws-diagram-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-diagram-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-diagram-mcp-server\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/aws-diagram-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.aws-diagram-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/aws-diagram-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/aws-diagram-mcp-server/#features","title":"Features","text":"<p>The Diagrams MCP Server provides the following capabilities:</p> <ol> <li>Generate Diagrams: Create professional diagrams using Python code</li> <li>Multiple Diagram Types: Support for AWS architecture, sequence diagrams, flow charts, class diagrams, and more</li> <li>Customization: Customize diagram appearance, layout, and styling</li> <li>Security: Code scanning to ensure secure diagram generation</li> </ol>"},{"location":"servers/aws-diagram-mcp-server/#quick-example","title":"Quick Example","text":"<pre><code>from diagrams import Diagram\nfrom diagrams.aws.compute import Lambda\nfrom diagrams.aws.database import Dynamodb\nfrom diagrams.aws.network import APIGateway\n\nwith Diagram(\"Serverless Application\", show=False):\n    api = APIGateway(\"API Gateway\")\n    function = Lambda(\"Function\")\n    database = Dynamodb(\"DynamoDB\")\n\n    api &gt;&gt; function &gt;&gt; database\n</code></pre>"},{"location":"servers/aws-diagram-mcp-server/#development","title":"Development","text":""},{"location":"servers/aws-diagram-mcp-server/#testing","title":"Testing","text":"<p>The project includes a comprehensive test suite to ensure the functionality of the MCP server. The tests are organized by module and cover all aspects of the server's functionality.</p> <p>To run the tests, use the provided script:</p> <pre><code>./run_tests.sh\n</code></pre> <p>This script will automatically install pytest and its dependencies if they're not already installed.</p> <p>Or run pytest directly (if you have pytest installed):</p> <pre><code>pytest -xvs tests/\n</code></pre> <p>To run with coverage:</p> <pre><code>pytest --cov=awslabs.aws_diagram_mcp_server --cov-report=term-missing tests/\n</code></pre> <p>For more information about the tests, see the tests README.</p>"},{"location":"servers/aws-diagram-mcp-server/#development-dependencies","title":"Development Dependencies","text":"<p>To set up the development environment, install the development dependencies:</p> <pre><code>uv pip install -e \".[dev]\"\n</code></pre> <p>This will install the required dependencies for development, including pytest, pytest-asyncio, and pytest-cov.</p>"},{"location":"servers/aws-documentation-mcp-server/","title":"AWS Documentation MCP Server","text":"<p>Model Context Protocol (MCP) server for AWS Documentation</p> <p>This MCP server provides tools to access AWS documentation, search for content, and get recommendations.</p>"},{"location":"servers/aws-documentation-mcp-server/#features","title":"Features","text":"<ul> <li>Read Documentation: Fetch and convert AWS documentation pages to markdown format</li> <li>Search Documentation: Search AWS documentation using the official search API (global only)</li> <li>Recommendations: Get content recommendations for AWS documentation pages (global only)</li> <li>Get Available Services List: Get a list of available AWS services in China regions (China only)</li> </ul>"},{"location":"servers/aws-documentation-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/aws-documentation-mcp-server/#installation-requirements","title":"Installation Requirements","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python 3.10 or newer using <code>uv python install 3.10</code> (or a more recent version)</li> </ol>"},{"location":"servers/aws-documentation-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-documentation-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-documentation-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_DOCUMENTATION_PARTITION\": \"aws\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>Note: Set <code>AWS_DOCUMENTATION_PARTITION</code> to <code>aws-cn</code> to query AWS China documentation instead of global AWS documentation.</p> <p>or docker after a successful <code>docker build -t mcp/aws-documentation .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-documentation-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"AWS_DOCUMENTATION_PARTITION=aws\",\n        \"mcp/aws-documentation:latest\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-documentation-mcp-server/#basic-usage","title":"Basic Usage","text":"<p>Example:</p> <ul> <li>\"look up documentation on S3 bucket naming rule. cite your sources\"</li> <li>\"recommend content for page https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html\"</li> </ul> <p></p>"},{"location":"servers/aws-documentation-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/aws-documentation-mcp-server/#read_documentation","title":"read_documentation","text":"<p>Fetches an AWS documentation page and converts it to markdown format.</p> <pre><code>read_documentation(url: str) -&gt; str\n</code></pre>"},{"location":"servers/aws-documentation-mcp-server/#search_documentation-global-only","title":"search_documentation (global only)","text":"<p>Searches AWS documentation using the official AWS Documentation Search API.</p> <pre><code>search_documentation(search_phrase: str, limit: int) -&gt; list[dict]\n</code></pre>"},{"location":"servers/aws-documentation-mcp-server/#recommend-global-only","title":"recommend (global only)","text":"<p>Gets content recommendations for an AWS documentation page.</p> <pre><code>recommend(url: str) -&gt; list[dict]\n</code></pre>"},{"location":"servers/aws-documentation-mcp-server/#get_available_services-china-only","title":"get_available_services (China only)","text":"<p>Gets a list of available AWS services in China regions.</p> <pre><code>get_available_services() -&gt; str\n</code></pre>"},{"location":"servers/aws-healthomics-mcp-server/","title":"AWS HealthOmics MCP Server","text":"<p>A Model Context Protocol (MCP) server that provides AI assistants with comprehensive access to AWS HealthOmics services for genomic workflow management, execution, and analysis.</p>"},{"location":"servers/aws-healthomics-mcp-server/#overview","title":"Overview","text":"<p>AWS HealthOmics is a purpose-built service for storing, querying, and analyzing genomic, transcriptomic, and other omics data. This MCP server enables AI assistants to interact with HealthOmics workflows through natural language, making genomic data analysis more accessible and efficient.</p>"},{"location":"servers/aws-healthomics-mcp-server/#key-capabilities","title":"Key Capabilities","text":"<p>This MCP server provides tools for:</p>"},{"location":"servers/aws-healthomics-mcp-server/#workflow-management","title":"\ud83e\uddec Workflow Management","text":"<ul> <li>Create and validate workflows: Support for WDL, CWL, and Nextflow workflow languages</li> <li>Version management: Create and manage workflow versions with different configurations</li> <li>Package workflows: Bundle workflow definitions into deployable packages</li> </ul>"},{"location":"servers/aws-healthomics-mcp-server/#workflow-execution","title":"\ud83d\ude80 Workflow Execution","text":"<ul> <li>Start and monitor runs: Execute workflows with custom parameters and monitor progress</li> <li>Task management: Track individual workflow tasks and their execution status</li> <li>Resource configuration: Configure compute resources, storage, and caching options</li> </ul>"},{"location":"servers/aws-healthomics-mcp-server/#analysis-and-troubleshooting","title":"\ud83d\udcca Analysis and Troubleshooting","text":"<ul> <li>Performance analysis: Analyze workflow execution performance and resource utilization</li> <li>Failure diagnosis: Comprehensive troubleshooting tools for failed workflow runs</li> <li>Log access: Retrieve detailed logs from runs, engines, tasks, and manifests</li> </ul>"},{"location":"servers/aws-healthomics-mcp-server/#region-management","title":"\ud83c\udf0d Region Management","text":"<ul> <li>Multi-region support: Get information about AWS regions where HealthOmics is available</li> </ul>"},{"location":"servers/aws-healthomics-mcp-server/#available-tools","title":"Available Tools","text":""},{"location":"servers/aws-healthomics-mcp-server/#workflow-management-tools","title":"Workflow Management Tools","text":"<ol> <li>ListAHOWorkflows - List available HealthOmics workflows with pagination support</li> <li>CreateAHOWorkflow - Create new workflows with WDL, CWL, or Nextflow definitions</li> <li>GetAHOWorkflow - Retrieve detailed workflow information and export definitions</li> <li>CreateAHOWorkflowVersion - Create new versions of existing workflows</li> <li>ListAHOWorkflowVersions - List all versions of a specific workflow</li> <li>PackageAHOWorkflow - Package workflow files into base64-encoded ZIP format</li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#workflow-execution-tools","title":"Workflow Execution Tools","text":"<ol> <li>StartAHORun - Start workflow runs with custom parameters and resource configuration</li> <li>ListAHORuns - List workflow runs with filtering by status and date ranges</li> <li>GetAHORun - Retrieve detailed run information including status and metadata</li> <li>ListAHORunTasks - List tasks for specific runs with status filtering</li> <li>GetAHORunTask - Get detailed information about specific workflow tasks</li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#analysis-and-troubleshooting-tools","title":"Analysis and Troubleshooting Tools","text":"<ol> <li>AnalyzeAHORunPerformance - Analyze workflow run performance and resource utilization</li> <li>DiagnoseAHORunFailure - Comprehensive diagnosis of failed workflow runs with remediation suggestions</li> <li>GetAHORunLogs - Access high-level workflow execution logs and events</li> <li>GetAHORunEngineLogs - Retrieve workflow engine logs (STDOUT/STDERR) for debugging</li> <li>GetAHORunManifestLogs - Access run manifest logs with runtime information and metrics</li> <li>GetAHOTaskLogs - Get task-specific logs for debugging individual workflow steps</li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#region-management-tools","title":"Region Management Tools","text":"<ol> <li>GetAHOSupportedRegions - List AWS regions where HealthOmics is available</li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#instructions-for-ai-assistants","title":"Instructions for AI Assistants","text":"<p>This MCP server enables AI assistants to help users with AWS HealthOmics genomic workflow management. Here's how to effectively use these tools:</p>"},{"location":"servers/aws-healthomics-mcp-server/#understanding-aws-healthomics","title":"Understanding AWS HealthOmics","text":"<p>AWS HealthOmics is designed for genomic data analysis workflows. Key concepts:</p> <ul> <li>Workflows: Computational pipelines written in WDL, CWL, or Nextflow that process genomic data</li> <li>Runs: Executions of workflows with specific input parameters and data</li> <li>Tasks: Individual steps within a workflow run</li> <li>Storage Types: STATIC (fixed storage) or DYNAMIC (auto-scaling storage)</li> </ul>"},{"location":"servers/aws-healthomics-mcp-server/#workflow-management-best-practices","title":"Workflow Management Best Practices","text":"<ol> <li>Creating Workflows:</li> <li>Use <code>PackageAHOWorkflow</code> to bundle workflow files before creating</li> <li>Validate workflows with appropriate language syntax (WDL, CWL, Nextflow)</li> <li> <p>Include parameter templates to guide users on required inputs</p> </li> <li> <p>Version Management:</p> </li> <li>Create new versions for workflow updates rather than modifying existing ones</li> <li>Use descriptive version names that indicate changes or improvements</li> <li>List versions to help users choose the appropriate one</li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#workflow-execution-guidance","title":"Workflow Execution Guidance","text":"<ol> <li>Starting Runs:</li> <li>Always specify required parameters: workflow_id, role_arn, name, output_uri</li> <li>Choose appropriate storage type (DYNAMIC recommended for most cases)</li> <li>Use meaningful run names for easy identification</li> <li> <p>Configure caching when appropriate to save costs and time</p> </li> <li> <p>Monitoring Runs:</p> </li> <li>Use <code>ListAHORuns</code> with status filters to track active workflows</li> <li>Check individual run details with <code>GetAHORun</code> for comprehensive status</li> <li>Monitor tasks with <code>ListAHORunTasks</code> to identify bottlenecks</li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#troubleshooting-failed-runs","title":"Troubleshooting Failed Runs","text":"<p>When workflows fail, follow this diagnostic approach:</p> <ol> <li>Start with DiagnoseAHORunFailure: This comprehensive tool provides:</li> <li>Failure reasons and error analysis</li> <li>Failed task identification</li> <li>Log summaries and recommendations</li> <li> <p>Actionable troubleshooting steps</p> </li> <li> <p>Access Specific Logs:</p> </li> <li>Run Logs: High-level workflow events and status changes</li> <li>Engine Logs: Workflow engine STDOUT/STDERR for system-level issues</li> <li>Task Logs: Individual task execution details for specific failures</li> <li> <p>Manifest Logs: Resource utilization and workflow summary information</p> </li> <li> <p>Performance Analysis:</p> </li> <li>Use <code>AnalyzeAHORunPerformance</code> to identify resource bottlenecks</li> <li>Review task resource utilization patterns</li> <li>Optimize workflow parameters based on analysis results</li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#common-use-cases","title":"Common Use Cases","text":"<ol> <li> <p>Workflow Development:    <pre><code>User: \"Help me create a new genomic variant calling workflow\"\n\u2192 Use CreateAHOWorkflow with WDL/CWL/Nextflow definition\n\u2192 Package workflow files appropriately\n\u2192 Validate syntax and parameters\n</code></pre></p> </li> <li> <p>Production Execution:    <pre><code>User: \"Run my alignment workflow on these FASTQ files\"\n\u2192 Use StartAHORun with appropriate parameters\n\u2192 Monitor with ListAHORuns and GetAHORun\n\u2192 Track task progress with ListAHORunTasks\n</code></pre></p> </li> <li> <p>Troubleshooting:    <pre><code>User: \"My workflow failed, what went wrong?\"\n\u2192 Use DiagnoseAHORunFailure for comprehensive analysis\n\u2192 Access specific logs based on failure type\n\u2192 Provide actionable remediation steps\n</code></pre></p> </li> <li> <p>Performance Optimization:    <pre><code>User: \"How can I make my workflow run faster?\"\n\u2192 Use AnalyzeAHORunPerformance to identify bottlenecks\n\u2192 Review resource utilization patterns\n\u2192 Suggest optimization strategies\n</code></pre></p> </li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#important-considerations","title":"Important Considerations","text":"<ul> <li>IAM Permissions: Ensure proper IAM roles with HealthOmics permissions</li> <li>Regional Availability: Use <code>GetAHOSupportedRegions</code> to verify service availability</li> <li>Cost Management: Monitor storage and compute costs, especially with STATIC storage</li> <li>Data Security: Follow genomic data handling best practices and compliance requirements</li> <li>Resource Limits: Be aware of service quotas and limits for concurrent runs</li> </ul>"},{"location":"servers/aws-healthomics-mcp-server/#error-handling","title":"Error Handling","text":"<p>When tools return errors: - Check AWS credentials and permissions - Verify resource IDs (workflow_id, run_id, task_id) are valid - Ensure proper parameter formatting and required fields - Use diagnostic tools to understand failure root causes - Provide clear, actionable error messages to users</p>"},{"location":"servers/aws-healthomics-mcp-server/#installation","title":"Installation","text":"<p>Install using uvx:</p> <pre><code>uvx awslabs.aws-healthomics-mcp-server\n</code></pre> <p>Or install from source:</p> <pre><code>git clone &lt;repository-url&gt;\ncd mcp/src/aws-healthomics-mcp-server\nuv sync\nuv run server.py\n</code></pre>"},{"location":"servers/aws-healthomics-mcp-server/#configuration","title":"Configuration","text":""},{"location":"servers/aws-healthomics-mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>AWS_REGION</code> - AWS region for HealthOmics operations (default: us-east-1)</li> <li><code>AWS_PROFILE</code> - AWS profile for authentication</li> <li><code>FASTMCP_LOG_LEVEL</code> - Server logging level (default: WARNING)</li> </ul>"},{"location":"servers/aws-healthomics-mcp-server/#aws-credentials","title":"AWS Credentials","text":"<p>This server requires AWS credentials with appropriate permissions for HealthOmics operations. Configure using:</p> <ol> <li>AWS CLI: <code>aws configure</code></li> <li>Environment variables: <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code></li> <li>IAM roles (recommended for EC2/Lambda)</li> <li>AWS profiles: Set <code>AWS_PROFILE</code> environment variable</li> </ol>"},{"location":"servers/aws-healthomics-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<p>The following IAM permissions are required:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"omics:ListWorkflows\",\n                \"omics:CreateWorkflow\",\n                \"omics:GetWorkflow\",\n                \"omics:CreateWorkflowVersion\",\n                \"omics:ListWorkflowVersions\",\n                \"omics:StartRun\",\n                \"omics:ListRuns\",\n                \"omics:GetRun\",\n                \"omics:ListRunTasks\",\n                \"omics:GetRunTask\",\n                \"logs:DescribeLogGroups\",\n                \"logs:DescribeLogStreams\",\n                \"logs:GetLogEvents\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"iam:PassRole\"\n            ],\n            \"Resource\": \"arn:aws:iam::*:role/HealthOmicsExecutionRole*\"\n        }\n    ]\n}\n</code></pre>"},{"location":"servers/aws-healthomics-mcp-server/#usage-with-mcp-clients","title":"Usage with MCP Clients","text":""},{"location":"servers/aws-healthomics-mcp-server/#claude-desktop","title":"Claude Desktop","text":"<p>Add to your Claude Desktop configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"aws-healthomics\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-healthomics-mcp-server\"],\n      \"env\": {\n        \"AWS_REGION\": \"us-east-1\",\n        \"AWS_PROFILE\": \"your-profile\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-healthomics-mcp-server/#other-mcp-clients","title":"Other MCP Clients","text":"<p>Configure according to your client's documentation, using: - Command: <code>uvx</code> - Args: <code>[\"awslabs.aws-healthomics-mcp-server\"]</code> - Environment variables as needed</p>"},{"location":"servers/aws-healthomics-mcp-server/#development","title":"Development","text":""},{"location":"servers/aws-healthomics-mcp-server/#setup","title":"Setup","text":"<pre><code>git clone &lt;repository-url&gt;\ncd aws-healthomics-mcp-server\nuv sync\n</code></pre>"},{"location":"servers/aws-healthomics-mcp-server/#testing","title":"Testing","text":"<pre><code># Run tests with coverage\nuv run pytest --cov --cov-branch --cov-report=term-missing\n\n# Run specific test file\nuv run pytest tests/test_server.py -v\n</code></pre>"},{"location":"servers/aws-healthomics-mcp-server/#code-quality","title":"Code Quality","text":"<pre><code># Format code\nuv run ruff format\n\n# Lint code\nuv run ruff check\n\n# Type checking\nuv run pyright\n</code></pre>"},{"location":"servers/aws-healthomics-mcp-server/#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see the contributing guidelines for more information.</p>"},{"location":"servers/aws-healthomics-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache-2.0 License. See the LICENSE file for details.</p>"},{"location":"servers/aws-location-mcp-server/","title":"Amazon Location Service MCP Server","text":"<p>Model Context Protocol (MCP) server for Amazon Location Service</p> <p>This MCP server provides tools to access Amazon Location Service capabilities, focusing on place search and geographical coordinates.</p>"},{"location":"servers/aws-location-mcp-server/#features","title":"Features","text":"<ul> <li>Search for Places: Search for places using geocoding</li> <li>Get Place Details: Get details for specific places by PlaceId</li> <li>Reverse Geocode: Convert coordinates to addresses</li> <li>Search Nearby: Search for places near a specified location</li> <li>Open Now Search: Search for places that are currently open</li> <li>Route Calculation: Calculate routes between locations using Amazon Location Service</li> <li>Optimize Waypoints: Optimize the order of waypoints for a route using Amazon Location Service</li> </ul>"},{"location":"servers/aws-location-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/aws-location-mcp-server/#requirements","title":"Requirements","text":"<ol> <li>Have an AWS account with Amazon Location Service enabled</li> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python 3.10 or newer using <code>uv python install 3.10</code> (or a more recent version)</li> </ol>"},{"location":"servers/aws-location-mcp-server/#installation","title":"Installation","text":"<p>Here are the ways you can work with the Amazon Location MCP server:</p>"},{"location":"servers/aws-location-mcp-server/#configuration","title":"Configuration","text":"<p>Configure the server in your MCP configuration file. Here are some ways you can work with MCP across AWS, and we'll be adding support to more products soon: (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-location-mcp-server\": {\n        \"command\": \"uvx\",\n        \"args\": [\"awslabs.aws-location-mcp-server@latest\"],\n        \"env\": {\n          \"AWS_PROFILE\": \"your-aws-profile\",\n          \"AWS_REGION\": \"us-east-1\",\n          \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#using-temporary-credentials","title":"Using Temporary Credentials","text":"<p>For temporary credentials (such as those from AWS STS, IAM roles, or federation):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-location-mcp-server\": {\n        \"command\": \"uvx\",\n        \"args\": [\"awslabs.aws-location-mcp-server@latest\"],\n        \"env\": {\n          \"AWS_ACCESS_KEY_ID\": \"your-temporary-access-key\",\n          \"AWS_SECRET_ACCESS_KEY\": \"your-temporary-secret-key\",\n          \"AWS_SESSION_TOKEN\": \"your-session-token\",\n          \"AWS_REGION\": \"us-east-1\",\n          \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#docker-configuration","title":"Docker Configuration","text":"<p>After building with <code>docker build -t awslabs/aws-location-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-location-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"-i\",\n          \"awslabs/aws-location-mcp-server\"\n        ],\n        \"env\": {\n          \"AWS_PROFILE\": \"your-aws-profile\",\n          \"AWS_REGION\": \"us-east-1\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#docker-with-temporary-credentials","title":"Docker with Temporary Credentials","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-location-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"-i\",\n          \"awslabs/aws-location-mcp-server\"\n        ],\n        \"env\": {\n          \"AWS_ACCESS_KEY_ID\": \"your-temporary-access-key\",\n          \"AWS_SECRET_ACCESS_KEY\": \"your-temporary-secret-key\",\n          \"AWS_SESSION_TOKEN\": \"your-session-token\",\n          \"AWS_REGION\": \"us-east-1\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>AWS_PROFILE</code>: AWS CLI profile to use for credentials</li> <li><code>AWS_REGION</code>: AWS region to use (default: us-east-1)</li> <li><code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>: Explicit AWS credentials (alternative to AWS_PROFILE)</li> <li><code>AWS_SESSION_TOKEN</code>: Session token for temporary credentials (used with AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY)</li> <li><code>FASTMCP_LOG_LEVEL</code>: Logging level (ERROR, WARNING, INFO, DEBUG)</li> </ul>"},{"location":"servers/aws-location-mcp-server/#tools","title":"Tools","text":"<p>The server exposes the following tools through the MCP interface:</p>"},{"location":"servers/aws-location-mcp-server/#search_places","title":"search_places","text":"<p>Search for places using Amazon Location Service geocoding capabilities.</p> <pre><code>search_places(query: str, max_results: int = 5, mode: str = 'summary') -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#get_place","title":"get_place","text":"<p>Get details for a specific place using its unique place ID.</p> <pre><code>get_place(place_id: str, mode: str = 'summary') -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#reverse_geocode","title":"reverse_geocode","text":"<p>Convert coordinates to an address using reverse geocoding.</p> <pre><code>reverse_geocode(longitude: float, latitude: float) -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#search_nearby","title":"search_nearby","text":"<p>Search for places near a specific location with optional radius expansion.</p> <pre><code>search_nearby(longitude: float, latitude: float, radius: int = 500, max_results: int = 5,\n              query: str = None, max_radius: int = 10000, expansion_factor: float = 2.0,\n              mode: str = 'summary') -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#search_places_open_now","title":"search_places_open_now","text":"<p>Search for places that are currently open, with radius expansion if needed.</p> <pre><code>search_places_open_now(query: str, max_results: int = 5, initial_radius: int = 500,\n                       max_radius: int = 50000, expansion_factor: float = 2.0) -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#calculate_route","title":"calculate_route","text":"<p>Calculate a route between two locations using Amazon Location Service.</p> <p><pre><code>calculate_route(\n    departure_position: list,  # [longitude, latitude]\n    destination_position: list,  # [longitude, latitude]\n    travel_mode: str = 'Car',  # 'Car', 'Truck', 'Walking', or 'Bicycle'\n    optimize_for: str = 'FastestRoute'  # 'FastestRoute' or 'ShortestRoute'\n) -&gt; dict\n</code></pre> Returns route geometry, distance, duration, and turn-by-turn directions.</p> <ul> <li><code>departure_position</code>: List of [longitude, latitude] for the starting point.</li> <li><code>destination_position</code>: List of [longitude, latitude] for the destination.</li> <li><code>travel_mode</code>: Travel mode, one of <code>'Car'</code>, <code>'Truck'</code>, <code>'Walking'</code>, or <code>'Bicycle'</code>.</li> <li><code>optimize_for</code>: Route optimization, either <code>'FastestRoute'</code> or <code>'ShortestRoute'</code>.</li> </ul> <p>See AWS documentation for more details.</p>"},{"location":"servers/aws-location-mcp-server/#get_coordinates","title":"get_coordinates","text":"<p>Get coordinates for a location name or address.</p> <pre><code>get_coordinates(location: str) -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#optimize_waypoints","title":"optimize_waypoints","text":"<p>Optimize the order of waypoints using Amazon Location Service geo-routes API.</p> <p><pre><code>optimize_waypoints(\n    origin_position: list,  # [longitude, latitude]\n    destination_position: list,  # [longitude, latitude]\n    waypoints: list,  # List of waypoints, each as a dict with at least Position [longitude, latitude]\n    travel_mode: str = 'Car',\n    mode: str = 'summary'\n) -&gt; dict\n</code></pre> Returns the optimized order of waypoints, total distance, and duration.</p>"},{"location":"servers/aws-location-mcp-server/#amazon-location-service-resources","title":"Amazon Location Service Resources","text":"<p>This server uses the Amazon Location Service geo-places and route calculation APIs for: - Geocoding (converting addresses to coordinates) - Reverse geocoding (converting coordinates to addresses) - Place search (finding places by name, category, etc.) - Place details (getting information about specific places) - Route calculation (finding routes between locations)</p>"},{"location":"servers/aws-location-mcp-server/#security-considerations","title":"Security Considerations","text":"<ul> <li>Use AWS profiles for credential management</li> <li>Use IAM policies to restrict access to only the required Amazon Location Service resources</li> <li>Use temporary credentials (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN) from AWS STS for enhanced security</li> <li>Implement AWS IAM roles with temporary credentials for applications and services</li> <li>Regularly rotate credentials and use the shortest practical expiration time for temporary credentials</li> </ul>"},{"location":"servers/aws-pricing-mcp-server/","title":"AWS Pricing MCP Server","text":"<p>MCP server for generating upfront AWS service cost estimates and providing cost insights</p> <p>Important Note: This server provides estimated pricing based on AWS pricing APIs and web pages. These estimates are for pre-deployment planning purposes and do not reflect the actual expenses of deployed cloud services.</p>"},{"location":"servers/aws-pricing-mcp-server/#features","title":"Features","text":""},{"location":"servers/aws-pricing-mcp-server/#analyze-and-visualize-aws-costs","title":"Analyze and visualize AWS costs","text":"<ul> <li>Get detailed breakdown of your AWS costs by service, region and tier</li> <li>Understand how costs are distributed across various services</li> <li>Provide pre-deployment cost estimates for infrastructure planning</li> <li>Support for analyzing both CDK and Terraform projects to identify AWS services</li> </ul>"},{"location":"servers/aws-pricing-mcp-server/#query-cost-data-with-natural-language","title":"Query cost data with natural language","text":"<ul> <li>Ask questions about your AWS costs in plain English, no complex query languages required</li> <li>Get instant answers fetched from pricing webpage and AWS Pricing API, for questions related to AWS services</li> <li>Retrieve estimated pricing information before actual cloud service deployment</li> </ul>"},{"location":"servers/aws-pricing-mcp-server/#generate-cost-reports-and-insights","title":"Generate cost reports and insights","text":"<ul> <li>Generate comprehensive cost estimates based on your IaC implementation</li> <li>Get cost optimization recommendations for potential cloud infrastructure</li> <li>Provide upfront pricing analysis to support informed decision-making</li> </ul>"},{"location":"servers/aws-pricing-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to access AWS Pricing API</li> </ol>"},{"location":"servers/aws-pricing-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-pricing-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-pricing-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"your-aws-profile\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/aws-pricing-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.aws-pricing-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/aws-pricing-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/aws-pricing-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access the AWS Pricing API. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for accessing AWS services.</p>"},{"location":"servers/aws-serverless-mcp-server/","title":"AWS Serverless MCP Server","text":""},{"location":"servers/aws-serverless-mcp-server/#overview","title":"Overview","text":"<p>The AWS Serverless Model Context Protocol (MCP) Server is an open-source tool that combines AI assistance with serverless expertise to streamline how developers build serverless applications. It provides contextual guidance specific to serverless development, helping developers make informed decisions about architecture, implementation, and deployment throughout the entire application development lifecycle. With AWS Serverless MCP, developers can build reliable, efficient, and production-ready serverless applications with confidence.</p> <p>Key benefits of the Serverless MCP Server include:</p> <ul> <li>AI-powered serverless development: Provides rich contextual information to AI coding assistants to ensure your serverless application aligns with AWS best practices.</li> <li>Comprehensive tooling: Offers tools for initialization, deployment, monitoring, and troubleshooting of serverless applications.</li> <li>Architecture guidance: Helps evaluate design choices and select optimal serverless patterns based on application needs. Offers recommendations on event sources, function boundaries, and service integrations.</li> <li>Operational best practices: Ensures alignment with AWS architectural principles. Suggests effective use of AWS services for event processing, data persistence, and service communication, and guides implementation of security controls, performance tuning, and cost optimization.</li> <li>Security-first approach: Implements built-in guardrails with read-only defaults and controlled access to sensitive data.</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#features","title":"Features","text":"<p>The set of tools provided by the Serverless MCP server can be broken down into four categories:</p> <ol> <li>Serverless Application Lifecycle<ul> <li>Initialize, build, and deploy Serverless Application Model (SAM) applications with SAM CLI</li> <li>Test Lambda functions locally and remotely</li> </ul> </li> <li>Web Application Deployment &amp; Management<ul> <li>Deploy full-stack, frontend, and backend web applications onto AWS Serverless using Lambda Web Adapter</li> <li>Update frontend assets and optionally invaliate CloudFront caches</li> <li>Create custom domain names, including certificate and DNS setup</li> </ul> </li> <li>Observability<ul> <li>Retrieve and logs and metrics of serverless resources</li> </ul> </li> <li>Guidance, Templates, and Deployment Help<ul> <li>Provides guidance on AWS Lambda use-cases, selecting an IaC framework, and deployment process onto AWS Serverless</li> <li>Provides sample SAM templates for different serverless application types from Serverless Land</li> <li>Provides schema types for different Lambda event sources and runtimes</li> <li>Provides schema registry management and discovery for AWS EventBridge events</li> <li>Enables type-safe Lambda function development with complete event schemas</li> </ul> </li> </ol>"},{"location":"servers/aws-serverless-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Have an AWS account with credentials configured</li> <li>Install uv from Astral or the GitHub README</li> <li>Install Python 3.10 or newer using uv python install 3.10 (or a more recent version)</li> <li>Install AWS SAM CLI</li> <li>Install AWS CLI</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#installation","title":"Installation","text":"<p>You can download the AWS Serverless MCP Server from GitHub. To get started using your favorite code assistant with MCP support, like Q Developer, Cursor or Cline.</p> <p>Add the following code to your MCP client configuration. The Serverless MCP server uses the default AWS profile by default. Specify a value in AWS_PROFILE if you want to use a different profile. Similarly, adjust the AWS Region and log level values as needed. <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-serverless-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.aws-serverless-mcp-server@latest\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n          \"AWS_PROFILE\": \"your-aws-profile\",\n          \"AWS_REGION\": \"us-east-1\"\n        },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre></p>"},{"location":"servers/aws-serverless-mcp-server/#using-temporary-credentials","title":"Using temporary credentials","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-serverless-mcp-server\": {\n        \"command\": \"uvx\",\n        \"args\": [\"awslabs.aws-serverless-mcp-server@latest\"],\n        \"env\": {\n          \"AWS_ACCESS_KEY_ID\": \"your-temporary-access-key\",\n          \"AWS_SECRET_ACCESS_KEY\": \"your-temporary-secret-key\",\n          \"AWS_SESSION_TOKEN\": \"your-session-token\",\n          \"AWS_REGION\": \"us-east-1\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-serverless-mcp-server/#serverless-mcp-server-configuration-options","title":"Serverless MCP Server configuration options","text":""},{"location":"servers/aws-serverless-mcp-server/#-allow-write","title":"<code>--allow-write</code>","text":"<p>Enables write access mode, which allows mutating operations and creation of public resources. By default, the server runs in read-only mode, which restricts operations to only perform read actions, preventing any changes to AWS resources.</p> <p>Mutating operations:</p> <ul> <li>sam_deploy: Deploys a SAM application into AWS Cloud using CloudFormation</li> <li>deploy_webapp: Generates SAM template and deploys a web application into AWS CloudFormation. Creates public resources, including Route 53 DNS records, and CloudFront distributions</li> <li>configure_domain: Create custom domain using Route53 and ACM certificate and associates it with the project's CloudFront distribution</li> <li>update_frontend: Uploads frontend assets to S3 bucket</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#-allow-sensitive-data-access","title":"<code>--allow-sensitive-data-access</code>","text":"<p>Enables access to sensitive data such as logs. By default, the server restricts access to sensitive data.</p> <p>Operations returning sensitive data:</p> <ul> <li>sam_logs: Returns Lambda function logs and API Gateway logs</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#local-development","title":"Local development","text":"<p>To make changes to this MCP locally and run it:</p> <ol> <li> <p>Clone this repository:    <pre><code>git clone https://github.com/awslabs/mcp.git\ncd mcp/src/aws-serverless-mcp-server\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>pip install -e .\n</code></pre></p> </li> <li> <p>Configure AWS credentials:</p> </li> <li>Ensure you have AWS credentials configured in <code>~/.aws/credentials</code> or set the appropriate environment variables.</li> <li> <p>You can also set the AWS_PROFILE and AWS_REGION environment variables.</p> </li> <li> <p>Run the server:    <pre><code>python -m awslabs.aws_serverless_mcp_server.server\n</code></pre></p> </li> <li> <p>To use this MCP server with AI clients, add the following to your MCP configuration: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-serverless-mcp-server\": {\n        \"command\": \"mcp/src/aws-serverless-mcp-server/bin/awslabs.aws-serverless-mcp-server/\",\n        \"env\": {\n          \"AWS_PROFILE\": \"your-aws-profile\",\n          \"AWS_REGION\": \"us-east-1\",\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre></p> </li> </ol>"},{"location":"servers/aws-serverless-mcp-server/#environment-variables","title":"Environment variables","text":"<p>By default, the default AWS profile is used. However, the server can be configured through environment variables in the MCP configuration:</p> <ul> <li><code>AWS_PROFILE</code>: AWS CLI profile to use for credentials</li> <li><code>AWS_REGION</code>: AWS region to use (default: us-east-1)</li> <li><code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>: Explicit AWS credentials (alternative to AWS_PROFILE)</li> <li><code>AWS_SESSION_TOKEN</code>: Session token for temporary credentials (used with AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY)</li> <li><code>FASTMCP_LOG_LEVEL</code>: Logging level (ERROR, WARNING, INFO, DEBUG)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#available-resources","title":"Available resources","text":"<p>The server provides the following resources:</p>"},{"location":"servers/aws-serverless-mcp-server/#template-resources","title":"Template resources","text":"<ul> <li><code>template://list</code>: List of available deployment templates.</li> <li><code>template://{template_name}</code>: Details of a specific deployment template.</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#deployment-resources","title":"Deployment resources","text":"<ul> <li><code>deployment://list</code>: List of all AWS deployments managed by the MCP server.</li> <li><code>deployment://{project_name}</code>: Details about a specific deployment.</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#available-tools","title":"Available tools","text":"<p>The server exposes deployment capabilities as tools:</p>"},{"location":"servers/aws-serverless-mcp-server/#sam_init","title":"sam_init","text":"<p>Initializes a serverless application using AWS SAM (Serverless Application Model) CLI. This tool creates a new SAM project that consists of: - An AWS SAM template to define your infrastructure code - A folder structure that organizes your application - Configuration for your AWS Lambda functions You should have AWS SAM CLI installed and configured in your environment.</p> <p>Parameters:</p> <ul> <li><code>project_name</code> (required): Name of the SAM project to create</li> <li><code>runtime</code> (required): Runtime environment for the Lambda function</li> <li><code>project_directory</code> (required): Absolute path to directory where the SAM application will be initialized</li> <li><code>dependency_manager</code> (required): Dependency manager for the Lambda function</li> <li><code>architecture</code> (default: x86_64): Architecture for the Lambda function</li> <li><code>package_type</code> (default: Zip): Package type for the Lambda function</li> <li><code>application_template</code> (default: hello-world): Template for the SAM application, e.g., hello-world, quick-start, etc.</li> <li><code>application_insights</code>: Activate Amazon CloudWatch Application Insights monitoring</li> <li><code>no_application_insights</code>: Deactivate Amazon CloudWatch Application Insights monitoring</li> <li><code>base_image</code>: Base image for the application when package type is Image</li> <li><code>config_env</code>: Environment name specifying default parameter values in the configuration file</li> <li><code>config_file</code>: Absolute path to configuration file containing default parameter values</li> <li><code>debug</code>: Turn on debug logging</li> <li><code>extra_content</code>: Override custom parameters in the template's cookiecutter.json</li> <li><code>location</code>: Template or application location (Git, HTTP/HTTPS, zip file path)</li> <li><code>save_params</code>: Save parameters to the SAM configuration file</li> <li><code>tracing</code>: Activate AWS X-Ray tracing for Lambda functions</li> <li><code>no_tracing</code>: Deactivate AWS X-Ray tracing for Lambda functions</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#sam_build","title":"sam_build","text":"<p>Builds a serverless application using AWS SAM (Serverless Application Model) CLI. This command compiles your Lambda function code, creates deployment artifacts, and prepares your application for deployment. Before running this tool, the application should already be initialized with 'sam_init' tool. You should have AWS SAM CLI installed and configured in your environment.</p> <p>Parameters:</p> <ul> <li><code>project_directory</code> (required): Absolute path to directory containing the SAM project</li> <li><code>template_file</code>: Absolute path to the template file (defaults to template.yaml)</li> <li><code>base_dir</code>: Resolve relative paths to function's source code with respect to this folder</li> <li><code>build_dir</code>: The absolute path to a directory where the built artifacts are stored</li> <li><code>use_container</code> (default: false): Use a container to build the function</li> <li><code>no_use_container</code> (default: false): Run build in local machine instead of Docker container</li> <li><code>parallel</code> (default: true): Build your AWS SAM application in parallel</li> <li><code>container_env_vars</code>: Environment variables to pass to the build container</li> <li><code>container_env_var_file</code>: Absolute path to a JSON file containing container environment variables</li> <li><code>build_image</code>: The URI of the container image that you want to pull for the build</li> <li><code>debug</code> (default: false): Turn on debug logging</li> <li><code>manifest</code>: Absolute path to a custom dependency manifest file (e.g., package.json) instead of the default</li> <li><code>parameter_overrides</code>: CloudFormation parameter overrides encoded as key-value pairs</li> <li><code>region</code>: AWS Region to deploy to (e.g., us-east-1)</li> <li><code>save_params</code> (default: false): Save parameters to the SAM configuration file</li> <li><code>profile</code>: AWS profile to use</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#sam_deploy","title":"sam_deploy","text":"<p>Deploys a serverless application using AWS SAM (Serverless Application Model) CLI. This command deploys your application to AWS CloudFormation. Every time an appplication is deployed, it should be built with 'sam_build' tool before. You should have AWS SAM CLI installed and configured in your environment.</p> <p>Parameters:</p> <ul> <li><code>application_name</code> (required): Name of the application to be deployed</li> <li><code>project_directory</code> (required): Absolute path to directory containing the SAM project (defaults to current directory)</li> <li><code>template_file</code>: Absolute path to the template file (defaults to template.yaml)</li> <li><code>s3_bucket</code>: S3 bucket to deploy artifacts to</li> <li><code>s3_prefix</code>: S3 prefix for the artifacts</li> <li><code>region</code>: AWS region to deploy to</li> <li><code>profile</code>: AWS profile to use</li> <li><code>parameter_overrides</code>: CloudFormation parameter overrides encoded as key-value pairs</li> <li><code>capabilities</code> (default: [\"CAPABILITY_IAM\"]): IAM capabilities required for the deployment</li> <li><code>config_file</code>: Absolute path to the SAM configuration file</li> <li><code>config_env</code>: Environment name specifying default parameter values in the configuration file</li> <li><code>metadata</code>: Metadata to include with the stack</li> <li><code>tags</code>: Tags to apply to the stack</li> <li><code>resolve_s3</code> (default: false): Automatically create an S3 bucket for deployment artifacts</li> <li><code>debug</code> (default: false): Turn on debug logging</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#sam_logs","title":"sam_logs","text":"<p>Fetches CloudWatch logs that are generated by resources in a SAM application. Use this tool to help debug invocation failures and find root causes.</p> <p>Parameters:</p> <ul> <li><code>resource_name</code>: Name of the resource to fetch logs for (logical ID in CloudFormation/SAM template)</li> <li><code>stack_name</code>: Name of the CloudFormation stack</li> <li><code>start_time</code>: Fetch logs starting from this time (format: 5mins ago, tomorrow, or YYYY-MM-DD HH:MM:SS)</li> <li><code>end_time</code>: Fetch logs up until this time (format: 5mins ago, tomorrow, or YYYY-MM-DD HH:MM:SS)</li> <li><code>output</code> (default: text): Output format (text or json)</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> <li><code>profile</code>: AWS profile to use</li> <li><code>cw_log_group</code>: CloudWatch Logs log groups to fetch logs from</li> <li><code>config_env</code>: Environment name specifying default parameter values in the configuration file</li> <li><code>config_file</code>: Absolute path to configuration file containing default parameter values</li> <li><code>save_params</code> (default: false): Save parameters to the SAM configuration file</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#sam_local_invoke","title":"sam_local_invoke","text":"<p>Locally invokes a Lambda function using AWS SAM CLI. This command runs your Lambda function locally in a Docker container that simulates the AWS Lambda environment. You can use this tool to test your Lambda functions before deploying them to AWS. Docker must be installed and running in your environment.</p> <p>Parameters:</p> <ul> <li><code>project_directory</code> (required): Absolute path to directory containing the SAM project</li> <li><code>resource_name</code> (required): Name of the Lambda function to invoke locally</li> <li><code>template_file</code>: Absolute path to the SAM template file (defaults to template.yaml)</li> <li><code>event_file</code>: Absolute path to a JSON file containing event data</li> <li><code>event_data</code>: JSON string containing event data (alternative to event_file)</li> <li><code>environment_variables_file</code>: Absolute path to a JSON file containing environment variables to pass to the function</li> <li><code>docker_network</code>: Docker network to run the Lambda function in</li> <li><code>container_env_vars</code>: Environment variables to pass to the container</li> <li><code>parameter</code>: Override parameters from the template file</li> <li><code>log_file</code>: Absolute path to a file where the function logs will be written</li> <li><code>layer_cache_basedir</code>: Directory where the layers will be cached</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> <li><code>profile</code>: AWS profile to use</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_iac_guidance","title":"get_iac_guidance","text":"<p>Returns guidance on selecting an infrastructure as code (IaC) platform to deploy Serverless application to AWS. Choices include AWS SAM, CDK, and CloudFormation. Use this tool to decide which IaC tool to use for your Lambda deployments based on your specific use case and requirements.</p> <p>Parameters:</p> <ul> <li><code>iac_tool</code> (default: CloudFormation): IaC tool to use (CloudFormation, SAM, CDK, Terraform)</li> <li><code>include_examples</code> (default: true): Whether to include examples</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_lambda_event_schemas","title":"get_lambda_event_schemas","text":"<p>Returns AWS Lambda event schemas for different event sources (e.g. s3, sns, apigw) and programming languages.  Each Lambda event source defines its own schema and language-specific types, which should be used in the Lambda function handler to correctly parse the event data. If you cannot find a schema for your event source, you can directly parse the event data as a JSON object. For EventBridge events, you must use the list_registries, search_schema, and describe_schema tools to access the schema registry directly, get schema definitions, and generate code processing logic.</p> <p>Parameters:</p> <ul> <li><code>event_source</code> (required): Event source (e.g., api-gw, s3, sqs, sns, kinesis, eventbridge, dynamodb)</li> <li><code>runtime</code> (required): Programming language for the schema references (e.g., go, nodejs, python, java)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_lambda_guidance","title":"get_lambda_guidance","text":"<p>Use this tool to determine if AWS Lambda is suitable platform to deploy an application. Returns a comprehensive guide on when to choose AWS Lambda as a deployment platform. It includes scenarios when to use and not use Lambda, advantages and disadvantages, decision criteria, and specific guidance for various use cases.</p> <p>Parameters:</p> <ul> <li><code>use_case</code> (required): Description of the use case</li> <li><code>include_examples</code> (default: true): Whether to include examples</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#deploy_webapp","title":"deploy_webapp","text":"<p>Deploy web applications to AWS Serverless, including Lambda as compute, DynamoDB as databases, API GW, ACM Certificates, and Route 53 DNS records. This tool uses the Lambda Web Adapter framework so that applications can be written in a standard web framework like Express or Next.js can be easily deployed to Lambda. You do not need to use integrate the code with any adapter framework when using this tool.</p> <p>Parameters:</p> <ul> <li><code>deployment_type</code> (required): Type of deployment (backend, frontend, fullstack)</li> <li><code>project_name</code> (required): Project name</li> <li><code>project_root</code> (required): Absolute path to the project root directory</li> <li><code>region</code>: AWS Region to deploy to (e.g., us-east-1)</li> <li><code>backend_configuration</code>: Backend configuration</li> <li><code>frontend_configuration</code>: Frontend configuration</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#configure_domain","title":"configure_domain","text":"<p>Configures a custom domain for a deployed web application on AWS Serverless. This tool sets up Route 53 DNS records, ACM certificates, and CloudFront custom domain mappings as needed. Use this tool after deploying your web application to associate it with your own domain name.</p> <p>Parameters:</p> <ul> <li><code>project_name</code> (required): Project name</li> <li><code>domain_name</code> (required): Custom domain name</li> <li><code>create_certificate</code> (default: true): Whether to create a ACM certificate</li> <li><code>create_route53_record</code> (default: true): Whether to create a Route 53 record</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#webapp_deployment_help","title":"webapp_deployment_help","text":"<p>Get help information about using the deploy_webapp to perform web application deployments. If deployment_type is provided, returns help information for that deployment type. Otherwise, returns a list of deployments and general help information.</p> <p>Parameters:</p> <ul> <li><code>deployment_type</code> (required): Type of deployment to get help information for (backend, frontend, fullstack)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_metrics","title":"get_metrics","text":"<p>Retrieves CloudWatch metrics from a deployed web application. Use this tool get metrics on error rates, latency, concurrency, etc.</p> <p>Parameters:</p> <ul> <li><code>project_name</code> (required): Project name</li> <li><code>start_time</code>: Start time for metrics (ISO format)</li> <li><code>end_time</code>: End time for metrics (ISO format)</li> <li><code>period</code> (default: 60): Period for metrics in seconds</li> <li><code>resources</code> (default: [\"lambda\", \"apiGateway\"]): Resources to get metrics for</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> <li><code>stage</code> (default: \"prod\"): API Gateway stage</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#update_webapp_frontend","title":"update_webapp_frontend","text":"<p>Update the frontend assets of a deployed web application. This tool uploads new frontend assets to S3 and optionally invalidates the CloudFront cache.</p> <p>Parameters:</p> <ul> <li><code>project_name</code> (required): Project name</li> <li><code>project_root</code> (required): Project root</li> <li><code>built_assets_path</code> (required): Absolute path to pre-built frontend assets</li> <li><code>invalidate_cache</code> (default: true): Whether to invalidate the CloudFront cache</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#deploy_serverless_app_help","title":"deploy_serverless_app_help","text":"<p>Provides instructions on how to deploy a serverless application to AWS Lambda. Deploying a Lambda application requires generating IaC templates, building the code, packaging the code, selecting a deployment tool, and executing the deployment commands. For deploying web applications specifically, use the deploy_webapp tool.</p> <p>Parameters:</p> <ul> <li><code>application_type</code> (required): Type of application to deploy (event_driven, backend, fullstack)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_serverless_templates","title":"get_serverless_templates","text":"<p>Returns example SAM templates from the Serverless Land GitHub repo. Use this tool to get examples for building serverless applications with AWS Lambda and best practices of serverless architecture.</p> <p>Parameters:</p> <ul> <li><code>template_type</code> (required): Template type (e.g., API, ETL, Web)</li> <li><code>runtime</code>: Lambda runtime (e.g., nodejs22.x, python3.13)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#schema-tools","title":"Schema Tools","text":""},{"location":"servers/aws-serverless-mcp-server/#list_registries","title":"list_registries","text":"<p>Lists the registries in your account.</p> <p>Parameters:</p> <ul> <li><code>registry_name_prefix</code>: Limits results to registries starting with this prefix</li> <li><code>scope</code>: Filter by registry scope (LOCAL or AWS)</li> <li><code>limit</code>: Maximum number of results to return (1-100)</li> <li><code>next_token</code>: Pagination token for subsequent requests</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#search_schema","title":"search_schema","text":"<p>Search for schemas in a registry using keywords.</p> <p>Parameters:</p> <ul> <li><code>keywords</code> (required): Keywords to search for (prefix with \"aws.\" for service events)</li> <li><code>registry_name</code> (required): Registry to search in (use \"aws.events\" for AWS service events)</li> <li><code>limit</code>: Maximum number of results (1-100)</li> <li><code>next_token</code>: Pagination token</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#describe_schema","title":"describe_schema","text":"<p>Retrieve the schema definition for the specified schema version.</p> <p>Parameters:</p> <ul> <li><code>registry_name</code> (required): Registry containing the schema (use \"aws.events\" for AWS service events)</li> <li><code>schema_name</code> (required): Name of schema to retrieve (e.g., \"aws.s3@ObjectCreated\" for S3 events)</li> <li><code>schema_version</code>: Version number of schema (latest by default)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#example-usage","title":"Example usage","text":""},{"location":"servers/aws-serverless-mcp-server/#creating-a-lambda-function-with-sam","title":"Creating a Lambda Function with SAM","text":"<p>Example user prompt:</p> <pre><code>I want to build a simple backend for a todo app using Python and deploy it to the cloud with AWS Serverless. Can you help me create a new project called my-todo-app. It should include basic functionality to add and list todos. Once it's set up, please build and deploy it with all the necessary permissions. I don\u2019t need to review the changeset before deployment.\n</code></pre> <p>This prompt would trigger the AI assistant to: 1. Initialize a new SAM project using a template. 2. Make modifications to code and infra for a todo app. 3. Build the SAM application 4. Deploy the application with CAPABILITY_IAM permissions</p>"},{"location":"servers/aws-serverless-mcp-server/#deploying-a-web-application","title":"Deploying a Web Application","text":"<p>Example user prompt:</p> <pre><code>I have a full-stack web app built with Node.js called my-web-app, and I want to deploy it to the cloud using AWS. Everything\u2019s ready \u2014 both frontend and backend. Can you set it up and deploy it with AWS Lambda so it's live and works smoothly?\n</code></pre> <p>This prompt would trigger the AI assistant to use the deploy_webapp to deploy the full stack application with the specified configuration.</p>"},{"location":"servers/aws-serverless-mcp-server/#working-with-eventbridge-schemas","title":"Working with EventBridge Schemas","text":"<p>Example user prompt:</p> <pre><code>I need to create a Lambda function that processes autoscaling events. Can you help me find the right event schema and implement type-safe event handling?\n</code></pre> <p>This prompt would trigger the AI assistant to: 1. Search for autoscaling event schemas in aws.events registry using search_schema 2. Retrieve complete schema definition using describe_schema 3. Generate type-safe handler code based on schema structure 4. Implement validation for required fields</p>"},{"location":"servers/aws-serverless-mcp-server/#security-features","title":"Security features","text":"<ol> <li>AWS Authentication: Uses AWS credentials from the environment for secure authentication</li> <li>TLS Verification: Enforces TLS verification for all AWS API calls</li> <li>Resource Tagging: Tags all created resources for traceability</li> <li>Least Privilege: Uses IAM roles with appropriate permissions for CloudFormation templates</li> </ol>"},{"location":"servers/aws-serverless-mcp-server/#security-considerations","title":"Security considerations","text":""},{"location":"servers/aws-serverless-mcp-server/#production-use-cases","title":"Production use cases","text":"<p>The AWS Serverless MCP Server can be used for production environments with proper security controls in place. For production use cases, consider the following:</p> <ul> <li>Read-Only Mode by Default: The server runs in read-only mode by default, which is safer for production environments. Only explicitly enable write access when necessary.</li> <li>Disable auto-approve: Require the user to approve each time the AI assitant executes a tool</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#role-scoping-recommendations","title":"Role scoping recommendations","text":"<p>To follow security best practices:</p> <ol> <li>Create dedicated IAM roles to be used by the AWS Serverless MCP Server with the principle of least privilege</li> <li>Use separate roles for read-only and write operations</li> <li>Implement resource tagging to limit actions to resources created by the server</li> <li>Enable AWS CloudTrail to audit all API calls made by the server</li> <li>Regularly review the permissions granted to the server's IAM role</li> <li>Use IAM Access Analyzer to identify unused permissions that can be removed</li> </ol>"},{"location":"servers/aws-serverless-mcp-server/#sensitive-information-handling","title":"Sensitive information handling","text":"<p>IMPORTANT: Do not pass secrets or sensitive information via allowed input mechanisms:</p> <ul> <li>Do not include secrets or credentials in CloudFormation templates</li> <li>Do not pass sensitive information directly in the prompt to the model</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#links","title":"Links","text":"<ul> <li>Homepage</li> <li>Documentation</li> <li>Source Code</li> <li>Bug Tracker</li> <li>Changelog</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#license","title":"License","text":"<p>Apache-2.0</p>"},{"location":"servers/aws-support-mcp-server/","title":"AWS Support MCP Server","text":"<p>A Model Context Protocol (MCP) server implementation for interacting with the AWS Support API. This server enables AI assistants to create and manage AWS support cases programmatically.</p>"},{"location":"servers/aws-support-mcp-server/#features","title":"Features","text":"<ul> <li>Create and manage AWS support cases</li> <li>Retrieve case information and communications</li> <li>Add communications to existing cases</li> <li>Resolve support cases</li> <li>Determine appropriate Issue Type, Service Code, and Category Code</li> <li>Determine appropriate Severity Level for a case</li> </ul>"},{"location":"servers/aws-support-mcp-server/#requirements","title":"Requirements","text":"<ul> <li>Python 3.7+</li> <li>AWS credentials with Support API access</li> <li>Business, Enterprise On-Ramp, or Enterprise Support plan</li> </ul>"},{"location":"servers/aws-support-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/aws-support-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n   \"mcpServers\": {\n      \"awslabs_support_mcp_server\": {\n         \"command\": \"uvx\",\n         \"args\": [\n            \"-m\", \"awslabs.aws-support-mcp-server@latest\",\n            \"--debug\",\n            \"--log-file\",\n            \"./logs/mcp_support_server.log\"\n         ],\n         \"env\": {\n            \"AWS_PROFILE\": \"your-aws-profile\"\n         }\n      }\n   }\n}\n</code></pre> <p>Alternatively: <pre><code>uv pip install -e .\nuv run awslabs/aws_support_mcp_server/server.py\n</code></pre></p> <pre><code>{\n   \"mcpServers\": {\n      \"awslabs_support_mcp_server\": {\n         \"command\": \"path-to-python\",\n         \"args\": [\n            \"-m\",\n            \"awslabs.aws_support_mcp_server.server\",\n            \"--debug\",\n            \"--log-file\",\n            \"./logs/mcp_support_server.log\"\n         ],\n         \"env\": {\n            \"AWS_PROFILE\": \"manual_enterprise\"\n         }\n      }\n   }\n}\n</code></pre>"},{"location":"servers/aws-support-mcp-server/#usage","title":"Usage","text":"<p>Start the server:</p> <pre><code>python -m awslabs.aws_support_mcp_server.server [options]\n</code></pre> <p>Options: - <code>--port PORT</code>: Port to run the server on (default: 8888) - <code>--debug</code>: Enable debug logging - <code>--log-file</code>: Where to save the log file</p>"},{"location":"servers/aws-support-mcp-server/#configuration","title":"Configuration","text":"<p>The server can be configured using environment variables:</p> <ul> <li><code>AWS_REGION</code>: AWS region (default: us-east-1)</li> <li><code>AWS_PROFILE</code>: AWS credentials profile name</li> </ul>"},{"location":"servers/aws-support-mcp-server/#documentation","title":"Documentation","text":"<p>For detailed documentation on available tools and resources, see the API Documentation.</p>"},{"location":"servers/aws-support-mcp-server/#license","title":"License","text":"<p>Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\").</p>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/","title":"Amazon Bedrock Knowledge Base Retrieval MCP Server","text":"<p>MCP server for accessing Amazon Bedrock Knowledge Bases</p>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#features","title":"Features","text":""},{"location":"servers/bedrock-kb-retrieval-mcp-server/#discover-knowledge-bases-and-their-data-sources","title":"Discover knowledge bases and their data sources","text":"<ul> <li>Find and explore all available knowledge bases</li> <li>Search for knowledge bases by name or tag</li> <li>List data sources associated with each knowledge base</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#query-knowledge-bases-with-natural-language","title":"Query knowledge bases with natural language","text":"<ul> <li>Retrieve information using conversational queries</li> <li>Get relevant passages from your knowledge bases</li> <li>Access citation information for all results</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#filter-results-by-data-source","title":"Filter results by data source","text":"<ul> <li>Focus your queries on specific data sources</li> <li>Include or exclude specific data sources</li> <li>Prioritize results from specific data sources</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#rerank-results","title":"Rerank results","text":"<ul> <li>Improve relevance of retrieval results</li> <li>Use Amazon Bedrock reranking capabilities</li> <li>Sort results by relevance to your query</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/bedrock-kb-retrieval-mcp-server/#installation-requirements","title":"Installation Requirements","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#aws-requirements","title":"AWS Requirements","text":"<ol> <li>AWS CLI Configuration: You must have the AWS CLI configured with credentials and an AWS_PROFILE that has access to Amazon Bedrock and Knowledge Bases</li> <li>Amazon Bedrock Knowledge Base: You must have at least one Amazon Bedrock Knowledge Base with the tag key <code>mcp-multirag-kb</code> with a value of <code>true</code></li> <li>IAM Permissions: Your IAM role/user must have appropriate permissions to:</li> <li>List and describe knowledge bases</li> <li>Access data sources</li> <li>Query knowledge bases</li> </ol>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#reranking-requirements","title":"Reranking Requirements","text":"<p>If you intend to use reranking functionality, your Bedrock Knowledge Base needs additional permissions:</p> <ol> <li>Your IAM role must have permissions for both <code>bedrock:Rerank</code> and <code>bedrock:InvokeModel</code> actions</li> <li>The Amazon Bedrock Knowledge Bases service role must also have these permissions</li> <li>Reranking is only available in specific regions. Please refer to the official documentation for an up to date list of supported regions.</li> <li>Enable model access for the available reranking models in the specified region.</li> </ol>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#controlling-reranking","title":"Controlling Reranking","text":"<p>Reranking can be globally enabled or disabled using the <code>BEDROCK_KB_RERANKING_ENABLED</code> environment variable:</p> <ul> <li>Set to <code>false</code> (default): Disables reranking for all queries unless explicitly enabled</li> <li>Set to <code>true</code>: Enables reranking for all queries unless explicitly disabled</li> </ul> <p>The environment variable accepts various formats:</p> <ul> <li>For enabling: 'true', '1', 'yes', or 'on' (case-insensitive)</li> <li>For disabling: any other value or not set (default behavior)</li> </ul> <p>This setting provides a global default, while individual API calls can still override it by explicitly setting the <code>reranking</code> parameter.</p> <p>For detailed instructions on setting up knowledge bases, see:</p> <ul> <li>Create a knowledge base</li> <li>Managing permissions for Amazon Bedrock knowledge bases</li> <li>Permissions for reranking in Amazon Bedrock</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.bedrock-kb-retrieval-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.bedrock-kb-retrieval-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile-name\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"KB_INCLUSION_TAG_KEY\": \"optional-tag-key-to-filter-kbs\",\n        \"BEDROCK_KB_RERANKING_ENABLED\": \"false\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/bedrock-kb-retrieval-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.bedrock-kb-retrieval-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"--env\",\n          \"KB_INCLUSION_TAG_KEY=optional-tag-key-to-filter-kbs\",\n          \"--env\",\n          \"BEDROCK_KB_RERANKING_ENABLED=false\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/bedrock-kb-retrieval-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#limitations","title":"Limitations","text":"<ul> <li>Results with <code>IMAGE</code> content type are not included in the KB query response.</li> <li>The <code>reranking</code> parameter requires additional permissions, Amazon Bedrock model access, and is only available in specific regions.</li> </ul>"},{"location":"servers/cdk-mcp-server/","title":"AWS CDK MCP Server","text":"<p>MCP server for AWS Cloud Development Kit (CDK) best practices, infrastructure as code patterns, and security compliance with CDK Nag.</p>"},{"location":"servers/cdk-mcp-server/#features","title":"Features","text":""},{"location":"servers/cdk-mcp-server/#cdk-general-guidance","title":"CDK General Guidance","text":"<ul> <li>Prescriptive patterns with AWS Solutions Constructs and GenAI CDK libraries</li> <li>Structured decision flow for choosing appropriate implementation approaches</li> <li>Security automation through CDK Nag integration and Lambda Powertools</li> </ul>"},{"location":"servers/cdk-mcp-server/#cdk-nag-integration","title":"CDK Nag Integration","text":"<ul> <li>Work with CDK Nag rules for security and compliance</li> <li>Explain specific CDK Nag rules with AWS Well-Architected guidance</li> <li>Check if CDK code contains Nag suppressions that require human review</li> </ul>"},{"location":"servers/cdk-mcp-server/#aws-solutions-constructs","title":"AWS Solutions Constructs","text":"<ul> <li>Search and discover AWS Solutions Constructs patterns</li> <li>Find recommended patterns for common architecture needs</li> <li>Get detailed documentation on Solutions Constructs</li> </ul>"},{"location":"servers/cdk-mcp-server/#generative-ai-cdk-constructs","title":"Generative AI CDK Constructs","text":"<ul> <li>Search for GenAI CDK constructs by name or type</li> <li>Discover specialized constructs for AI/ML workloads</li> <li>Get implementation guidance for generative AI applications</li> </ul>"},{"location":"servers/cdk-mcp-server/#lambda-layer-documentation-provider","title":"Lambda Layer Documentation Provider","text":"<ul> <li>Access comprehensive documentation for AWS Lambda layers</li> <li>Get code examples for generic Lambda layers and Python-specific layers</li> <li>Retrieve directory structure information and implementation best practices</li> <li>Seamless integration with AWS Documentation MCP Server for detailed documentation</li> </ul>"},{"location":"servers/cdk-mcp-server/#amazon-bedrock-agent-schema-generation","title":"Amazon Bedrock Agent Schema Generation","text":"<ul> <li>Use this tool when creating Bedrock Agents with Action Groups that use Lambda functions</li> <li>Streamline the creation of Bedrock Agent schemas</li> <li>Convert code files to compatible OpenAPI specifications</li> </ul>"},{"location":"servers/cdk-mcp-server/#developer-notes","title":"Developer Notes","text":"<ul> <li>Requirements: Your Lambda function must use <code>BedrockAgentResolver</code> from AWS Lambda Powertools</li> <li>Lambda Dependencies: If schema generation fails, a fallback script will be generated. If you see error messages about missing dependencies, install them and then run the script again.</li> <li>Integration: Use the generated schema with <code>bedrock.ApiSchema.fromLocalAsset()</code> in your CDK code</li> </ul>"},{"location":"servers/cdk-mcp-server/#cdk-implementation-workflow","title":"CDK Implementation Workflow","text":"<p>This diagram provides a comprehensive view of the recommended CDK implementation workflow:</p> <pre><code>graph TD\n    Start([Start]) --&gt; A[\"CDKGeneralGuidance\"]\n    A --&gt; Init[\"cdk init app\"]\n\n    Init --&gt; B{Choose Approach}\n    B --&gt;|\"Common Patterns\"| C1[\"GetAwsSolutionsConstructPattern\"]\n    B --&gt;|\"GenAI Features\"| C2[\"SearchGenAICDKConstructs\"]\n    B --&gt;|\"Custom Needs\"| C3[\"Custom CDK Code\"]\n\n    C1 --&gt; D1[\"Implement Solutions Construct\"]\n    C2 --&gt; D2[\"Implement GenAI Constructs\"]\n    C3 --&gt; D3[\"Implement Custom Resources\"]\n\n    %% Bedrock Agent with Action Groups specific flow\n    D2 --&gt;|\"For Bedrock Agents&lt;br/&gt;with Action Groups\"| BA[\"Create Lambda with&lt;br/&gt;BedrockAgentResolver\"]\n\n    %% Schema generation flow\n    BA --&gt; BS[\"GenerateBedrockAgentSchema\"]\n    BS --&gt;|\"Success\"| JSON[\"openapi.json created\"]\n    BS --&gt;|\"Import Errors\"| BSF[\"Tool generates&lt;br/&gt;generate_schema.py\"]\n    BSF --&gt;|\"Missing dependencies?\"| InstallDeps[\"Install dependencies\"]\n    InstallDeps --&gt; BSR[\"Run script manually:&lt;br/&gt;python generate_schema.py\"]\n    BSR --&gt; JSON[\"openapi.json created\"]\n\n    %% Use schema in Agent CDK\n    JSON --&gt; AgentCDK[\"Use schema in&lt;br/&gt;Agent CDK code\"]\n    AgentCDK --&gt; D2\n\n    %% Conditional Lambda Powertools implementation\n    D1 &amp; D2 &amp; D3 --&gt; HasLambda{\"Using Lambda&lt;br/&gt;Functions?\"}\n    HasLambda --&gt; UseLayer{\"Using Lambda&lt;br/&gt;Layers?\"}\n    UseLayer --&gt;|\"Yes\"| LLDP[\"LambdaLayerDocumentationProvider\"]\n\n    HasLambda --&gt;|\"No\"| SkipL[\"Skip\"]\n\n    %% Rest of workflow\n    LLDP[\"LambdaLayerDocumentationProvider\"] --&gt; Synth[\"cdk synth\"]\n    SkipL --&gt; Synth\n\n    Synth --&gt; Nag{\"CDK Nag&lt;br/&gt;warnings?\"}\n    Nag --&gt;|Yes| E[\"ExplainCDKNagRule\"]\n    Nag --&gt;|No| Deploy[\"cdk deploy\"]\n\n    E --&gt; Fix[\"Fix or Add Suppressions\"]\n    Fix --&gt; CN[\"CheckCDKNagSuppressions\"]\n    CN --&gt; Synth\n\n    %% Styling with darker colors\n    classDef default fill:#424242,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef cmd fill:#4a148c,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef tool fill:#01579b,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef note fill:#1b5e20,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef output fill:#006064,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef decision fill:#5d4037,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n\n    class Init,Synth,Deploy,BSR cmd;\n    class A,C1,C2,BS,E,CN,LLDP tool;\n    class JSON output;\n    class HasLambda,UseLayer,Nag decision;</code></pre>"},{"location":"servers/cdk-mcp-server/#available-mcp-tools","title":"Available MCP Tools","text":"<ul> <li>CDKGeneralGuidance: Get prescriptive advice for building AWS applications with CDK</li> <li>GetAwsSolutionsConstructPattern: Find vetted architecture patterns combining AWS services</li> <li>SearchGenAICDKConstructs: Discover GenAI CDK constructs by name or features</li> <li>GenerateBedrockAgentSchema: Create OpenAPI schemas for Bedrock Agent action groups</li> <li>LambdaLayerDocumentationProvider: Access documentation for Lambda layers implementation</li> <li>ExplainCDKNagRule: Get detailed guidance on CDK Nag security rules</li> <li>CheckCDKNagSuppressions: Validate CDK Nag suppressions in your code</li> </ul>"},{"location":"servers/cdk-mcp-server/#available-mcp-resources","title":"Available MCP Resources","text":"<ul> <li>CDK Nag Rules: Access rule packs via <code>cdk-nag://rules/{rule_pack}</code></li> <li>AWS Solutions Constructs: Access patterns via <code>aws-solutions-constructs://{pattern_name}</code></li> <li>GenAI CDK Constructs: Access documentation via <code>genai-cdk-constructs://{construct_type}/{construct_name}</code></li> <li>Lambda Powertools: Get guidance on Lambda Powertools via <code>lambda-powertools://{topic}</code></li> </ul>"},{"location":"servers/cdk-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install AWS CDK CLI using <code>npm install -g aws-cdk</code> (Note: The MCP server itself doesn't use the CDK CLI directly, but it guides users through CDK application development that requires the CLI)</li> </ol>"},{"location":"servers/cdk-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cdk-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.cdk-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/cdk-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.cdk-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/cdk-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/cdk-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider:</p> <ul> <li>Reviewing all CDK Nag warnings and errors manually</li> <li>Fixing security issues rather than suppressing them whenever possible</li> <li>Documenting clear justifications for any necessary suppressions</li> <li>Using the CheckCDKNagSuppressions tool to verify no unauthorized suppressions exist</li> </ul> <p>Before applying CDK NAG Suppressions, you should consider conducting your own independent assessment to ensure that your use would comply with your own specific security and quality control practices and standards, as well as the local laws, rules, and regulations that govern you and your content.</p>"},{"location":"servers/cfn-mcp-server/","title":"CloudFormation MCP Server","text":"<p>Model Context Protocol (MCP) server that enables LLMs to directly create and manage over 1,100 AWS resources through natural language using AWS Cloud Control API and Iac Generator with Infrastructure as Code best practices.</p>"},{"location":"servers/cfn-mcp-server/#features","title":"Features","text":"<ul> <li>Resource Creation: Uses a declarative approach to create any of 1,100+ AWS resources through Cloud Control API</li> <li>Resource Reading: Reads all properties and attributes of specific AWS resources</li> <li>Resource Updates: Uses a declarative approach to apply changes to existing AWS resources</li> <li>Resource Deletion: Safely removes AWS resources with proper validation</li> <li>Resource Listing: Enumerates all resources of a specified type across your AWS environment</li> <li>Schema Information: Returns detailed CloudFormation schema for any resource to enable more effective operations</li> <li>Natural Language Interface: Transform infrastructure-as-code from static authoring to dynamic conversations</li> <li>Partner Resource Support: Works with both AWS-native and partner-defined resources</li> <li>Template Generation: Generates a template on created/existing resources for a subset of resource types</li> </ul>"},{"location":"servers/cfn-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Configure AWS credentials:</li> <li>Via AWS CLI: <code>aws configure</code></li> <li>Or set environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION)</li> <li>Ensure your IAM role or user has the necessary permissions (see Security Considerations)</li> </ol>"},{"location":"servers/cfn-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cfn-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.cfn-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-named-profile\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>If you would like to prevent the MCP from taking any mutating actions (i.e. Create/Update/Delete Resource), you can specify the readonly flag as demonstrated below:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cfn-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.cfn-mcp-server@latest\",\n        \"--readonly\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-named-profile\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/cfn-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.cfn-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/cfn-mcp-server:latest\",\n          \"--readonly\" // Optional paramter if you would like to restrict the MCP to only read actions\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/cfn-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/cfn-mcp-server/#create_resource","title":"create_resource","text":"<p>Creates an AWS resource using the AWS Cloud Control API with a declarative approach. Example: Create an S3 bucket with versioning and encryption enabled.</p>"},{"location":"servers/cfn-mcp-server/#get_resource","title":"get_resource","text":"<p>Gets details of a specific AWS resource using the AWS Cloud Control API. Example: Get the configuration of an EC2 instance.</p>"},{"location":"servers/cfn-mcp-server/#update_resource","title":"update_resource","text":"<p>Updates an AWS resource using the AWS Cloud Control API with a declarative approach. Example: Update an RDS instance's storage capacity.</p>"},{"location":"servers/cfn-mcp-server/#delete_resource","title":"delete_resource","text":"<p>Deletes an AWS resource using the AWS Cloud Control API. Example: Remove an unused NAT gateway.</p>"},{"location":"servers/cfn-mcp-server/#list_resources","title":"list_resources","text":"<p>Lists AWS resources of a specified type using AWS Cloud Control API. Example: List all EC2 instances in a region.</p>"},{"location":"servers/cfn-mcp-server/#get_resource_schema_information","title":"get_resource_schema_information","text":"<p>Get schema information for an AWS CloudFormation resource. Example: Get the schema for AWS::S3::Bucket to understand all available properties.</p>"},{"location":"servers/cfn-mcp-server/#get_request_status","title":"get_request_status","text":"<p>Get the status of a mutation that was initiated by create/update/delete resource. Example: Give me the status of the last request I made.</p>"},{"location":"servers/cfn-mcp-server/#create_template","title":"create_template","text":"<p>Create a Cloudformation template from created or listed resources. Example: Create a YAML template for those resources.</p>"},{"location":"servers/cfn-mcp-server/#basic-usage","title":"Basic Usage","text":"<p>Examples of how to use the AWS Infrastructure as Code MCP Server:</p> <ul> <li>\"Create a new S3 bucket with versioning and encryption enabled\"</li> <li>\"List all EC2 instances in the production environment\"</li> <li>\"Update the RDS instance to increase storage to 500GB\"</li> <li>\"Delete unused NAT gateways in VPC-123\"</li> <li>\"Set up a three-tier architecture with web, app, and database layers\"</li> <li>\"Create a disaster recovery environment in us-east-1\"</li> <li>\"Configure CloudWatch alarms for all production resources\"</li> <li>\"Implement cross-region replication for critical S3 buckets\"</li> <li>\"Show me the schema for AWS::Lambda::Function\"</li> <li>\"Create a template for all the resources we created and modified\"</li> </ul>"},{"location":"servers/cfn-mcp-server/#resource-type-support","title":"Resource Type support","text":"<p>Resources which are supported by this MCP and the supported operations can be found here: https://docs.aws.amazon.com/cloudcontrolapi/latest/userguide/supported-resources.html</p>"},{"location":"servers/cfn-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider:</p> <ul> <li>Ensuring proper IAM permissions are configured before use</li> <li>Use AWS CloudTrail for additional security monitoring</li> <li>Configure resource-specific permissions when possible instead of wildcard permissions</li> <li>Consider using resource tagging for better governance and cost management</li> <li>Review all changes made by the MCP server as part of your regular security reviews</li> <li>If you would like to restrict the MCP to readonly operations, specify --readonly True in the startup arguments for the MCP</li> </ul>"},{"location":"servers/cfn-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<p>Ensure your AWS credentials have the following minimum permissions:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"cloudcontrol:ListResources\",\n                \"cloudcontrol:GetResource\",\n                \"cloudcontrol:CreateResource\",\n                \"cloudcontrol:DeleteResource\",\n                \"cloudcontrol:UpdateResource\",\n                \"cloudformation:CreateGeneratedTemplate\",\n                \"cloudformation:DescribeGeneratedTemplate\",\n                \"cloudformation:GetGeneratedTemplate\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre>"},{"location":"servers/cfn-mcp-server/#limitations","title":"Limitations","text":"<ul> <li>Operations are limited to resources supported by AWS Cloud Control API and Iac Generator</li> <li>Performance depends on the underlying AWS services' response times</li> <li>Some complex resource relationships may require multiple operations</li> <li>This MCP server can only manage resources in the AWS regions where Cloud Control API and/or Iac Generator is available</li> <li>Resource modification operations may be limited by service-specific constraints</li> <li>Rate limiting may affect operations when managing many resources simultaneously</li> <li>Some resource types might not support all operations (create, read, update, delete)</li> <li>Generated templates are primarily intended for importing existing resources into a CloudFormation stack and may not always work for creating new resources (in another account or region)</li> </ul>"},{"location":"servers/cloudwatch-appsignals-mcp-server/","title":"CloudWatch Application Signals MCP Server","text":"<p>An MCP (Model Context Protocol) server that provides tools for monitoring and analyzing AWS services using AWS Application Signals.</p> <p>This server enables AI assistants like Claude, GitHub Copilot, and Amazon Q to help you monitor service health, analyze performance metrics, track SLO compliance, and investigate issues using distributed tracing.</p>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#key-features","title":"Key Features","text":"<ol> <li>Monitor overall service health, diagnose root causes, and recommend actionable fixes with the built-in APM expertise.</li> <li>Generate business insights from telemetry data through natural language queries.</li> </ol>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Sign-Up for an AWS account</li> <li>Enable Application Signals for your applications</li> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#available-tools","title":"Available Tools","text":"<ol> <li><code>list_monitored_services</code> - List all services monitored by AWS Application Signals</li> <li>Get an overview of all monitored services</li> <li>See service names, types, and key attributes</li> <li> <p>Identify the services monitored by Application Signals</p> </li> <li> <p><code>get_service_detail</code> - Get detailed information about a specific service</p> </li> <li>Get Service key properties such as Hosting environment, list of APIs,etc</li> <li>Get the list of ApplicationSignals metrics available on service</li> <li> <p>Find associated log groups</p> </li> <li> <p><code>list_slis</code> - List all SLOs and SLIs status for all services</p> </li> <li>List the configured SLOs and across all services</li> <li> <p>Find out all breached SLIs and status</p> </li> <li> <p><code>get_slo</code> - Gets the details configuration for a specific SLO</p> </li> <li> <p>Return the relevant metrics info, SLO threshold</p> </li> <li> <p><code>search_transaction_spans</code> - Queries OTel Spans data via Transaction Search</p> </li> <li>Query OTel Spans to root cause the potential problems</li> <li> <p>Generate business performance insights summaries</p> </li> <li> <p><code>query_sampled_traces</code> - Queries AWS X-Ray traces to gain deeper insights</p> </li> <li>Find the impact from the tracing dependency view</li> <li> <p>Return the exact error stack for LLM to suggest the actionable fixes</p> </li> <li> <p><code>query_service_metrics</code> - Queries Application Signals metrics for root causing service performance issues</p> </li> <li>Query Application Signals RED metrics to correlate the relevant OTel Spans/Traces for troubleshooting</li> </ol>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#installation","title":"Installation","text":""},{"location":"servers/cloudwatch-appsignals-mcp-server/#installing-via-cursor","title":"Installing via Cursor","text":"<p>To install CloudWatch Application Signals MCP Server for Cursor automatically:</p> <p></p>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#installing-via-uv","title":"Installing via <code>uv</code>","text":"<p>When using <code>uv</code> no specific installation is needed. We will use <code>uvx</code> to directly run awslabs.cloudwatch-appsignals-mcp-server.</p>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#installing-for-amazon-q-preview","title":"Installing for Amazon Q (Preview)","text":"<ul> <li>Start Amazon Q Developer CLI from here.</li> <li>Add the following configuration in <code>~/.aws/amazonq/mcp.json</code> file. <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-appsignals-mcp-server\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.cloudwatch-appsignals-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"AWS_ACCESS_KEY_ID\": \"[AWS Access Key ID]\",\n        \"AWS_SECRET_ACCESS_KEY\": \"[AWS Access Key]\",\n        \"AWS_REGION\": \"[AWS Region]\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n</code></pre></li> </ul>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#installing-via-claude-desktop","title":"Installing via Claude Desktop","text":"<p>On MacOS: <code>~/Library/Application\\ Support/Claude/claude_desktop_config.json</code> On Windows: <code>%APPDATA%/Claude/claude_desktop_config.json</code></p> Development/Unpublished Servers Configuration   When installing a development or unpublished server, add the `--directory` flag:    <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-appsignals-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"--from\", \"/absolute/path/to/cloudwatch-appsignals-mcp-server\", \"awslabs.cloudwatch-appsignals-mcp-server\"]\n    }\n  }\n}\n</code></pre> Published Servers Configuration <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-appsignals-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.cloudwatch-appsignals-mcp-server@latest\"]\n    }\n  }\n}\n</code></pre>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#build-and-install-docker-image-locally-on-the-same-host-of-your-llm-client","title":"Build and install docker image locally on the same host of your LLM client","text":"<ol> <li><code>git clone https://github.com/awslabs/mcp.git</code></li> <li>Go to sub-directory 'src/cloudwatch-appsignals-mcp-server/'</li> <li>Run 'docker build -t awslabs/cloudwatch-appsignals-mcp-server:latest .'</li> </ol>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#add-or-update-your-llm-clients-config-with-following","title":"Add or update your LLM client's config with following:","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-appsignals-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"AWS_ACCESS_KEY_ID=[your data]\",\n        \"-e\", \"AWS_SECRET_ACCESS_KEY=[your data]\",\n        \"-e\", \"AWS_REGION=[your data]\",\n        \"awslabs/cloudwatch-appsignals-mcp-server:latest\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#debugging","title":"Debugging","text":"<p>You can use the MCP inspector to debug the server. For <code>uvx</code> installations:</p> <pre><code>npx @modelcontextprotocol/inspector uvx awslabs.cloudwatch-appsignals-mcp-server\n</code></pre> <p>Or if you've installed the package in a specific directory:</p> <pre><code>cd /path/to/cloudwatch-appsignals-mcp-server\nnpx @modelcontextprotocol/inspector uv run awslabs.cloudwatch-appsignals-mcp-server\n</code></pre>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#usage-examples","title":"Usage Examples","text":""},{"location":"servers/cloudwatch-appsignals-mcp-server/#example-1-getting-started-with-service-monitoring","title":"Example 1: Getting Started with Service Monitoring","text":"<pre><code>User: \"What services are being monitored by Application Signals?\"\nAssistant: I'll check what services are currently being monitored by AWS Application Signals.\n\n[Uses list_monitored_services tool]\n\nI found 3 services being monitored:\n\n\u2022 Service: api-gateway-service\n  Type: AWS::ApiGateway::RestApi\n  Key Attributes:\n    Name: api-gateway-service\n    Type: AWS::ApiGateway::RestApi\n    Environment: production\n\n\u2022 Service: order-service\n  Type: AWS::ECS::Service\n  Key Attributes:\n    Name: order-service\n    Type: AWS::ECS::Service\n    Environment: production\n    Platform: ECS\n\n\u2022 Service: payment-lambda\n  Type: AWS::Lambda::Function\n  Key Attributes:\n    Name: payment-lambda\n    Type: AWS::Lambda::Function\n    Environment: production\n</code></pre>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#example-2-investigating-service-details","title":"Example 2: Investigating Service Details","text":"<pre><code>User: \"Tell me more about the order-service\"\nAssistant: I'll get detailed information about the order-service.\n\n[Uses get_service_detail tool]\n\nHere are the details for order-service:\n\nKey Attributes:\n  Name: order-service\n  Type: AWS::ECS::Service\n  Environment: production\n\nAdditional Attributes:\n  Platform: ECS\n  Application: ecommerce-app\n  Telemetry.SDK: opentelemetry-1.9.0\n\nMetric References (15 total):\n  \u2022 AWS/ApplicationSignals/Latency\n    Type: GAUGE\n    Dimensions: Service=order-service, Operation=GetOrder\n\n  \u2022 AWS/ApplicationSignals/ErrorRate\n    Type: GAUGE\n    Dimensions: Service=order-service, Operation=CreateOrder\n\nLog Group References (2 total):\n  \u2022 /aws/ecs/order-service\n  \u2022 /aws/application-signals/order-service\n</code></pre>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#configuration","title":"Configuration","text":""},{"location":"servers/cloudwatch-appsignals-mcp-server/#required-aws-permissions","title":"Required AWS Permissions","text":"<p>The server requires the following AWS IAM permissions:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"application-signals:ListServices\",\n        \"application-signals:GetService\",\n        \"application-signals:ListServiceLevelObjectives\",\n        \"application-signals:GetServiceLevelObjective\",\n        \"application-signals:BatchGetServiceLevelObjectiveBudgetReport\",\n        \"cloudwatch:GetMetricData\",\n        \"logs:GetQueryResults\",\n        \"logs:StartQuery\",\n        \"logs:StopQuery\",\n        \"xray:GetTraceSummaries\",\n        \"xray:BatchGetTraces\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>AWS_REGION</code> - AWS region (defaults to us-east-1)</li> <li><code>MCP_CLOUDWATCH_APPSIGNALS_LOG_LEVEL</code> - Logging level (defaults to INFO)</li> </ul>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#aws-credentials","title":"AWS Credentials","text":"<p>This server uses the standard AWS credential chain via boto3. It will automatically use credentials from: - Environment variables (<code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, etc.) - AWS credentials file (<code>~/.aws/credentials</code>) - AWS config file (<code>~/.aws/config</code>) - IAM roles (when running on EC2, ECS, Lambda, etc.) - And other standard AWS credential providers</p> <p>No additional credential configuration is needed beyond your standard AWS setup.</p>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#development","title":"Development","text":"<p>This server is part of the AWS Labs MCP collection. For development and contribution guidelines, please see the main repository documentation.</p>"},{"location":"servers/cloudwatch-appsignals-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License, Version 2.0. See the LICENSE file for details.</p>"},{"location":"servers/cloudwatch-logs-mcp-server/","title":"Cloudwatch logs mcp server","text":"<p>title: cloudwatch-logs MCP Server</p>"},{"location":"servers/cloudwatch-logs-mcp-server/#aws-labs-cloudwatch-logs-mcp-server-deprecated","title":"AWS Labs cloudwatch-logs MCP Server (DEPRECATED)","text":"<p>An AWS Labs Model Context Protocol (MCP) server for cloudwatch-logs. (DEPRECATED). Please use CloudWatch MCP Server for unified CloudWatch Telemetry related tools.</p>"},{"location":"servers/cloudwatch-logs-mcp-server/#instructions","title":"Instructions","text":"<p>Use this MCP server to run read-only commands and analyze CloudWatchLogs. Supports discovering logs groups as well as running CloudWatch Log Insight Queries. With CloudWatch Logs Insights, you can interactively search and analyze your log data in Amazon CloudWatch Logs and perform queries to help you more efficiently and effectively respond to operational issues.</p>"},{"location":"servers/cloudwatch-logs-mcp-server/#features","title":"Features","text":"<ul> <li>Discovering log groups and metadata about them within your AWS account or accounts connected by CloudWatch Cross Account Observability</li> <li>Converting human-readable questions and commands into CloudWatch Log Insight queries and executing them against the discovered log groups.</li> </ul>"},{"location":"servers/cloudwatch-logs-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>An AWS account with CloudWatch Log Groups</li> <li>This MCP server can only be run locally on the same host as your LLM client.</li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/cloudwatch-logs-mcp-server/#available-tools","title":"Available Tools","text":"<ul> <li><code>describe_log_groups</code> - Describe log groups in the account and region, including user saved queries applicable to them. Supports Cross Account Observability.</li> <li><code>analyze_log_group</code> - Analyzes a CloudWatch log group for anomalies, top message patterns, and top error patterns within a specified time window. Log group must have at least one CloudWatch Log Anomaly Detector configured to search for anomalies.</li> <li><code>execute_log_insights_query</code> - Execute a Log Insights query against one or more log groups. Will wait for the query to complete for a configurable timeout.</li> <li><code>get_query_results</code> - Get the results of a query previously started by <code>execute_log_insights_query</code>.</li> <li><code>cancel_query</code> - Cancel an ongoing query that was previously started by <code>execute_log_insights_query</code>.</li> </ul>"},{"location":"servers/cloudwatch-logs-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<ul> <li><code>logs:Describe*</code></li> <li><code>logs:Get*</code></li> <li><code>logs:List*</code></li> <li><code>logs:StartQuery</code></li> <li><code>logs:StopQuery</code></li> </ul>"},{"location":"servers/cloudwatch-logs-mcp-server/#installation","title":"Installation","text":"<p>(DEPRECATED). Please use CloudWatch MCP Server for unified CloudWatch Telemetry related tools.</p> <p></p> <p>Example for Amazon Q Developer CLI (~/.aws/amazonq/mcp.json):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-logs-mcp-server\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.cloudwatch-logs-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"[The AWS Profile Name to use for AWS access]\",\n        \"AWS_REGION\": \"[The AWS region to run in]\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n</code></pre>"},{"location":"servers/cloudwatch-logs-mcp-server/#build-and-install-docker-image-locally-on-the-same-host-of-your-llm-client","title":"Build and install docker image locally on the same host of your LLM client","text":"<ol> <li><code>git clone https://github.com/awslabs/mcp.git</code></li> <li>Go to sub-directory 'src/cloudwatch-logs-mcp-server/'</li> <li>Run 'docker build -t awslabs/cloudwatch-logs-mcp-server:latest .'</li> </ol>"},{"location":"servers/cloudwatch-logs-mcp-server/#add-or-update-your-llm-clients-config-with-following","title":"Add or update your LLM client's config with following:","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-logs-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"AWS_PROFILE=[your data]\",\n        \"-e\", \"AWS_REGION=[your data]\",\n        \"awslabs/cloudwatch-logs-mcp-server:latest\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"servers/cloudwatch-logs-mcp-server/#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see the CONTRIBUTING.md in the monorepo root for guidelines.</p>"},{"location":"servers/cloudwatch-mcp-server/","title":"Amazon CloudWatch MCP Server","text":"<p>title: cloudwatch MCP Server</p>"},{"location":"servers/cloudwatch-mcp-server/#aws-labs-cloudwatch-mcp-server","title":"AWS Labs cloudwatch MCP Server","text":"<p>This AWS Labs Model Context Protocol (MCP) server for CloudWatch enables your troubleshooting agents to use CloudWatch data to do AI-powered root cause analysis and provide recommendations. It offers comprehensive observability tools that simplify monitoring, reduce context switching, and help teams quickly diagnose and resolve service issues. This server will provide AI agents with seamless access to CloudWatch telemetry data through standardized MCP interfaces, eliminating the need for custom API integrations and reducing context switching during troubleshooting workflows. By consolidating access to all CloudWatch capabilities, we enable powerful cross-service correlations and insights that accelerate incident resolution and improve operational visibility.</p>"},{"location":"servers/cloudwatch-mcp-server/#instructions","title":"Instructions","text":"<p>The CloudWatch MCP Server provides specialized tools to address common operational scenarios including alarm troubleshooting, understand metrics definitions, alarm recommendations and log analysis. Each tool encapsulates one or multiple CloudWatch APIs into task-oriented operations.</p>"},{"location":"servers/cloudwatch-mcp-server/#features","title":"Features","text":"<p>Alarm Based Troubleshooting - Identifies active alarms, retrieves related metrics and logs, and analyzes historical alarm patterns to determine root causes of triggered alerts. Provides context-aware recommendations for remediation.</p> <p>Log Analyzer - Analyzes a CloudWatch log group for anomalies, message patterns, and error patterns within a specified time window.</p> <p>Metric Definition Analyzer - Provides comprehensive descriptions of what metrics represent, how they're calculated, recommended statistics to use for metric data retrieval</p> <p>Alarm Recommendations - Suggests recommended alarm configurations for CloudWatch metrics, including thresholds, evaluation periods, and other alarm settings.</p>"},{"location":"servers/cloudwatch-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>An AWS account with CloudWatch Telemetry</li> <li>This MCP server can only be run locally on the same host as your LLM client.</li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/cloudwatch-mcp-server/#available-tools","title":"Available Tools","text":""},{"location":"servers/cloudwatch-mcp-server/#tools-for-cloudwatch-metrics","title":"Tools for CloudWatch Metrics","text":"<ul> <li><code>get_metric_data</code> - Retrieves detailed CloudWatch metric data for any CloudWatch metric. Use this for general CloudWatch metrics that aren't specific to Application Signals. Provides ability to query any metric namespace, dimension, and statistic</li> <li><code>get_metric_metadata</code> - Retrieves comprehensive metadata about a specific CloudWatch metric</li> <li><code>get_recommended_metric_alarms</code> - Gets recommended alarms for a CloudWatch metric</li> </ul>"},{"location":"servers/cloudwatch-mcp-server/#tools-for-cloudwatch-alarms","title":"Tools for CloudWatch Alarms","text":"<ul> <li><code>get_active_alarms</code> - Identifies currently active CloudWatch alarms across the account</li> <li><code>get_alarm_history</code> - Retrieves historical state changes and patterns for a given CloudWatch alarm</li> </ul>"},{"location":"servers/cloudwatch-mcp-server/#tools-for-cloudwatch-logs","title":"Tools for CloudWatch Logs","text":"<ul> <li><code>describe_log_groups</code> - Finds metadata about CloudWatch log groups</li> <li><code>analyze_log_group</code> - Analyzes CloudWatch logs for anomalies, message patterns, and error patterns</li> <li><code>execute_log_insights_query</code> - Executes CloudWatch Logs insights query on CloudWatch log group(s) with specified time range and query syntax, returns a unique ID used to retrieve results</li> <li><code>get_logs_insight_query_results</code> - Retrieves the results of an executed CloudWatch insights query using the query ID. It is used after <code>execute_log_insights_query</code> has been called</li> <li><code>cancel_logs_insight_query</code> - Cancels in progress CloudWatch logs insights query</li> </ul>"},{"location":"servers/cloudwatch-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<ul> <li><code>cloudwatch:DescribeAlarms</code></li> <li><code>cloudwatch:DescribeAlarmHistory</code></li> <li><code>cloudwatch:GetMetricData</code></li> <li> <p><code>cloudwatch:ListMetrics</code></p> </li> <li> <p><code>logs:DescribeLogGroups</code></p> </li> <li><code>logs:DescribeQueryDefinitions</code></li> <li><code>logs:ListLogAnomalyDetectors</code></li> <li><code>logs:ListAnomalies</code></li> <li><code>logs:StartQuery</code></li> <li><code>logs:GetQueryResults</code></li> <li><code>logs:StopQuery</code></li> </ul>"},{"location":"servers/cloudwatch-mcp-server/#installation","title":"Installation","text":"<p>Example for Amazon Q Developer CLI (~/.aws/amazonq/mcp.json):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-mcp-server\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.cloudwatch-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"[The AWS Profile Name to use for AWS access]\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n</code></pre> <p>Please reference AWS documentation to create and manage your credentials profile</p>"},{"location":"servers/cloudwatch-mcp-server/#build-and-install-docker-image-locally-on-the-same-host-of-your-llm-client","title":"Build and install docker image locally on the same host of your LLM client","text":"<ol> <li><code>git clone https://github.com/awslabs/mcp.git</code></li> <li>Go to sub-directory 'src/cloudwatch-mcp-server/'</li> <li>Run 'docker build -t awslabs/cloudwatch-mcp-server:latest .'</li> </ol>"},{"location":"servers/cloudwatch-mcp-server/#add-or-update-your-llm-clients-config-with-following","title":"Add or update your LLM client's config with following:","text":"<pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n</code></pre> <p><pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.cloudwatch-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/cloudwatch-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/cloudwatch-mcp-server/#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see the CONTRIBUTING.md in the monorepo root for guidelines.</p>"},{"location":"servers/code-doc-gen-mcp-server/","title":"AWS Labs Code Documentation Generation MCP Server","text":"<p>A Model Context Protocol (MCP) server that automatically analyzes repository structure and generates comprehensive documentation for code projects. This server uses repomix to extract project structure and creates tailored documentation based on project type.</p>"},{"location":"servers/code-doc-gen-mcp-server/#architecture","title":"Architecture","text":""},{"location":"servers/code-doc-gen-mcp-server/#how-the-server-works","title":"How the Server Works","text":"<p>The code-doc-gen-mcp-server follows this workflow:</p> <ol> <li>prepare_repository:</li> <li>Uses RepomixManager to analyze a project directory</li> <li>Runs <code>repomix</code> to generate an XML representation of the repo</li> <li>Extracts directory structure from this XML</li> <li> <p>Returns a ProjectAnalysis with the directory structure</p> </li> <li> <p>create_context:</p> </li> <li> <p>Creates a DocumentationContext with the ProjectAnalysis</p> </li> <li> <p>plan_documentation:</p> </li> <li>Uses the directory structure from DocumentationContext</li> <li> <p>Creates a DocumentationPlan with document structure and sections</p> </li> <li> <p>generate_documentation:</p> </li> <li>Generates document templates based on the plan</li> </ol>"},{"location":"servers/code-doc-gen-mcp-server/#key-components","title":"Key Components","text":"<ol> <li>RepomixManager: Manages the execution of repomix and parses its XML output to extract directory structure</li> <li>DocumentationContext: Central state container that tracks project info and documentation progress</li> <li>ProjectAnalysis: Data structure containing analyzed project metadata (languages, dependencies, etc.)</li> <li>DocumentationPlan: Structured plan for document generation with section outlines</li> <li>DocumentGenerator: Creates actual document templates based on the plan</li> </ol>"},{"location":"servers/code-doc-gen-mcp-server/#features","title":"Features","text":"<ul> <li>Project Structure Analysis: Uses repomix to analyze repository structure and extract key components</li> <li>Content Organization: Creates appropriately structured documentation based on project type</li> <li>Multiple Document Types: Supports README, API docs, backend docs, frontend docs, and more</li> <li>Integration with Other MCP Servers: Works with AWS Diagram MCP server</li> <li>Custom Document Templates: Templates for different document types with appropriate sections</li> </ul>"},{"location":"servers/code-doc-gen-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install <code>repomix</code> using <code>pip install repomix&gt;=0.2.6</code></li> </ol>"},{"location":"servers/code-doc-gen-mcp-server/#installation","title":"Installation","text":"<p>This MCP server can be added to your AWS AI assistants via the appropriate MCP configuration file:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.code-doc-gen-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.code-doc-gen-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/code-doc-gen-mcp-server/#core-concepts","title":"Core Concepts","text":""},{"location":"servers/code-doc-gen-mcp-server/#documentationcontext","title":"DocumentationContext","text":"<p>The <code>DocumentationContext</code> class maintains the state of the documentation process throughout its lifecycle:</p> <ul> <li><code>project_name</code>: Name of the project being documented</li> <li><code>working_dir</code>: Working directory for the project (source code location)</li> <li><code>repomix_path</code>: Path where documentation files will be generated</li> <li><code>status</code>: Current status of the documentation process</li> <li><code>current_step</code>: Current step in the documentation workflow</li> <li><code>analysis_result</code>: Contains the ProjectAnalysis with project metadata</li> </ul>"},{"location":"servers/code-doc-gen-mcp-server/#projectanalysis","title":"ProjectAnalysis","text":"<p>The <code>ProjectAnalysis</code> class contains detailed information about the project:</p> <ul> <li><code>project_type</code>: Type of project (e.g., \"Web Application\", \"CLI Tool\")</li> <li><code>features</code>: Key capabilities and functions of the project</li> <li><code>file_structure</code>: Project organization with directory structure</li> <li><code>dependencies</code>: Project dependencies with versions</li> <li><code>primary_languages</code>: Programming languages used in the project</li> <li><code>apis</code> (optional): API endpoint details</li> <li><code>backend</code> (optional): Backend implementation details</li> <li><code>frontend</code> (optional): Frontend implementation details</li> </ul>"},{"location":"servers/code-doc-gen-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/code-doc-gen-mcp-server/#prepare_repository","title":"prepare_repository","text":"<pre><code>async def prepare_repository(\n    project_root: str = Field(..., description='Path to the code repository'),\n    ctx: Context = None,\n) -&gt; ProjectAnalysis\n</code></pre> <p>This tool: 1. Extracts directory structure from the repository using repomix 2. Returns a ProjectAnalysis template for the MCP client to fill 3. Provides directory structure in file_structure[\"directory_structure\"]</p> <p>The MCP client then: 1. Reviews the directory structure 2. Uses read_file to examine key files 3. Fills out the ProjectAnalysis fields 4. Sets has_infrastructure_as_code=True if CDK/Terraform code is detected</p>"},{"location":"servers/code-doc-gen-mcp-server/#create_context","title":"create_context","text":"<pre><code>async def create_context(\n    project_root: str = Field(..., description='Path to the code repository'),\n    analysis: ProjectAnalysis = Field(..., description='Completed ProjectAnalysis'),\n    ctx: Context = None,\n) -&gt; DocumentationContext\n</code></pre> <p>Creates a DocumentationContext from the completed ProjectAnalysis.</p>"},{"location":"servers/code-doc-gen-mcp-server/#plan_documentation","title":"plan_documentation","text":"<pre><code>async def plan_documentation(\n    doc_context: DocumentationContext,\n    ctx: Context,\n) -&gt; DocumentationPlan\n</code></pre> <p>Creates a documentation plan based on the project analysis, determining what document types are needed and creating appropriate document structures.</p>"},{"location":"servers/code-doc-gen-mcp-server/#generate_documentation","title":"generate_documentation","text":"<pre><code>async def generate_documentation(\n    plan: DocumentationPlan,\n    doc_context: DocumentationContext,\n    ctx: Context,\n) -&gt; List[GeneratedDocument]\n</code></pre> <p>Generates document structures with sections for the MCP client to fill with content.</p>"},{"location":"servers/code-doc-gen-mcp-server/#integration-with-other-mcp-servers","title":"Integration with Other MCP Servers","text":"<p>This MCP server is designed to work with:</p> <ul> <li>AWS Diagram MCP Server: For generating architecture diagrams</li> <li>AWS CDK MCP Server: For documenting CDK infrastructure code</li> </ul>"},{"location":"servers/code-doc-gen-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License, Version 2.0. See the LICENSE file for details.</p>"},{"location":"servers/core-mcp-server/","title":"Core MCP Server","text":"<p>MCP server that provides a starting point for using the following awslabs MCP servers - awslabs.cdk-mcp-server - awslabs.bedrock-kb-retrieval-mcp-server - awslabs.nova-canvas-mcp-server - awslabs.aws-pricing-mcp-server - awslabs.aws-documentation-mcp-server - awslabs.aws-diagram-mcp-server</p>"},{"location":"servers/core-mcp-server/#features","title":"Features","text":""},{"location":"servers/core-mcp-server/#planning-and-orchestration","title":"Planning and orchestration","text":"<ul> <li>Provides tool for prompt understanding and translation to AWS services</li> </ul>"},{"location":"servers/core-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12 or higher</li> <li>uv - Fast Python package installer and resolver</li> <li>AWS credentials configured with Bedrock access</li> <li>Node.js (for UVX installation support)</li> </ul>"},{"location":"servers/core-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.core-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/core-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.core-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/core-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/core-mcp-server/#tools-and-resources","title":"Tools and Resources","text":"<p>The server exposes the following tools through the MCP interface:</p> <ul> <li><code>prompt_understanding</code> - Helps to provide guidance and planning support when building AWS Solutions for the given prompt</li> </ul>"},{"location":"servers/cost-explorer-mcp-server/","title":"Cost Explorer MCP Server","text":"<p>MCP server for analyzing AWS costs and usage data through the AWS Cost Explorer API.</p>"},{"location":"servers/cost-explorer-mcp-server/#features","title":"Features","text":""},{"location":"servers/cost-explorer-mcp-server/#analyze-aws-costs-and-usage-data","title":"Analyze AWS costs and usage data","text":"<ul> <li>Get detailed breakdown of your AWS costs by service, region, and other dimensions</li> <li>Understand how costs are distributed across various services</li> <li>Query historical cost data for specific time periods</li> <li>Filter costs by various dimensions, tags, and cost categories</li> </ul>"},{"location":"servers/cost-explorer-mcp-server/#compare-costs-between-time-periods","title":"Compare costs between time periods","text":"<ul> <li>NEW AWS Feature: Leverage AWS Cost Explorer's new Cost Comparison feature</li> <li>Compare costs between two time periods to identify changes and trends</li> <li>Analyze cost drivers to understand what caused cost increases or decreases</li> <li>Get detailed insights into the top 10 most significant cost change drivers automatically</li> <li>Identify specific usage types, discount changes, and infrastructure changes affecting costs</li> </ul>"},{"location":"servers/cost-explorer-mcp-server/#forecast-future-costs","title":"Forecast future costs","text":"<ul> <li>Generate cost forecasts based on historical usage patterns</li> <li>Get predictions with confidence intervals (80% or 95%)</li> <li>Support for daily and monthly forecast granularity</li> <li>Plan budgets and anticipate future AWS spending</li> </ul>"},{"location":"servers/cost-explorer-mcp-server/#query-cost-data-with-natural-language","title":"Query cost data with natural language","text":"<ul> <li>Ask questions about your AWS costs in plain English</li> <li>Get instant answers about your AWS spending patterns</li> <li>Retrieve historical cost data with simple queries</li> </ul>"},{"location":"servers/cost-explorer-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS Cost Explorer</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to access AWS Cost Explorer API</li> </ol>"},{"location":"servers/cost-explorer-mcp-server/#installation","title":"Installation","text":"<p>Here are some ways you can work with MCP across AWS, and we'll be adding support to more products including Amazon Q Developer CLI soon: (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cost-explorer-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.cost-explorer-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"your-aws-profile\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/cost-explorer-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=\nAWS_SECRET_ACCESS_KEY=\nAWS_SESSION_TOKEN=\n</code></pre> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cost-explorer-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env-file\",\n        \"/full/path/to/file/above/.env\",\n        \"awslabs/cost-explorer-mcp-server:latest\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/cost-explorer-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access the AWS Cost Explorer API. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for accessing AWS services.</p>"},{"location":"servers/cost-explorer-mcp-server/#cost-considerations","title":"Cost Considerations","text":"<p>Important: AWS Cost Explorer API incurs charges on a per-request basis. Each API call made by this MCP server will result in charges to your AWS account.</p> <ul> <li>Cost Explorer API Pricing: The AWS Cost Explorer API lets you directly access the interactive, ad-hoc query engine that powers AWS Cost Explorer. Each request will incur a cost of $0.01.</li> <li>Each tool invocation that queries Cost Explorer (get_dimension_values, get_tag_values, get_cost_and_usage) will generate at least one billable API request</li> <li>Complex queries with multiple filters or large date ranges may result in multiple API calls</li> </ul> <p>For current pricing information, please refer to the AWS Cost Explorer Pricing page.</p>"},{"location":"servers/cost-explorer-mcp-server/#security-considerations","title":"Security Considerations","text":""},{"location":"servers/cost-explorer-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<p>The following IAM permissions are required for this MCP server: - ce:GetCostAndUsage - ce:GetDimensionValues - ce:GetTags - ce:GetCostForecast - ce:GetCostAndUsageComparisons - ce:GetCostComparisonDrivers</p>"},{"location":"servers/cost-explorer-mcp-server/#available-tools","title":"Available Tools","text":"<p>The Cost Explorer MCP Server provides the following tools:</p> <ol> <li><code>get_today_date</code> - Get the current date and month to determine relevent data when answering last month.</li> <li><code>get_dimension_values</code> - Get available values for a specific dimension (e.g., SERVICE, REGION)</li> <li><code>get_tag_values</code> - Get available values for a specific tag key</li> <li><code>get_cost_and_usage</code> - Retrieve AWS cost and usage data with filtering and grouping options</li> <li><code>get_cost_and_usage_comparisons</code> - Compare costs between two time periods to identify changes and trends</li> <li><code>get_cost_comparison_drivers</code> - Analyze what drove cost changes between periods (top 10 most significant drivers)</li> <li><code>get_cost_forecast</code> - Generate cost forecasts based on historical usage patterns</li> </ol>"},{"location":"servers/cost-explorer-mcp-server/#example-usage","title":"Example Usage","text":"<p>Here are some examples of how to use the Cost Explorer MCP Server through natural language queries:</p>"},{"location":"servers/cost-explorer-mcp-server/#cost-analysis-examples","title":"Cost Analysis Examples","text":"<pre><code>Show me my AWS costs for the last 3 months grouped by service in us-east-1 region\nBreak down my S3 costs by storage class for Q1 2025\nShow me costs for production resources tagged with Environment=prod\nWhat were my costs for reserved instances vs on-demand in May?\nWhat was my EC2 instance usage by instance type?\n</code></pre>"},{"location":"servers/cost-explorer-mcp-server/#cost-comparison-examples","title":"Cost Comparison Examples","text":"<pre><code>Compare my AWS costs between April and May 2025\nHow did my EC2 costs change from last month to this month?\nWhy did my AWS bill increase in June compared to May?\nWhat caused the spike in my S3 costs last month?\n</code></pre>"},{"location":"servers/cost-explorer-mcp-server/#forecasting-examples","title":"Forecasting Examples","text":"<pre><code>Forecast my AWS costs for next month\nPredict my EC2 spending for the next quarter\nWhat will my total AWS bill be for the rest of 2025?\n</code></pre>"},{"location":"servers/cost-explorer-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"servers/documentdb-mcp-server/","title":"AWS DocumentDB MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for AWS DocumentDB that enables AI assistants to interact with DocumentDB databases.</p>"},{"location":"servers/documentdb-mcp-server/#overview","title":"Overview","text":"<p>The DocumentDB MCP Server provides tools to connect to and query AWS DocumentDB databases. It serves as a bridge between AI assistants and AWS DocumentDB, allowing for safe and efficient database operations through the Model Context Protocol (MCP).</p>"},{"location":"servers/documentdb-mcp-server/#features","title":"Features","text":"<ul> <li>Connection Management: Establish and maintain connections to DocumentDB clusters</li> <li>Database Management: List databases and retrieve database statistics</li> <li>Collection Management: List, create, drop collections and retrieve collection statistics</li> <li>Document Operations: Query, insert, update, and delete documents</li> <li>Aggregation Pipelines: Execute DocumentDB aggregation pipelines</li> <li>Query Planning: Get explanations of how operations will be executed</li> <li>Schema Analysis: Analyze collection schemas by sampling documents</li> <li>Read-Only Mode: Optional security feature to restrict operations to read-only operations</li> </ul>"},{"location":"servers/documentdb-mcp-server/#available-tools","title":"Available Tools","text":"<p>The DocumentDB MCP Server provides the following tools:</p>"},{"location":"servers/documentdb-mcp-server/#connection-management","title":"Connection Management","text":"<ul> <li><code>connect</code>: Connect to a DocumentDB cluster and get a connection ID</li> <li><code>disconnect</code>: Close an active connection</li> </ul>"},{"location":"servers/documentdb-mcp-server/#database-management","title":"Database Management","text":"<ul> <li><code>listDatabases</code>: List all available databases in the DocumentDB cluster</li> <li><code>getDatabaseStats</code>: Get statistics about a DocumentDB database</li> </ul>"},{"location":"servers/documentdb-mcp-server/#collection-management","title":"Collection Management","text":"<ul> <li><code>listCollections</code>: List collections in a database</li> <li><code>createCollection</code>: Create a new collection in a database (blocked in read-only mode)</li> <li><code>dropCollection</code>: Drop a collection from a database (blocked in read-only mode)</li> <li><code>getCollectionStats</code>: Get statistics about a collection</li> <li><code>countDocuments</code>: Count documents in a collection</li> <li><code>analyzeSchema</code>: Analyze the schema of a collection by sampling documents and providing field coverage</li> </ul>"},{"location":"servers/documentdb-mcp-server/#document-operations","title":"Document Operations","text":"<ul> <li><code>find</code>: Query documents from a collection</li> <li><code>aggregate</code>: Run aggregation pipelines</li> <li><code>insert</code>: Insert documents (blocked in read-only mode)</li> <li><code>update</code>: Update documents (blocked in read-only mode)</li> <li><code>delete</code>: Delete documents (blocked in read-only mode)</li> </ul>"},{"location":"servers/documentdb-mcp-server/#query-planning","title":"Query Planning","text":"<ul> <li><code>explainOperation</code>: Get an explanation of how an operation will be executed</li> </ul>"},{"location":"servers/documentdb-mcp-server/#server-configuration","title":"Server Configuration","text":""},{"location":"servers/documentdb-mcp-server/#starting-the-server","title":"Starting the Server","text":"<pre><code># Basic usage\npython -m awslabs.documentdb_mcp_server.server\n\n# With custom port and host\npython -m awslabs.documentdb_mcp_server.server --port 9000 --host 0.0.0.0\n\n# With write operations enabled\npython -m awslabs.documentdb_mcp_server.server --allow-write\n</code></pre>"},{"location":"servers/documentdb-mcp-server/#command-line-options","title":"Command Line Options","text":"Option Description Default <code>--log-level</code> Set logging level (TRACE, DEBUG, INFO, etc.) INFO <code>--connection-timeout</code> Idle connection timeout in minutes 30 <code>--allow-write</code> Enable write operations (otherwise defaults to read-only mode) False"},{"location":"servers/documentdb-mcp-server/#read-only-mode","title":"Read-Only Mode","text":"<p>By default, the server runs in read-only mode that only allows read operations. This enhances security by preventing any modifications to the database. In read-only mode:</p> <ul> <li>Read operations (<code>find</code>, <code>aggregate</code>, <code>listCollections</code>) work normally</li> <li>Write operations (<code>insert</code>, <code>update</code>, <code>delete</code>) are blocked and return a permission error</li> <li>Connection management operations (<code>connect</code>, <code>disconnect</code>) work normally</li> </ul> <p>This mode is particularly useful for: - Demonstration environments - Security-sensitive applications - Integration with public-facing AI assistants - Protecting production databases from unintended modifications</p>"},{"location":"servers/documentdb-mcp-server/#usage-examples","title":"Usage Examples","text":""},{"location":"servers/documentdb-mcp-server/#basic-connection-and-query-read-only-operations","title":"Basic Connection and Query (Read-Only Operations)","text":"<pre><code># Connect to a DocumentDB cluster\nconnection_result = await use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"connect\",\n    arguments={\n        \"connection_string\": \"mongodb://&lt;username&gt;:&lt;password&gt;@docdb-cluster.cluster-xyz.us-west-2.docdb.amazonaws.com:27017/?tls=true&amp;tlsCAFile=global-bundle.pem\"\n    }\n)\nconnection_id = connection_result[\"connection_id\"]\n\n# Query documents\nquery_result = await use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"find\",\n    arguments={\n        \"connection_id\": connection_id,\n        \"database\": \"my_database\",\n        \"collection\": \"users\",\n        \"query\": {\"active\": True},\n        \"limit\": 5\n    }\n)\n\n# Close the connection when done\nawait use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"disconnect\",\n    arguments={\"connection_id\": connection_id}\n)\n</code></pre>"},{"location":"servers/documentdb-mcp-server/#enabling-write-operations","title":"Enabling Write Operations","text":"<p>To enable write operations, start the server with the <code>--allow-write</code> flag:</p> <pre><code>python -m awslabs.documentdb_mcp_server.server --allow-write\n</code></pre> <p>When the server is running with write operations enabled:</p> <pre><code># This operation will succeed\nquery_result = await use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"find\",\n    arguments={\n        \"connection_id\": connection_id,\n        \"database\": \"my_database\",\n        \"collection\": \"users\",\n        \"query\": {\"active\": True}\n    }\n)\n\n# This operation will now succeed when --allow-write is used\ninsert_result = await use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"insert\",\n    arguments={\n        \"connection_id\": connection_id,\n        \"database\": \"my_database\",\n        \"collection\": \"users\",\n        \"documents\": {\"name\": \"New User\", \"active\": True}\n    }\n)\n\n# Without the --allow-write flag, you would receive this error:\n# ValueError: \"Operation not permitted: Server is configured in read-only mode. Use --allow-write flag when starting the server to enable write operations.\"\n</code></pre>"},{"location":"servers/documentdb-mcp-server/#configure-in-your-mcp-client","title":"Configure in your MCP client","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit ~/.aws/amazonq/mcp.json):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.documentdb-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.documentdb-mcp-server@latest\",\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/documentdb-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Network access to your DocumentDB cluster</li> <li>SSL/TLS certificate if your cluster requires TLS (typically <code>global-bundle.pem</code>)</li> </ul>"},{"location":"servers/dynamodb-mcp-server/","title":"AWS DynamoDB MCP Server","text":"<p>The official MCP Server for interacting with AWS DynamoDB</p>"},{"location":"servers/dynamodb-mcp-server/#available-mcp-tools","title":"Available MCP Tools","text":""},{"location":"servers/dynamodb-mcp-server/#table-operations","title":"Table Operations","text":"<ul> <li><code>create_table</code> - Creates a new DynamoDB table with optional secondary indexes</li> <li><code>delete_table</code> - Deletes a table and all of its items</li> <li><code>describe_table</code> - Returns table information including status, creation time, key schema and indexes</li> <li><code>list_tables</code> - Returns a paginated list of table names in your account</li> <li><code>update_table</code> - Modifies table settings including provisioned throughput, global secondary indexes, and DynamoDB Streams configuration</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#item-operations","title":"Item Operations","text":"<ul> <li><code>get_item</code> - Returns attributes for an item with the given primary key</li> <li><code>put_item</code> - Creates a new item or replaces an existing item in a table</li> <li><code>update_item</code> - Edits an existing item's attributes, or adds a new item if it does not already exist</li> <li><code>delete_item</code> - Deletes a single item in a table by primary key</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#query-and-scan-operations","title":"Query and Scan Operations","text":"<ul> <li><code>query</code> - Returns items from a table or index matching a partition key value, with optional sort key filtering</li> <li><code>scan</code> - Returns items and attributes by scanning a table or secondary index</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#backup-and-recovery","title":"Backup and Recovery","text":"<ul> <li><code>create_backup</code> - Creates a backup of a DynamoDB table</li> <li><code>describe_backup</code> - Describes an existing backup of a table</li> <li><code>list_backups</code> - Returns a list of table backups</li> <li><code>restore_table_from_backup</code> - Creates a new table from a backup</li> <li><code>describe_continuous_backups</code> - Returns continuous backup and point in time recovery status</li> <li><code>update_continuous_backups</code> - Enables or disables point in time recovery</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#time-to-live-ttl","title":"Time to Live (TTL)","text":"<ul> <li><code>update_time_to_live</code> - Enables or disables Time to Live (TTL) for the specified table</li> <li><code>describe_time_to_live</code> - Returns the Time to Live (TTL) settings for a table</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#export-operations","title":"Export Operations","text":"<ul> <li><code>describe_export</code> - Returns information about a table export</li> <li><code>list_exports</code> - Returns a list of table exports</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#tags-and-resource-policies","title":"Tags and Resource Policies","text":"<ul> <li><code>put_resource_policy</code> - Attaches a resource-based policy document to a table or stream</li> <li><code>get_resource_policy</code> - Returns the resource-based policy document attached to a table or stream</li> <li><code>tag_resource</code> - Adds tags to a DynamoDB resource</li> <li><code>untag_resource</code> - Removes tags from a DynamoDB resource</li> <li><code>list_tags_of_resource</code> - Returns tags for a DynamoDB resource</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#misc","title":"Misc","text":"<ul> <li><code>describe_limits</code> - Returns the current provisioned-capacity quotas for your AWS account</li> <li><code>describe_endpoints</code> - Returns DynamoDB endpoints for the current region</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#instructions","title":"Instructions","text":"<p>The official MCP Server for interacting with AWS DynamoDB provides a comprehensive set of tools for managing DynamoDB resources. Each tool maps directly to DynamoDB API operations and supports all relevant parameters.</p> <p>To use these tools, ensure you have proper AWS credentials configured with appropriate permissions for DynamoDB operations. The server will automatically use credentials from environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN) or other standard AWS credential sources.</p> <p>All tools support an optional <code>region_name</code> parameter to specify which AWS region to operate in. If not provided, it will use the AWS_REGION environment variable or default to 'us-west-2'.</p>"},{"location":"servers/dynamodb-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services</li> <li>Consider setting up Read-only permission if you don't want the LLM to modify any resources</li> </ol>"},{"location":"servers/dynamodb-mcp-server/#installation","title":"Installation","text":"<p>Add the MCP to your favorite agentic tools. (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.dynamodb-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.dynamodb-mcp-server@latest\"],\n      \"env\": {\n        \"DDB-MCP-READONLY\": \"true\",\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/dynamodb-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.dynamodb-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/dynamodb-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/ecs-mcp-server/","title":"Amazon ECS MCP Server","text":"<p>An MCP server for containerizing applications, deploying applications to Amazon Elastic Container Service (ECS), troubleshooting ECS deployments, and managing ECS resources. This server enables AI assistants to help users with the full lifecycle of containerized applications on AWS.</p>"},{"location":"servers/ecs-mcp-server/#features","title":"Features","text":"<ul> <li>Containerization Guidance: Provides best practices and guidance for containerizing web applications</li> <li>ECS Deployment: Deploy containerized applications to AWS ECS using Fargate</li> <li>Load Balancer Integration: Automatically configure Application Load Balancers (ALBs) for web traffic</li> <li>Infrastructure as Code: Generate and apply CloudFormation templates for ECS infrastructure</li> <li>URL Management: Return public ALB URLs for immediate access to deployed applications</li> <li>Circuit Breaker: Implement deployment circuit breaker with automatic rollback</li> <li>Container Insights: Enable enhanced container insights for monitoring</li> <li>VPC Endpoints: Configure VPC endpoints for secure access to AWS services without internet exposure</li> <li>Security Best Practices: Implement AWS security best practices for container deployments</li> <li>Resource Management: List and explore ECS resources such as task definitions, services, clusters, and tasks</li> <li>ECR Integration: View repositories and container images in Amazon ECR</li> </ul> <p>Customers can use the <code>containerize_app</code> tool to help them containerize their applications with best practices and deploy them to Amazon ECS. The <code>create_ecs_infrastructure</code> tool automates infrastructure deployment using CloudFormation, while <code>get_deployment_status</code> returns the status of deployments and provide the URL of the set up Application Load Balancer. When resources are no longer needed, the <code>delete_ecs_infrastructure</code> tool allows for easy cleanup and removal of all deployed components.</p> <p>Customers can list and view their ECS resources (clusters, services, tasks, task definitions) and access their ECR resources (container images) using the <code>ecs_resource_management</code> tool. When running into ECS deployment issues, they can use the <code>ecs_troubleshooting_tool</code> to diagnose and resolve common problems.</p>"},{"location":"servers/ecs-mcp-server/#installation","title":"Installation","text":"<pre><code># Install using uv\nuv pip install awslabs.ecs-mcp-server\n\n# Or install using pip\npip install awslabs.ecs-mcp-server\n</code></pre> <p>You can also run the MCP server directly from a local clone of the GitHub repository:</p> <pre><code># Clone the awslabs repository\ngit clone https://github.com/awslabs/mcp.git\n\n# Run the server directly using uv\nuv --directory /path/to/ecs-mcp-server/src/ecs-mcp-server/awslabs/ecs_mcp_server run main.py\n</code></pre>"},{"location":"servers/ecs-mcp-server/#usage-environments","title":"Usage Environments","text":"<p>The ECS MCP Server is currently in development and is designed for the following environments:</p> <ul> <li>Development and Prototyping: Ideal for local application development, testing containerization approaches, and rapidly iterating on deployment configurations.</li> <li>Learning and Exploration: Excellent for users who want to learn about containerization, ECS, and AWS infrastructure.</li> <li>Testing and Staging: Suitable for integration testing and pre-production validation in non-critical environments.</li> </ul> <p>Not Recommended For: - Production Workloads: As this tool is still in active development, it is not suited for production deployments or business-critical applications. - Regulated or Sensitive Workloads: Not suitable for applications handling sensitive data or subject to regulatory compliance requirements.</p> <p>Important Note on Troubleshooting Tools: Even the troubleshooting tools should be used with caution in production environments. Always set <code>ALLOW_SENSITIVE_DATA=false</code> and <code>ALLOW_WRITE=false</code> flags when connecting to production accounts to prevent accidental exposure of sensitive information or unintended infrastructure modifications.</p>"},{"location":"servers/ecs-mcp-server/#production-considerations","title":"Production Considerations","text":"<p>While the ECS MCP Server is primarily designed for development, testing, and non-critical environments, certain components can be considered for controlled production use with appropriate safeguards.</p>"},{"location":"servers/ecs-mcp-server/#allowlisted-actions-for-production","title":"Allowlisted Actions for Production","text":"<p>The following operations are read-only and relatively safe for production environments when used with appropriate IAM permissions. Note: they can return sensitive information, so ensure <code>ALLOW_SENSITIVE_DATA=false</code> is set in production configurations.</p> Tool Operation Production Safety <code>ecs_resource_management</code> List operations (clusters, services, tasks) \u2705 Safe - Read-only <code>ecs_resource_management</code> Describe operations (clusters, services, tasks) \u2705 Safe - Read-only <code>ecs_troubleshooting_tool</code> <code>fetch_service_events</code> \u2705 Safe - Read-only <code>ecs_troubleshooting_tool</code> <code>get_ecs_troubleshooting_guidance</code> \u2705 Safe - Read-only <code>get_deployment_status</code> Status checking \u2705 Safe - Read-only <p>The following operations modify resources and should be used with extreme caution in production:</p> Tool Operation Production Safety <code>create_ecs_infrastructure</code> Creating resources \u26a0\ufe0f High Risk - Creates infrastructure <code>delete_ecs_infrastructure</code> Deleting resources \ud83d\uded1 Dangerous - Deletes infrastructure <code>containerize_app</code> Generate container configs \ud83d\udfe1 Medium Risk - Local changes only <code>ecs_resource_management</code> Create operations (clusters, services, tasks) \u26a0\ufe0f High Risk - Creates resources <code>ecs_resource_management</code> Update operations (services, tasks, settings) \u26a0\ufe0f High Risk - Modifies resources <code>ecs_resource_management</code> Delete operations (clusters, services, tasks) \ud83d\uded1 Dangerous - Deletes resources <code>ecs_resource_management</code> Run/Start/Stop task operations \u26a0\ufe0f High Risk - Affects running workloads"},{"location":"servers/ecs-mcp-server/#when-to-consider-production-use","title":"When to Consider Production Use","text":"<p>The ECS MCP Server may be appropriate for production environments in the following scenarios:</p> <ol> <li>Read-only monitoring: Using resource management tools with read-only IAM policies</li> <li>Troubleshooting non-critical issues: Using diagnostic tools to gather logs and status information</li> <li>Sandbox or isolated environments: Using deployment tools in production-like environments that are isolated from core services</li> </ol>"},{"location":"servers/ecs-mcp-server/#when-to-avoid-production-use","title":"When to Avoid Production Use","text":"<p>Avoid using ECS MCP Server in production for:</p> <ol> <li>Critical business infrastructure</li> <li>Applications handling sensitive customer data</li> <li>High-throughput or high-availability services</li> <li>Regulated workloads with compliance requirements</li> <li>Infrastructure lacking proper backup and disaster recovery procedures</li> </ol>"},{"location":"servers/ecs-mcp-server/#configuration","title":"Configuration","text":"<p>Add the ECS MCP Server to your MCP client configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.ecs-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"--from\", \"awslabs-ecs-mcp-server\", \"ecs-mcp-server\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\", // Optional - uses your local AWS configuration if not specified\n        \"AWS_REGION\": \"your-aws-region\", // Optional - uses your local AWS configuration if not specified\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"FASTMCP_LOG_FILE\": \"/path/to/ecs-mcp-server.log\",\n        \"ALLOW_WRITE\": \"false\",\n        \"ALLOW_SENSITIVE_DATA\": \"false\"\n      }\n    }\n  }\n}\n</code></pre> <p>If running from a local repository, configure the MCP client like this:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.ecs-mcp-server\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/ecs-mcp-server/src/ecs-mcp-server/awslabs/ecs_mcp_server\",\n        \"run\",\n        \"main.py\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"your-aws-region\",\n        \"FASTMCP_LOG_LEVEL\": \"DEBUG\",\n        \"FASTMCP_LOG_FILE\": \"/path/to/ecs-mcp-server.log\",\n        \"ALLOW_WRITE\": \"false\",\n        \"ALLOW_SENSITIVE_DATA\": \"false\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/ecs-mcp-server/#security-controls","title":"Security Controls","text":"<p>The ECS MCP Server includes security controls in your MCP client configuration to prevent accidental changes to infrastructure and limit access to sensitive data:</p>"},{"location":"servers/ecs-mcp-server/#allow_write","title":"ALLOW_WRITE","text":"<p>Controls whether write operations (creating or deleting infrastructure) are allowed.</p> <pre><code># Enable write operations\n\"ALLOW_WRITE\": \"true\"\n\n# Disable write operations (default)\n\"ALLOW_WRITE\": \"false\"\n</code></pre>"},{"location":"servers/ecs-mcp-server/#allow_sensitive_data","title":"ALLOW_SENSITIVE_DATA","text":"<p>Controls whether tools that return logs and detailed resource information are allowed.</p> <pre><code># Enable access to sensitive data\n\"ALLOW_SENSITIVE_DATA\": \"true\"\n\n# Disable access to sensitive data (default)\n\"ALLOW_SENSITIVE_DATA\": \"false\"\n</code></pre>"},{"location":"servers/ecs-mcp-server/#iam-best-practices","title":"IAM Best Practices","text":"<p>We strongly recommend creating dedicated IAM roles with least-privilege permissions when using the ECS MCP Server:</p> <ol> <li>Create a dedicated IAM role specifically for ECS MCP Server operations</li> <li>Apply least-privilege permissions by attaching only the necessary policies based on your use case</li> <li>Use scoped-down resource policies whenever possible</li> <li>Apply a permission boundary to limit the maximum permissions</li> </ol> <p>For detailed example IAM policies tailored for different ECS MCP Server use cases (read-only monitoring, troubleshooting, deployment, and service-specific access), see EXAMPLE_IAM_POLICIES.md.</p>"},{"location":"servers/ecs-mcp-server/#mcp-tools","title":"MCP Tools","text":""},{"location":"servers/ecs-mcp-server/#deployment-tools","title":"Deployment Tools","text":"<p>These tools help you containerize applications and deploy them to Amazon ECS with proper infrastructure setup and monitoring.</p> <ul> <li>containerize_app: Generates Dockerfile and container configurations for web applications</li> <li>create_ecs_infrastructure: Creates AWS infrastructure needed to deploy your containerized application using ECS. This includes:</li> <li>Application Load Balancer (ALB) with public-facing endpoints</li> <li>Network security groups with appropriate inbound/outbound rules</li> <li>IAM roles and policies with least-privilege permissions</li> <li>VPC configurations with public and private subnets (if needed)</li> <li>S3 Gateway endpoint associations for ECR image pulls</li> <li>ECS cluster with capacity provider settings</li> <li>Task definition with CPU/memory allocations and container configs</li> <li>Service configuration with desired count and auto-scaling policies</li> <li>Health check configuration and deployment circuit breakers</li> <li>get_deployment_status: Gets the status of an ECS deployment and returns the ALB URL</li> <li>delete_ecs_infrastructure: Deletes the AWS infrastructure created by the ECS MCP Server</li> </ul>"},{"location":"servers/ecs-mcp-server/#troubleshooting-tool","title":"Troubleshooting Tool","text":"<p>The troubleshooting tool helps diagnose and resolve common ECS deployment issues stemming from infrastructure, service, task, and network configuration.</p> <ul> <li>ecs_troubleshooting_tool: Consolidated tool with the following actions:</li> <li>get_ecs_troubleshooting_guidance: Initial assessment and troubleshooting path recommendation</li> <li>fetch_cloudformation_status: Infrastructure-level diagnostics for CloudFormation stacks</li> <li>fetch_service_events: Service-level diagnostics for ECS services</li> <li>fetch_task_failures: Task-level diagnostics for ECS task failures</li> <li>fetch_task_logs: Application-level diagnostics through CloudWatch logs</li> <li>detect_image_pull_failures: Specialized tool for detecting container image pull failures</li> <li>fetch_network_configuration: Network-level diagnostics for ECS deployments including VPC, subnets, security groups, and load balancers</li> </ul>"},{"location":"servers/ecs-mcp-server/#resource-management","title":"Resource Management","text":"<p>This tool provides comprehensive access to Amazon ECS resources to help you monitor, understand, and manage your deployment environment.</p> <ul> <li>ecs_resource_management: Execute operations on ECS resources with a consistent interface:</li> <li>Read Operations (always available):<ul> <li>Clusters: List all clusters, describe specific cluster details</li> <li>Services: List services in a cluster, describe service configuration</li> <li>Tasks: List running or stopped tasks, describe task details and status</li> <li>Task Definitions: List task definition families, describe specific task definition revisions</li> <li>Container Instances: List container instances, describe instance health and capacity</li> <li>Capacity Providers: List and describe capacity providers associated with clusters</li> <li>ECR repositories and container images</li> </ul> </li> <li>Write Operations (requires ALLOW_WRITE=true):<ul> <li>Create resources: Create clusters, services, task sets, and capacity providers</li> <li>Update resources: Update service configurations, task protection settings, and cluster settings</li> <li>Delete resources: Delete clusters, services, task definitions, and capacity providers</li> <li>Register/Deregister: Register and deregister task definitions and container instances</li> <li>Task Management: Run tasks, start tasks, stop tasks, and execute commands on running tasks</li> <li>Tag Management: Tag and untag resources</li> </ul> </li> </ul> <p>The resource management tool enforces permission checks for write operations. Operations that modify resources require the ALLOW_WRITE environment variable to be set to true.</p>"},{"location":"servers/ecs-mcp-server/#example-prompts","title":"Example Prompts","text":""},{"location":"servers/ecs-mcp-server/#containerization-and-deployment","title":"Containerization and Deployment","text":"<ul> <li>\"Containerize this Node.js app and deploy it to AWS\"</li> <li>\"Deploy this Flask application to Amazon ECS\"</li> <li>\"Create an ECS deployment for this web application with auto-scaling\"</li> <li>\"Set up a containerized environment for this Django app on Amazon ECS\"</li> <li>\"List all my ECS clusters\"</li> <li>\"Show me details for my-cluster\"</li> </ul>"},{"location":"servers/ecs-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>\"Help me troubleshoot my ECS deployment\"</li> <li>\"My ECS tasks keep failing, can you diagnose the issue?\"</li> <li>\"The ALB health check is failing for my ECS service\"</li> <li>\"Why can't I access my deployed application?\"</li> <li>\"Check what's wrong with my CloudFormation stack\"</li> </ul>"},{"location":"servers/ecs-mcp-server/#resource-management_1","title":"Resource Management","text":"<ul> <li>\"Show me my ECS clusters\"</li> <li>\"List all running tasks in my ECS cluster\"</li> <li>\"Describe my ECS service configuration\"</li> <li>\"Get information about my task definition\"</li> <li>\"Create a new ECS cluster\"</li> <li>\"Update my service configuration\"</li> <li>\"Register a new task definition\"</li> <li>\"Delete an unused task definition\"</li> <li>\"Run a task in my cluster\"</li> <li>\"Stop a running task\"</li> </ul>"},{"location":"servers/ecs-mcp-server/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>AWS credentials with permissions for ECS, ECR, CloudFormation, and related services</li> <li>Docker (for local containerization testing)</li> </ul>"},{"location":"servers/ecs-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache-2.0 License.</p>"},{"location":"servers/eks-mcp-server/","title":"Amazon EKS MCP Server","text":"<p>The Amazon EKS MCP server provides AI code assistants with resource management tools and real-time cluster state visibility. This provides large language models (LLMs) with essential tooling and contextual awareness, enabling AI code assistants to streamline application development through tailored guidance \u2014 from initial setup through production optimization and troubleshooting.</p> <p>Integrating the EKS MCP server into AI code assistants enhances development workflow across all phases, from simplifying initial cluster setup with automated prerequisite creation and application of best practices. Further, it streamlines application deployment with high-level workflows and automated code generation. Finally, it accelerates troubleshooting through intelligent debugging tools and knowledge base access. All of this simplifies complex operations through natural language interactions in AI code assistants.</p>"},{"location":"servers/eks-mcp-server/#key-features","title":"Key features","text":"<ul> <li>Enables users of AI code assistants to create new EKS clusters, complete with prerequisites such as dedicated VPCs, networking, and EKS Auto Mode node pools, by translating requests into the appropriate AWS CloudFormation actions.</li> <li>Provides the ability to deploy containerized applications by applying existing Kubernetes YAML files or by generating new deployment and service manifests based on user-provided parameters.</li> <li>Supports full lifecycle management of individual Kubernetes resources (such as Pods, Services, and Deployments) within EKS clusters, enabling create, read, update, patch, and delete operations.</li> <li>Provides the ability to list Kubernetes resources with filtering by namespace, labels, and fields, simplifying the process for both users and LLMs to gather information about the state of Kubernetes applications and EKS infrastructure.</li> <li>Facilitates operational tasks such as retrieving logs from specific pods and containers or fetching Kubernetes events related to particular resources, supporting troubleshooting and monitoring for both direct users and AI-driven workflows.</li> <li>Enables users to troubleshoot issues with an EKS cluster.</li> </ul>"},{"location":"servers/eks-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install Python 3.10+</li> <li>Install the <code>uv</code> package manager</li> <li>Install and configure the AWS CLI with credentials</li> </ul>"},{"location":"servers/eks-mcp-server/#setup","title":"Setup","text":"<p>Add these IAM policies to the IAM role or user that you use to manage your EKS cluster resources.</p>"},{"location":"servers/eks-mcp-server/#read-only-operations-policy","title":"Read-Only Operations Policy","text":"<p>For read operations, the following permissions are required:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"eks:DescribeCluster\",\n        \"cloudformation:DescribeStacks\",\n        \"cloudwatch:GetMetricData\",\n        \"logs:StartQuery\",\n        \"logs:GetQueryResults\",\n        \"iam:GetRole\",\n        \"iam:GetRolePolicy\",\n        \"iam:ListRolePolicies\",\n        \"iam:ListAttachedRolePolicies\",\n        \"iam:GetPolicy\",\n        \"iam:GetPolicyVersion\",\n        \"eks-mcpserver:QueryKnowledgeBase\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"servers/eks-mcp-server/#write-operations-policy","title":"Write Operations Policy","text":"<p>For write operations, we recommend the following IAM policies to ensure successful deployment of EKS clusters using the CloudFormation template in <code>/awslabs/eks_mcp_server/templates/eks-templates/eks-with-vpc.yaml</code>:</p> <ul> <li>IAMFullAccess: Enables creation and management of IAM roles and policies required for cluster operation</li> <li>AmazonVPCFullAccess: Allows creation and configuration of VPC resources including subnets, route tables, internet gateways, and NAT gateways</li> <li>AWSCloudFormationFullAccess: Provides permissions to create, update, and delete CloudFormation stacks that orchestrate the deployment</li> <li>EKS Full Access (provided below): Required for creating and managing EKS clusters, including control plane configuration, node groups, and add-ons    <code>{     \"Version\": \"2012-10-17\",     \"Statement\": [       {         \"Effect\": \"Allow\",         \"Action\": \"eks:*\",         \"Resource\": \"*\"       }     ]   }</code></li> </ul> <p>Important Security Note: Users should exercise caution when <code>--allow-write</code> and <code>--allow-sensitive-data-access</code> modes are enabled with these broad permissions, as this combination grants significant privileges to the MCP server. Only enable these flags when necessary and in trusted environments. For production use, consider creating more restrictive custom policies.</p>"},{"location":"servers/eks-mcp-server/#kubernetes-api-access-requirements","title":"Kubernetes API Access Requirements","text":"<p>All Kubernetes API operations will only work when one of the following conditions is met:</p> <ol> <li>The user's principal (IAM role/user) actually created the EKS cluster being accessed</li> <li>An EKS Access Entry has been configured for the user's principal</li> </ol> <p>If you encounter authorization errors when using Kubernetes API operations, verify that an access entry has been properly configured for your principal.</p>"},{"location":"servers/eks-mcp-server/#quickstart","title":"Quickstart","text":"<p>This quickstart guide walks you through the steps to configure the Amazon EKS MCP Server for use with both the Cursor IDE and the Amazon Q Developer CLI. By following these steps, you'll setup your development environment to leverage the EKS MCP Server's tools for managing your Amazon EKS clusters and Kubernetes resources.</p> <p>Set up Cursor</p> <p></p> <p>Set up the Amazon Q Developer CLI</p> <ol> <li>Install the Amazon Q Developer CLI .</li> <li>The Q Developer CLI supports MCP servers for tools and prompts out-of-the-box. Edit your Q developer CLI's MCP configuration file named mcp.json following these instructions.</li> </ol> <p>The example below includes both the <code>--allow-write</code> flag for mutating operations and the <code>--allow-sensitive-data-access</code> flag for accessing logs and events (see the Arguments section for more details):</p> <p>For Mac/Linux:</p> <pre><code>```\n{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.eks-mcp-server@latest\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n```\n</code></pre> <p>For Windows:</p> <pre><code>```\n{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"awslabs.eks-mcp-server@latest\",\n        \"awslabs.eks-mcp-server.exe\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n```\n</code></pre> <ol> <li>Verify your setup by running the <code>/tools</code> command in the Q Developer CLI to see the available EKS MCP tools.</li> </ol> <p>Note that this is a basic quickstart. You can enable additional capabilities, such as running MCP servers in containers or combining more MCP servers like the AWS Documentation MCP Server into a single MCP server definition. To view an example, see the Installation and Setup guide in AWS MCP Servers on GitHub. To view a real-world implementation with application code in context with an MCP server, see the Server Developer guide in Anthropic documentation.</p>"},{"location":"servers/eks-mcp-server/#configurations","title":"Configurations","text":""},{"location":"servers/eks-mcp-server/#arguments","title":"Arguments","text":"<p>The <code>args</code> field in the MCP server definition specifies the command-line arguments passed to the server when it starts. These arguments control how the server is executed and configured. For example:</p> <p>For Mac/Linux: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.eks-mcp-server@latest\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>For Windows: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"awslabs.eks-mcp-server@latest\",\n        \"awslabs.eks-mcp-server.exe\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"servers/eks-mcp-server/#command-format","title":"Command Format","text":"<p>The command format differs between operating systems:</p> <p>For Mac/Linux: * <code>awslabs.eks-mcp-server@latest</code> - Specifies the latest package/version specifier for the MCP client config.</p> <p>For Windows: * <code>--from awslabs.eks-mcp-server@latest awslabs.eks-mcp-server.exe</code> - Windows requires the <code>--from</code> flag to specify the package and the <code>.exe</code> extension.</p> <p>Both formats enable MCP server startup and tool registration.</p>"},{"location":"servers/eks-mcp-server/#-allow-write-optional","title":"<code>--allow-write</code> (optional)","text":"<p>Enables write access mode, which allows mutating operations (e.g., create, update, delete resources) for apply_yaml, generate_app_manifest, manage_k8s_resource, manage_eks_stacks, add_inline_policy tool operations.</p> <ul> <li>Default: false (The server runs in read-only mode by default)</li> <li>Example: Add <code>--allow-write</code> to the <code>args</code> list in your MCP server definition.</li> </ul>"},{"location":"servers/eks-mcp-server/#-allow-sensitive-data-access-optional","title":"<code>--allow-sensitive-data-access</code> (optional)","text":"<p>Enables access to sensitive data such as logs, events, and Kubernetes Secrets. This flag is required for tools that access potentially sensitive information, such as get_pod_logs, get_k8s_events, get_cloudwatch_logs, and manage_k8s_resource (when used to read Kubernetes secrets).</p> <ul> <li>Default: false (Access to sensitive data is restricted by default)</li> <li>Example: Add <code>--allow-sensitive-data-access</code> to the <code>args</code> list in your MCP server definition.</li> </ul>"},{"location":"servers/eks-mcp-server/#environment-variables","title":"Environment variables","text":"<p>The <code>env</code> field in the MCP server definition allows you to configure environment variables that control the behavior of the EKS MCP server.  For example:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"my-profile\",\n        \"AWS_REGION\": \"us-west-2\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/eks-mcp-server/#fastmcp_log_level-optional","title":"<code>FASTMCP_LOG_LEVEL</code> (optional)","text":"<p>Sets the logging level verbosity for the server.</p> <ul> <li>Valid values: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"</li> <li>Default: \"WARNING\"</li> <li>Example: <code>\"FASTMCP_LOG_LEVEL\": \"ERROR\"</code></li> </ul>"},{"location":"servers/eks-mcp-server/#aws_profile-optional","title":"<code>AWS_PROFILE</code> (optional)","text":"<p>Specifies the AWS profile to use for authentication.</p> <ul> <li>Default: None (If not set, uses default AWS credentials).</li> <li>Example: <code>\"AWS_PROFILE\": \"my-profile\"</code></li> </ul>"},{"location":"servers/eks-mcp-server/#aws_region-optional","title":"<code>AWS_REGION</code> (optional)","text":"<p>Specifies the AWS region where EKS clusters are managed, which will be used for all AWS service operations.</p> <ul> <li>Default: None (If not set, uses default AWS region).</li> <li>Example: <code>\"AWS_REGION\": \"us-west-2\"</code></li> </ul>"},{"location":"servers/eks-mcp-server/#tools","title":"Tools","text":"<p>The following tools are provided by the EKS MCP server for managing Amazon EKS clusters and Kubernetes resources. Each tool performs a specific action that can be invoked to automate common tasks in your EKS clusters and Kubernetes workloads.</p>"},{"location":"servers/eks-mcp-server/#eks-cluster-management","title":"EKS Cluster Management","text":""},{"location":"servers/eks-mcp-server/#manage_eks_stacks","title":"<code>manage_eks_stacks</code>","text":"<p>Manages EKS CloudFormation stacks with operations for generating templates, deploying, describing, and deleting EKS clusters and their underlying infrastructure. Note: Cluster creation typically takes 15-20 minutes to complete.</p> <p>Features:</p> <ul> <li>Generates CloudFormation templates for EKS clusters, embedding specified cluster names.</li> <li>Deploys EKS clusters using CloudFormation, creating or updating stacks with VPC, subnets, NAT gateways, IAM roles, and node pools.</li> <li>Describes existing EKS CloudFormation stacks, providing details like status, outputs, and creation time.</li> <li>Deletes EKS CloudFormation stacks and their associated resources, ensuring proper cleanup.</li> <li>Ensures safety by only modifying/deleting stacks that were originally created by this tool.</li> </ul> <p>Parameters:</p> <ul> <li>operation (generate, deploy, describe, delete), template_file (for generate/deploy), cluster_name</li> </ul>"},{"location":"servers/eks-mcp-server/#kubernetes-resource-management","title":"Kubernetes Resource Management","text":""},{"location":"servers/eks-mcp-server/#manage_k8s_resource","title":"<code>manage_k8s_resource</code>","text":"<p>Manages individual Kubernetes resources with various operations.</p> <p>Features:</p> <ul> <li>Supports create, replace, patch, delete, and read Kubernetes operations.</li> <li>Handles both namespaced and non-namespaced Kubernetes resources.</li> </ul> <p>Parameters:</p> <ul> <li>operation (create, replace, patch, delete, read), cluster_name, kind, api_version, name, namespace (optional), body (for create/replace/patch)</li> </ul>"},{"location":"servers/eks-mcp-server/#apply_yaml","title":"<code>apply_yaml</code>","text":"<p>Applies Kubernetes YAML manifests to an EKS cluster.</p> <p>Features:</p> <ul> <li>Supports multi-document YAML files.</li> <li>Applies all resources in the manifest to the specified namespace.</li> <li>Can update existing resources if force is true.</li> </ul> <p>Parameters:</p> <ul> <li>yaml_path, cluster_name, namespace, force</li> </ul>"},{"location":"servers/eks-mcp-server/#list_k8s_resources","title":"<code>list_k8s_resources</code>","text":"<p>Lists Kubernetes resources of a specific kind in an EKS cluster.</p> <p>Features:</p> <ul> <li>Returns summaries of EKS resources with metadata.</li> <li>Supports filtering by EKS cluster namespace, labels, and fields.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, kind, api_version, namespace (optional), label_selector (optional), field_selector (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#list_api_versions","title":"<code>list_api_versions</code>","text":"<p>Lists all available API versions in the specified Kubernetes cluster.</p> <p>Features:</p> <ul> <li>Discovers all available API versions on the Kubernetes cluster.</li> <li>Helps determine the correct <code>apiVersion</code> to use for managing Kubernetes resources.</li> <li>Includes both core APIs (e.g., \"v1\") and API groups (e.g., \"apps/v1\", \"networking.k8s.io/v1\").</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name</li> </ul>"},{"location":"servers/eks-mcp-server/#application-support","title":"Application Support","text":""},{"location":"servers/eks-mcp-server/#generate_app_manifest","title":"<code>generate_app_manifest</code>","text":"<p>Generates Kubernetes manifests for application deployment.</p> <p>Features:</p> <ul> <li>Generates Kubernetes deployment and service YAMLs with configurable parameters.</li> <li>Supports load balancer configuration and resource requests.</li> <li>Outputs Kubernetes manifest to a specified directory.</li> </ul> <p>Parameters:</p> <ul> <li>app_name, image_uri, output_dir, port (optional), replicas (optional), cpu (optional), memory (optional), namespace (optional), load_balancer_scheme (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#get_pod_logs","title":"<code>get_pod_logs</code>","text":"<p>Retrieves logs from pods in a Kubernetes cluster.</p> <p>Features:</p> <ul> <li>Supports filtering logs by time, line count, and byte size.</li> <li>Can retrieve logs from specific containers in a pod.</li> <li>Requires <code>--allow-sensitive-data-access</code> server flag to be enabled.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, pod_name, namespace, container_name (optional), since_seconds (optional), tail_lines (optional), limit_bytes (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#get_k8s_events","title":"<code>get_k8s_events</code>","text":"<p>Retrieves events related to specific Kubernetes resources.</p> <p>Features:</p> <ul> <li>Returns Kubernetes event details including timestamps, count, message, reason, reporting component, and type.</li> <li>Supports both namespaced and non-namespaced Kubernetes resources.</li> <li>Requires <code>--allow-sensitive-data-access</code> server flag to be enabled.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, kind, name, namespace (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#cloudwatch-integration","title":"CloudWatch Integration","text":""},{"location":"servers/eks-mcp-server/#get_cloudwatch_logs","title":"<code>get_cloudwatch_logs</code>","text":"<p>Retrieves logs from CloudWatch for a specific resource within an EKS cluster.</p> <p>Features:</p> <ul> <li>Fetches logs based on resource type (pod, node, container), resource name, and log type.</li> <li>Allows filtering by time range (minutes, start/end time), log content (filter_pattern), and number of entries.</li> <li>Supports specifying custom fields to be included in the query results.</li> <li>Requires <code>--allow-sensitive-data-access</code> server flag to be enabled.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, log_type (application, host, performance, control-plane, custom), resource_type (pod, node, container, cluster), resource_name (optional), minutes (optional), start_time (optional), end_time (optional), limit (optional), filter_pattern (optional), fields (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#get_cloudwatch_metrics","title":"<code>get_cloudwatch_metrics</code>","text":"<p>Retrieves metrics from CloudWatch for Kubernetes resources.</p> <p>Features:</p> <ul> <li>Fetches metrics based on metric name and dimensions.</li> <li>Allows specification of CloudWatch namespace and time range.</li> <li>Configurable period, statistic (Average, Sum, etc.), and limit for data points.</li> <li>Supports providing custom dimensions for fine-grained metric querying.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, metric_name, namespace, dimensions, minutes (optional), start_time (optional), end_time (optional), limit (optional), stat (optional), period (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#get_eks_metrics_guidance","title":"<code>get_eks_metrics_guidance</code>","text":"<p>Provides guidance on available CloudWatch metrics for different resource types in EKS clusters.</p> <p>Features:</p> <ul> <li>Returns a list of available Container Insights metrics for the specified resource type, including metric names, dimensions, and descriptions.</li> <li>Helps determine the correct dimensions to use with the <code>get_cloudwatch_metrics</code> tool.</li> <li>Supports the following resource types:</li> <li><code>cluster</code>: Metrics for EKS clusters (e.g., cluster_node_count, cluster_failed_node_count)</li> <li><code>node</code>: Metrics for EKS nodes (e.g., node_cpu_utilization, node_memory_utilization, node_network_total_bytes)</li> <li><code>pod</code>: Metrics for Kubernetes pods (e.g., pod_cpu_utilization, pod_memory_utilization, pod_network_rx_bytes)</li> <li><code>namespace</code>: Metrics for Kubernetes namespaces (e.g., namespace_number_of_running_pods)</li> <li><code>service</code>: Metrics for Kubernetes services (e.g., service_number_of_running_pods)</li> </ul> <p>Parameters:</p> <ul> <li>resource_type</li> </ul> <p>Implementation:</p> <p>The data in <code>/awslabs/eks_mcp_server/data/eks_cloudwatch_metrics_guidance.json</code> is generated by a Python script (<code>/awslabs/eks_mcp_server/scripts/update_eks_cloudwatch_metrics_guidance.py</code>) that scrapes the Container Insights metrics table from AWS documentation. Running the script requires installing BeautifulSoup (used for parsing HTML content) with uv: <code>uv pip install bs4</code>.</p>"},{"location":"servers/eks-mcp-server/#iam-integration","title":"IAM Integration","text":""},{"location":"servers/eks-mcp-server/#get_policies_for_role","title":"<code>get_policies_for_role</code>","text":"<p>Retrieves all policies attached to a specified IAM role, including assume role policy, managed policies, and inline policies.</p> <p>Features:</p> <ul> <li>Fetches the assume role policy document for the specified IAM role.</li> <li>Lists all attached managed policies and includes their policy documents.</li> <li>Lists all embedded inline policies and includes their policy documents.</li> </ul> <p>Parameters:</p> <ul> <li>role_name</li> </ul>"},{"location":"servers/eks-mcp-server/#add_inline_policy","title":"<code>add_inline_policy</code>","text":"<p>Adds a new inline policy with specified permissions to an IAM role; it will not modify existing policies. It will only create new policies; it will reject requests to modify existing policies.</p> <p>Features:</p> <ul> <li>Creates and attaches a new inline policy to a specified IAM role.</li> <li>Rejects requests if the policy name already exists on the role to prevent accidental modification.</li> <li>Requires <code>--allow-write</code> server flag to be enabled.</li> <li>Accepts permissions as a single JSON object (statement) or a list of JSON objects (statements).</li> </ul> <p>Parameters:</p> <ul> <li>policy_name, role_name, permissions (JSON object or array of objects)</li> </ul>"},{"location":"servers/eks-mcp-server/#troubleshooting","title":"Troubleshooting","text":""},{"location":"servers/eks-mcp-server/#search_eks_troubleshoot_guide","title":"<code>search_eks_troubleshoot_guide</code>","text":"<p>Searches the EKS Troubleshoot Guide for troubleshooting information based on a query.</p> <p>Features:</p> <ul> <li>Provides detailed troubleshooting guidance for Amazon EKS issues.</li> <li>Covers EKS Auto mode node provisioning, bootstrap issues, and controller failure modes.</li> <li>Returns symptoms, step-by-step short-term, and long-term fixes for identified issues.</li> </ul> <p>Parameters:</p> <ul> <li>query</li> </ul>"},{"location":"servers/eks-mcp-server/#security-permissions","title":"Security &amp; permissions","text":""},{"location":"servers/eks-mcp-server/#features","title":"Features","text":"<p>The EKS MCP Server implements the following security features:</p> <ol> <li>AWS Authentication: Uses AWS credentials from the environment for secure authentication.</li> <li>Kubernetes Authentication: Generates temporary credentials for Kubernetes API access.</li> <li>SSL Verification: Enforces SSL verification for all Kubernetes API calls.</li> <li>Resource Tagging: Tags all created resources for traceability.</li> <li>Least Privilege: Uses IAM roles with appropriate permissions for CloudFormation templates.</li> <li>Stack Protection: Ensures CloudFormation stacks can only be modified by the tool that created them.</li> <li>Client Caching: Caches Kubernetes clients with TTL-based expiration for security and performance.</li> </ol>"},{"location":"servers/eks-mcp-server/#considerations","title":"Considerations","text":"<p>When using the EKS MCP Server, consider the following:</p> <ul> <li>AWS Credentials: The server needs permission to create and manage EKS resources.</li> <li>Kubernetes Access: The server generates temporary credentials for Kubernetes API access.</li> <li>Network Security: Configure VPC and security groups properly for EKS clusters.</li> <li>Authentication: Use appropriate authentication mechanisms for Kubernetes resources.</li> <li>Authorization: Configure RBAC properly for Kubernetes resources.</li> <li>Data Protection: Encrypt sensitive data in Kubernetes secrets.</li> <li>Logging and Monitoring: Enable logging and monitoring for EKS clusters.</li> </ul>"},{"location":"servers/eks-mcp-server/#permissions","title":"Permissions","text":"<p>The EKS MCP Server can be used for production environments with proper security controls in place. The server runs in read-only mode by default, which is recommended and considered generally safer for production environments. Only explicitly enable write access when necessary. Below are the EKS MCP server tools available in read-only versus write-access mode:</p> <ul> <li>Read-only mode (default): <code>manage_eks_stacks</code> (with operation=\"describe\"), <code>manage_k8s_resource</code> (with operation=\"read\"), <code>list_k8s_resources</code>, <code>get_pod_logs</code>, <code>get_k8s_events</code>, <code>get_cloudwatch_logs</code>, <code>get_cloudwatch_metrics</code>, <code>get_policies_for_role</code>, <code>search_eks_troubleshoot_guide</code>, <code>list_api_versions</code>.</li> <li>Write-access mode: (require <code>--allow-write</code>): <code>manage_eks_stacks</code> (with \"generate\", \"deploy\", \"delete\"), <code>manage_k8s_resource</code> (with \"create\", \"replace\", \"patch\", \"delete\"), <code>apply_yaml</code>, <code>generate_app_manifest</code>, <code>add_inline_policy</code>.</li> </ul>"},{"location":"servers/eks-mcp-server/#autoapprove-optional","title":"<code>autoApprove</code> (optional)","text":"<p>An array within the MCP server definition that lists tool names to be automatically approved by the EKS MCP Server client, bypassing user confirmation for those specific tools. For example:</p> <p>For Mac/Linux: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.eks-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"eks-mcp-readonly-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"autoApprove\": [\n        \"manage_eks_stacks\",\n        \"manage_k8s_resource\",\n        \"list_k8s_resources\",\n        \"get_pod_logs\",\n        \"get_k8s_events\",\n        \"get_cloudwatch_logs\",\n        \"get_cloudwatch_metrics\",\n        \"get_policies_for_role\",\n        \"search_eks_troubleshoot_guide\",\n        \"list_api_versions\"\n      ]\n    }\n  }\n}\n</code></pre></p> <p>For Windows: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"awslabs.eks-mcp-server@latest\",\n        \"awslabs.eks-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"eks-mcp-readonly-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"autoApprove\": [\n        \"manage_eks_stacks\",\n        \"manage_k8s_resource\",\n        \"list_k8s_resources\",\n        \"get_pod_logs\",\n        \"get_k8s_events\",\n        \"get_cloudwatch_logs\",\n        \"get_cloudwatch_metrics\",\n        \"get_policies_for_role\",\n        \"search_eks_troubleshoot_guide\",\n        \"list_api_versions\"\n      ]\n    }\n  }\n}\n</code></pre></p>"},{"location":"servers/eks-mcp-server/#iam-permissions-management","title":"IAM Permissions Management","text":"<p>When the <code>--allow-write</code> flag is enabled, the EKS MCP Server can create missing IAM permissions for EKS resources through the <code>add_inline_policy</code> tool. This tool enables the following:</p> <ul> <li>Only creates new inline policies; it never modifies existing policies.</li> <li>Is useful for automatically fixing common permissions issues with EKS clusters.</li> <li>Should be used with caution and with properly scoped IAM roles.</li> </ul>"},{"location":"servers/eks-mcp-server/#role-scoping-recommendations","title":"Role Scoping Recommendations","text":"<p>In accordance with security best practices, we recommend the following:</p> <ol> <li>Create dedicated IAM roles to be used by the EKS MCP Server with the principle of \"least privilege.\"</li> <li>Use separate roles for read-only and write operations.</li> <li>Implement resource tagging to limit actions to resources created by the server.</li> <li>Enable AWS CloudTrail to audit all API calls made by the server.</li> <li>Regularly review the permissions granted to the server's IAM role.</li> <li>Use IAM Access Analyzer to identify unused permissions that can be removed.</li> </ol>"},{"location":"servers/eks-mcp-server/#sensitive-information-handling","title":"Sensitive Information Handling","text":"<p>IMPORTANT: Do not pass secrets or sensitive information via allowed input mechanisms:</p> <ul> <li>Do not include secrets or credentials in YAML files applied with <code>apply_yaml</code>.</li> <li>Do not pass sensitive information directly in the prompt to the model.</li> <li>Do not include secrets in CloudFormation templates or application manifests.</li> <li>Avoid using MCP tools for creating Kubernetes Secrets, as this would require providing the secret data to the model.</li> </ul> <p>YAML Content Security:</p> <ul> <li>Only use YAML files from trustworthy sources.</li> <li>The server relies on Kubernetes API validation for YAML content and does not perform its own validation.</li> <li>Audit YAML files before applying them to your cluster.</li> </ul> <p>Instead of passing secrets through MCP:</p> <ul> <li>Use AWS Secrets Manager or Parameter Store to store sensitive information.</li> <li>Configure proper Kubernetes RBAC for service accounts.</li> <li>Use IAM roles for service accounts (IRSA) for AWS service access from pods.</li> </ul>"},{"location":"servers/eks-mcp-server/#general-best-practices","title":"General Best Practices","text":"<ul> <li>Resource Naming: Use descriptive names for EKS clusters and Kubernetes resources.</li> <li>Namespace Usage: Organize resources into namespaces for better management.</li> <li>Error Handling: Check for errors in tool responses and handle them appropriately.</li> <li>Resource Cleanup: Delete unused resources to avoid unnecessary costs.</li> <li>Monitoring: Monitor cluster and resource status regularly.</li> <li>Security: Follow AWS security best practices for EKS clusters.</li> <li>Backup: Regularly backup important Kubernetes resources.</li> </ul>"},{"location":"servers/eks-mcp-server/#general-troubleshooting","title":"General Troubleshooting","text":"<ul> <li>Permission Errors: Verify that your AWS credentials have the necessary permissions.</li> <li>CloudFormation Errors: Check the CloudFormation console for stack creation errors.</li> <li>Kubernetes API Errors: Verify that the EKS cluster is running and accessible.</li> <li>Network Issues: Check VPC and security group configurations.</li> <li>Client Errors: Verify that the MCP client is configured correctly.</li> <li>Log Level: Increase the log level to DEBUG for more detailed logs.</li> </ul> <p>For general EKS issues, consult the Amazon EKS documentation.</p>"},{"location":"servers/eks-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 0.1.0</p>"},{"location":"servers/elasticache-mcp-server/","title":"AWS ElastiCache MCP Server","text":"<p>The official MCP Server for interacting with AWS ElastiCache control plane. In order to interact with your data in ElastiCache Serverless caches and self-designed clusters use the Valkey MCP Server or the Memcached MCP Server.</p>"},{"location":"servers/elasticache-mcp-server/#available-mcp-tools","title":"Available MCP Tools","text":""},{"location":"servers/elasticache-mcp-server/#serverless-cache-operations","title":"Serverless Cache Operations","text":"<ul> <li><code>create-serverless-cache</code> - Create a new ElastiCache serverless cache</li> <li><code>delete-serverless-cache</code> - Delete a serverless cache</li> <li><code>describe-serverless-caches</code> - Get information about serverless caches</li> <li><code>modify-serverless-cache</code> - Modify settings of a serverless cache</li> <li><code>connect-jump-host-serverless-cache</code> - Configure an EC2 instance as a jump host for serverless cache access</li> <li><code>create-jump-host-serverless-cache</code> - Create an EC2 jump host to access a serverless cache via SSH tunnel</li> <li><code>get-ssh-tunnel-command-serverless-cache</code> - Generate SSH tunnel command for serverless cache access</li> </ul>"},{"location":"servers/elasticache-mcp-server/#replication-group-operations","title":"Replication Group Operations","text":"<ul> <li><code>create-replication-group</code> - Create an Amazon ElastiCache replication group with specified configuration</li> <li><code>delete-replication-group</code> - Delete an ElastiCache replication group with optional final snapshot</li> <li><code>describe-replication-groups</code> - Get detailed information about one or more replication groups</li> <li><code>modify-replication-group</code> - Modify settings of an existing replication group</li> <li><code>modify-replication-group-shard-configuration</code> - Modify the shard configuration of a replication group</li> <li><code>test-migration</code> - Test migration from a Redis instance to an ElastiCache replication group</li> <li><code>start-migration</code> - Start migration from a Redis instance to an ElastiCache replication group</li> <li><code>complete-migration</code> - Complete migration from a Redis instance to an ElastiCache replication group</li> <li><code>connect-jump-host-replication-group</code> - Configure an EC2 instance as a jump host for replication group access</li> <li><code>create-jump-host-replication-group</code> - Create an EC2 jump host to access a replication group via SSH tunnel</li> <li><code>get-ssh-tunnel-command-replication-group</code> - Generate SSH tunnel command for replication group access</li> </ul>"},{"location":"servers/elasticache-mcp-server/#cache-cluster-operations","title":"Cache Cluster Operations","text":"<ul> <li><code>create-cache-cluster</code> - Create a new ElastiCache cache cluster</li> <li><code>delete-cache-cluster</code> - Delete a cache cluster with optional final snapshot</li> <li><code>describe-cache-clusters</code> - Get detailed information about one or more cache clusters</li> <li><code>modify-cache-cluster</code> - Modify settings of an existing cache cluster</li> <li><code>connect-jump-host-cache-cluster</code> - Configure an EC2 instance as a jump host for cluster access</li> <li><code>create-jump-host-cache-cluster</code> - Create an EC2 jump host to access a cluster via SSH tunnel</li> <li><code>get-ssh-tunnel-command-cache-cluster</code> - Generate SSH tunnel command for cluster access</li> </ul>"},{"location":"servers/elasticache-mcp-server/#cloudwatch-operations","title":"CloudWatch Operations","text":"<ul> <li><code>get-metric-statistics</code> - Get CloudWatch metric statistics for ElastiCache resources with customizable time periods and dimensions</li> </ul>"},{"location":"servers/elasticache-mcp-server/#cloudwatch-logs-operations","title":"CloudWatch Logs Operations","text":"<ul> <li><code>describe-log-groups</code> - List and describe CloudWatch Logs log groups</li> <li><code>create-log-group</code> - Create a new CloudWatch Logs log group</li> <li><code>describe-log-streams</code> - List and describe log streams in a log group</li> <li><code>filter-log-events</code> - Search and filter log events across log streams</li> <li><code>get-log-events</code> - Retrieve log events from a specific log stream</li> </ul>"},{"location":"servers/elasticache-mcp-server/#firehose-operations","title":"Firehose Operations","text":"<ul> <li><code>list-delivery-streams</code> - List your Kinesis Data Firehose delivery streams</li> </ul>"},{"location":"servers/elasticache-mcp-server/#cost-explorer-operations","title":"Cost Explorer Operations","text":"<ul> <li><code>get-cost-and-usage</code> - Get cost and usage data for ElastiCache resources with customizable time periods and granularity</li> </ul>"},{"location":"servers/elasticache-mcp-server/#misc-operations","title":"Misc Operations","text":"<ul> <li><code>describe-cache-engine-versions</code> - List available cache engines and their versions</li> <li><code>describe-engine-default-parameters</code> - Get default parameters for a cache engine family</li> <li><code>describe-events</code> - Get events related to clusters, security groups, and parameters</li> <li><code>describe-service-updates</code> - Get information about available service updates</li> <li><code>batch-apply-update-action</code> - Apply service updates to resources</li> <li><code>batch-stop-update-action</code> - Stop service updates on resources</li> </ul>"},{"location":"servers/elasticache-mcp-server/#instructions","title":"Instructions","text":"<p>The official MCP Server for interacting with AWS ElastiCache provides a comprehensive set of tools for managing ElastiCache resources. Each tool maps directly to ElastiCache API operations and supports all relevant parameters.</p> <p>To use these tools, ensure you have proper AWS credentials configured with appropriate permissions for ElastiCache operations. The server will automatically use credentials from environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN) or other standard AWS credential sources.</p> <p>All tools support an optional <code>region_name</code> parameter to specify which AWS region to operate in. If not provided, it will use the AWS_REGION environment variable or default to 'us-west-2'.</p>"},{"location":"servers/elasticache-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services</li> <li>Consider setting up Read-only permission if you don't want the LLM to modify any resources</li> </ol>"},{"location":"servers/elasticache-mcp-server/#installation","title":"Installation","text":"<p>Add the MCP to your favorite agentic tools. (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <p><pre><code>{\n  \"mcpServers\": {\n    \"awslabs.elasticache-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.elasticache-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> If you would like to prevent the MCP from taking any mutating actions (i.e. Create/Update/Delete Resource), you can specify the readonly flag as demonstrated below:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.elasticache-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.elasticache-mcp-server@latest\",\n        \"--readonly\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/elasticache-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.elasticache-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"awslabs/elasticache-mcp-server:latest\",\n        \"--readonly\" // Optional paramter if you would like to restrict the MCP to only read actions\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/elasticache-mcp-server/#configuration","title":"Configuration","text":""},{"location":"servers/elasticache-mcp-server/#aws-configuration","title":"AWS Configuration","text":"<p>Configure AWS credentials and region:</p> <pre><code># AWS settings\nAWS_PROFILE=default              # AWS credential profile to use\nAWS_REGION=us-east-1            # AWS region to connect to\n</code></pre>"},{"location":"servers/elasticache-mcp-server/#connection-settings","title":"Connection Settings","text":"<p>Configure connection behavior and timeouts:</p> <pre><code># Connection settings\nELASTICACHE_MAX_RETRIES=3        # Maximum number of retry attempts for AWS API calls\nELASTICACHE_RETRY_MODE=standard  # AWS SDK retry mode for API calls\nELASTICACHE_CONNECT_TIMEOUT=5    # Connection timeout in seconds\nELASTICACHE_READ_TIMEOUT=10      # Read timeout in seconds\n\n# Cost Explorer settings\nCOST_EXPLORER_MAX_RETRIES=3      # Maximum number of retry attempts for Cost Explorer API calls\nCOST_EXPLORER_RETRY_MODE=standard # AWS SDK retry mode for Cost Explorer API calls\nCOST_EXPLORER_CONNECT_TIMEOUT=5   # Connection timeout in seconds for Cost Explorer\nCOST_EXPLORER_READ_TIMEOUT=10     # Read timeout in seconds for Cost Explorer\n\n# CloudWatch settings\nCLOUDWATCH_MAX_RETRIES=3         # Maximum number of retry attempts for CloudWatch API calls\nCLOUDWATCH_RETRY_MODE=standard    # AWS SDK retry mode for CloudWatch API calls\nCLOUDWATCH_CONNECT_TIMEOUT=5      # Connection timeout in seconds for CloudWatch\nCLOUDWATCH_READ_TIMEOUT=10        # Read timeout in seconds for CloudWatch\n\n# CloudWatch Logs settings\nCLOUDWATCH_LOGS_MAX_RETRIES=3     # Maximum number of retry attempts for CloudWatch Logs API calls\nCLOUDWATCH_LOGS_RETRY_MODE=standard # AWS SDK retry mode for CloudWatch Logs API calls\nCLOUDWATCH_LOGS_CONNECT_TIMEOUT=5  # Connection timeout in seconds for CloudWatch Logs\nCLOUDWATCH_LOGS_READ_TIMEOUT=10    # Read timeout in seconds for CloudWatch Logs\n\n# Firehose settings\nFIREHOSE_MAX_RETRIES=3            # Maximum number of retry attempts for Firehose API calls\nFIREHOSE_RETRY_MODE=standard      # AWS SDK retry mode for Firehose API calls\nFIREHOSE_CONNECT_TIMEOUT=5        # Connection timeout in seconds for Firehose\nFIREHOSE_READ_TIMEOUT=10          # Read timeout in seconds for Firehose\n</code></pre> <p>The server automatically handles: - AWS authentication and credential management - Connection establishment and management - Automatic retrying of failed operations - Timeout enforcement and error handling</p>"},{"location":"servers/elasticache-mcp-server/#development","title":"Development","text":""},{"location":"servers/elasticache-mcp-server/#running-tests","title":"Running Tests","text":"<pre><code>uv venv\nsource .venv/bin/activate\nuv sync\nuv run --frozen pytest\n</code></pre>"},{"location":"servers/elasticache-mcp-server/#building-docker-image","title":"Building Docker Image","text":"<pre><code>docker build -t awslabs/elasticache-mcp-server .\n</code></pre>"},{"location":"servers/elasticache-mcp-server/#running-docker-container","title":"Running Docker Container","text":"<p>```bash docker run -p 8080:8080 \\   -e AWS_PROFILE=default \\   -e AWS_REGION=us-west-2 \\   awslabs/elasticache-mcp-server</p>"},{"location":"servers/finch-mcp-server/","title":"Finch MCP Server","text":"<p>A Model Context Protocol (MCP) server for Finch that enables generative AI models to build and push container images through finch cli leveraged MCP tools.</p>"},{"location":"servers/finch-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and Finch, allowing generative AI models to build and push container images to repositories, and create ECR repositories as needed. The server provides a secure way to interact with Finch, ensuring that the Finch VM is properly initialized and running before performing operations.</p>"},{"location":"servers/finch-mcp-server/#key-capabilities","title":"Key Capabilities","text":"<ul> <li>Build container images using Finch</li> <li>Push container images to repositories, including Amazon ECR</li> <li>Check if ECR repositories exist and create them if needed</li> <li>Automatic management of the Finch VM on macos and windows (initialization, starting, etc.)</li> <li>Automatic configuration of ECR credential helpers when needed (only modifies finch.yaml as config.json is automatically handled)</li> </ul>"},{"location":"servers/finch-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install Finch on your system</li> <li>For ECR operations, AWS credentials with permissions to push to ECR repositories and create/describe ECR repositories</li> </ol>"},{"location":"servers/finch-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/finch-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration:</p>"},{"location":"servers/finch-mcp-server/#default-mode-read-only-aws-resources","title":"Default Mode (Read-only AWS Resources)","text":"<p>By default, the server runs in a mode that prevents the creation of new AWS resources. This is useful for environments where you want to limit resource creation or for users who should only be able to build and push to existing repositories.</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.finch-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.finch-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"transportType\": \"stdio\",\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>In this default mode: - The <code>finch_build_container_image</code> tools will work normally - The <code>finch_create_ecr_repo</code> and <code>finch_push_image</code> tool will return an error and will not create or modify AWS resources.</p>"},{"location":"servers/finch-mcp-server/#aws-resource-write-mode","title":"AWS Resource Write Mode","text":"<p>The server can also be set to enable AWS resource creation and modification by using the <code>--enable-aws-resource-write</code> flag.</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.finch-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.finch-mcp-server@latest\",\n        \"--enable-aws-resource-write\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"transportType\": \"stdio\",\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/finch-mcp-server/#available-tools","title":"Available Tools","text":""},{"location":"servers/finch-mcp-server/#finch_build_container_image","title":"<code>finch_build_container_image</code>","text":"<p>Build a container image using Finch.</p> <p>The tool builds a Docker image using the specified Dockerfile and context directory. It supports a range of build options including tags, platforms, and more.</p> <p>Arguments: - <code>dockerfile_path</code> (str): Absolute path to the Dockerfile - <code>context_path</code> (str): Absolute path to the build context directory - <code>tags</code> (List[str], optional): List of tags to apply to the image (e.g., [\"myimage:latest\", \"myimage:v1\"]) - <code>platforms</code> (List[str], optional): List of target platforms (e.g., [\"linux/amd64\", \"linux/arm64\"]) - <code>target</code> (str, optional): Target build stage to build - <code>no_cache</code> (bool, optional): Whether to disable cache. Defaults to False. - <code>pull</code> (bool, optional): Whether to always pull base images. Defaults to False. - <code>build_contexts</code> (List[str], optional): List of additional build contexts - <code>outputs</code> (str, optional): Output destination - <code>cache_from</code> (List[str], optional): List of external cache sources - <code>quiet</code> (bool, optional): Whether to suppress build output. Defaults to False. - <code>progress</code> (str, optional): Type of progress output. Defaults to \"auto\".</p>"},{"location":"servers/finch-mcp-server/#finch_push_image","title":"<code>finch_push_image</code>","text":"<p>Push a container image to a repository using Finch, replacing the tag with the image hash.</p> <p>If the image URL is an ECR repository, it verifies that ECR login credential helper is configured. This tool gets the image hash, creates a new tag using the hash, and pushes the image with the hash tag to the repository.</p> <p>The workflow is: 1. Get the image hash using <code>finch image inspect</code> 2. Create a new tag for the image using the short form of the hash (first 12 characters) 3. Push the hash-tagged image to the repository</p> <p>Arguments: - <code>image</code> (str): The full image name to push, including the repository URL and tag. For ECR repositories, it must follow the format: <code>&lt;aws_account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/&lt;repository_name&gt;:&lt;tag&gt;</code></p> <p>Example: <pre><code># Original image: myrepo/myimage:latest\n# After processing: myrepo/myimage:1a2b3c4d5e6f (where 1a2b3c4d5e6f is the short hash)\n</code></pre></p>"},{"location":"servers/finch-mcp-server/#finch_create_ecr_repo","title":"<code>finch_create_ecr_repo</code>","text":"<p>Check if an ECR repository exists and create it if it doesn't.</p> <p>This tool checks if the specified ECR repository exists using boto3. If the repository doesn't exist, it creates a new one with the given name with scan on push enabled and immutable tags for enhanced security. The tool requires appropriate AWS credentials configured.</p> <p>Note: When the server is running in readonly mode, this tool will return an error and will not create any AWS resources.</p> <p>Arguments: - <code>app_name</code> (str): The name of the application/repository to check or create in ECR - <code>region</code> (str, optional): AWS region for the ECR repository. If not provided, uses the default region from AWS configuration</p> <p>Example: <pre><code># Check if 'my-app' repository exists in us-west-2 region, create it if it doesn't\n{\n  \"app_name\": \"my-app\",\n  \"region\": \"us-west-2\"\n}\n\n# Response if repository already exists:\n{\n  \"status\": \"success\",\n  \"message\": \"ECR repository 'my-app' already exists.\",\n}\n\n# Response if repository was created:\n{\n  \"status\": \"success\",\n  \"message\": \"Successfully created ECR repository 'my-app'.\",\n}\n\n# Response if server is in readonly mode:\n{\n  \"status\": \"error\",\n  \"message\": \"Server running in read-only mode, unable to perform the action\"\n}\n</code></pre></p>"},{"location":"servers/finch-mcp-server/#best-practices","title":"Best Practices","text":"<ul> <li>Development and Prototyping Only: The tools provided by this MCP server are intended for development and prototyping purposes only. They are not meant for production use cases.</li> <li>Security Considerations: Always review the Dockerfiles and container configurations before building and pushing images.</li> <li>Resource Management: Regularly clean up unused images and containers to free up disk space.</li> <li>Version Control: Keep track of image versions and tags to ensure reproducibility.</li> <li>Error Handling: Implement proper error handling in your applications when using these tools.</li> </ul>"},{"location":"servers/finch-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter permission errors with ECR, verify your AWS credentials and boto3 configuration are properly set up</li> <li>For Finch VM issues, try running <code>finch vm stop</code> and then <code>finch vm start</code> manually</li> <li>If the build fails with errors about missing files, check that your context path is correct</li> <li>For general Finch issues, consult the Finch documentation</li> </ul>"},{"location":"servers/finch-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 0.1.0</p>"},{"location":"servers/frontend-mcp-server/","title":"AWS Labs Frontend MCP Server","text":"<p>A Model Context Protocol (MCP) server that provides specialized tools for modern web application development.</p>"},{"location":"servers/frontend-mcp-server/#features","title":"Features","text":""},{"location":"servers/frontend-mcp-server/#modern-react-application-documentation","title":"Modern React Application Documentation","text":"<p>This MCP Server provides comprehensive documentation on modern React application development through its <code>GetReactDocsByTopic</code> tool, which offers guidance on:</p> <ul> <li>Essential Knowledge: Fundamental concepts for building React applications</li> <li>Basic UI Setup: Setting up a React project with Tailwind CSS and shadcn/ui</li> <li>Authentication: AWS Amplify authentication integration</li> <li>Routing: Implementing routing with React Router</li> <li>Customizing: Theming with AWS Amplify components</li> <li>Creating Components: Building React components with AWS integrations</li> <li>Troubleshooting: Common issues and solutions for React development</li> </ul>"},{"location":"servers/frontend-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/frontend-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.frontend-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.frontend-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/frontend-mcp-server/#usage","title":"Usage","text":"<p>The Frontend MCP Server provides the <code>GetReactDocsByTopic</code> tool for accessing specialized documentation on modern web application development with AWS technologies. This server will instruct the caller to clone a base web application repo and use that as the starting point for customization.</p>"},{"location":"servers/frontend-mcp-server/#getreactdocsbytopic","title":"GetReactDocsByTopic","text":"<p>This tool retrieves comprehensive documentation on specific React and AWS integration topics. To use it, specify which topic you need information on:</p> <pre><code>result = await get_react_docs_by_topic('essential-knowledge')\n</code></pre> <p>Available topics:</p> <ol> <li>essential-knowledge: Foundational concepts for building React applications with AWS services</li> <li>troubleshooting: Common issues and solutions for React development with AWS integrations</li> </ol> <p>Each topic returns comprehensive markdown documentation with explanations, code examples, and implementation guidance.</p>"},{"location":"servers/git-repo-research-mcp-server/","title":"Git Repo Research MCP Server","text":"<p>Model Context Protocol (MCP) server for researching Git repositories using semantic search</p> <p>This MCP server enables developers to research external Git repositories and influence their code generation without having to clone repositories to local projects. It provides tools to index, search, and explore Git repositories using semantic search powered by Amazon Bedrock and FAISS.</p>"},{"location":"servers/git-repo-research-mcp-server/#features","title":"Features","text":"<ul> <li>Repository Indexing: Create searchable FAISS indexes from local or remote Git repositories</li> <li>Semantic Search: Query repository content using natural language and retrieve relevant code snippets</li> <li>Repository Summary: Get directory structures and identify key files like READMEs</li> <li>GitHub Repository Search: Find repositories in AWS-related organizations filtered by licenses and keywords</li> <li>File Access: Access repository files and directories with support for both text and binary content</li> </ul>"},{"location":"servers/git-repo-research-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/git-repo-research-mcp-server/#installation-requirements","title":"Installation Requirements","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python 3.12 or newer using <code>uv python install 3.12</code></li> <li> <ul> <li>uv - Fast Python package installer and resolver</li> </ul> </li> <li>AWS credentials configured with Bedrock access</li> <li>Node.js (for UVX installation support)</li> </ol>"},{"location":"servers/git-repo-research-mcp-server/#aws-requirements","title":"AWS Requirements","text":"<ol> <li>AWS CLI Configuration: You must have the AWS CLI configured with credentials that have access to Amazon Bedrock</li> <li>Amazon Bedrock Access: Ensure your AWS account has access to embedding models like Titan Embeddings</li> <li>Environment Variables: The server uses <code>AWS_REGION</code> and <code>AWS_PROFILE</code> environment variables</li> </ol>"},{"location":"servers/git-repo-research-mcp-server/#optional-requirements","title":"Optional Requirements","text":"<ol> <li>GitHub Token: Set <code>GITHUB_TOKEN</code> environment variable for higher rate limits when searching GitHub repositories</li> </ol>"},{"location":"servers/git-repo-research-mcp-server/#installation","title":"Installation","text":"<p>To add this MCP server to your Amazon Q or Claude, add the following to your MCP config file:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.git-repo-research-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.git-repo-research-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile-name\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"GITHUB_TOKEN\": \"your-github-token\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/git-repo-research-mcp-server/#create_research_repository","title":"create_research_repository","text":"<p>Indexes a Git repository (local or remote) using FAISS and Amazon Bedrock embeddings.</p> <pre><code>create_research_repository(\n    repository_path: str,\n    output_path: Optional[str] = None,\n    embedding_model: str = \"amazon.titan-embed-text-v2:0\",\n    include_patterns: Optional[List[str]] = None,\n    exclude_patterns: Optional[List[str]] = None,\n    chunk_size: int = 1000,\n    chunk_overlap: int = 200\n) -&gt; Dict\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#search_research_repository","title":"search_research_repository","text":"<p>Performs semantic search within an indexed repository.</p> <pre><code>search_research_repository(\n    index_path: str,\n    query: str,\n    limit: int = 10,\n    threshold: float = 0.0\n) -&gt; Dict\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#search_repos_on_github","title":"search_repos_on_github","text":"<p>Searches for GitHub repositories based on keywords, scoped to AWS organizations.</p> <pre><code>search_repos_on_github(\n    keywords: List[str],\n    num_results: int = 5\n) -&gt; Dict\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#access_file","title":"access_file","text":"<p>Accesses file or directory contents within repositories or on the filesystem.</p> <pre><code>access_file(\n    filepath: str\n) -&gt; Dict | ImageContent\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#delete_research_repository","title":"delete_research_repository","text":"<p>Deletes an indexed repository.</p> <pre><code>delete_research_repository(\n    repository_name_or_path: str,\n    index_directory: Optional[str] = None\n) -&gt; Dict\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#resources","title":"Resources","text":""},{"location":"servers/git-repo-research-mcp-server/#repositoriesrepository_namesummary","title":"repositories://{repository_name}/summary","text":"<p>Get a summary of an indexed repository including structure and helpful files.</p> <pre><code>repositories://awslabs_mcp/summary\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#repositories","title":"repositories://","text":"<p>List all indexed repositories with detailed information.</p> <pre><code>repositories://\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#repositoriesindex_directory","title":"repositories://{index_directory}","text":"<p>List all indexed repositories from a specific index directory.</p> <pre><code>repositories:///path/to/custom/index/directory\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#considerations","title":"Considerations","text":"<ul> <li>Repository indexing requires Amazon Bedrock access and sufficient permissions</li> <li>Large repositories may take significant time to index</li> <li>Binary files (except images) are not supported for content viewing</li> <li>GitHub repository search is by default limited to AWS organizations: aws-samples, aws-solutions-library-samples, and awslabs (but can be configured to include other organizations)</li> </ul>"},{"location":"servers/iam-mcp-server/","title":"AWS IAM MCP Server","text":"<p>A Model Context Protocol (MCP) server for comprehensive AWS Identity and Access Management (IAM) operations. This server provides AI assistants with the ability to manage IAM users, roles, policies, and permissions while following security best practices.</p>"},{"location":"servers/iam-mcp-server/#features","title":"Features","text":""},{"location":"servers/iam-mcp-server/#core-iam-management","title":"Core IAM Management","text":"<ul> <li>User Management: Create, list, retrieve, and delete IAM users</li> <li>Role Management: Create, list, and manage IAM roles with trust policies</li> <li>Group Management: Create, list, retrieve, and delete IAM groups with member management</li> <li>Policy Management: List and manage IAM policies (managed and inline)</li> <li>Inline Policy Management: Full CRUD operations for user and role inline policies</li> <li>Permission Management: Attach/detach policies to users and roles</li> <li>Access Key Management: Create and delete access keys for users</li> <li>Security Simulation: Test policy permissions before applying them</li> </ul>"},{"location":"servers/iam-mcp-server/#security-features","title":"Security Features","text":"<ul> <li>Policy Simulation: Test permissions without making changes</li> <li>Force Delete: Safely remove users with all associated resources</li> <li>Permissions Boundary Support: Set permission boundaries for enhanced security</li> <li>Trust Policy Validation: Validate JSON trust policies for roles</li> <li>Read-Only Mode: Run server in read-only mode to prevent any modifications</li> </ul>"},{"location":"servers/iam-mcp-server/#best-practices-integration","title":"Best Practices Integration","text":"<ul> <li>Follows AWS IAM security best practices</li> <li>Supports principle of least privilege</li> <li>Provides warnings for sensitive operations</li> <li>Includes comprehensive error handling</li> </ul>"},{"location":"servers/iam-mcp-server/#installation","title":"Installation","text":"<pre><code># Install using uv (recommended)\nuv tool install awslabs.iam-mcp-server\n\n# Or install using pip\npip install awslabs.iam-mcp-server\n</code></pre>"},{"location":"servers/iam-mcp-server/#configuration","title":"Configuration","text":""},{"location":"servers/iam-mcp-server/#aws-credentials","title":"AWS Credentials","text":"<p>The server requires AWS credentials to be configured. You can use any of the following methods:</p> <ol> <li> <p>AWS Profile (recommended):    <pre><code>export AWS_PROFILE=your-profile-name\n</code></pre></p> </li> <li> <p>Environment Variables:    <pre><code>export AWS_ACCESS_KEY_ID=your-access-key\nexport AWS_SECRET_ACCESS_KEY=your-secret-key\nexport AWS_REGION=us-east-1\n</code></pre></p> </li> <li> <p>IAM Roles (for EC2/Lambda):    The server will automatically use IAM roles when running on AWS services.</p> </li> </ol>"},{"location":"servers/iam-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<p>The AWS credentials used by this server need the following IAM permissions:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"iam:ListUsers\",\n                \"iam:GetUser\",\n                \"iam:CreateUser\",\n                \"iam:DeleteUser\",\n                \"iam:ListRoles\",\n                \"iam:GetRole\",\n                \"iam:CreateRole\",\n                \"iam:DeleteRole\",\n                \"iam:ListGroups\",\n                \"iam:GetGroup\",\n                \"iam:CreateGroup\",\n                \"iam:DeleteGroup\",\n                \"iam:AddUserToGroup\",\n                \"iam:RemoveUserFromGroup\",\n                \"iam:AttachGroupPolicy\",\n                \"iam:DetachGroupPolicy\",\n                \"iam:ListAttachedGroupPolicies\",\n                \"iam:ListGroupPolicies\",\n                \"iam:ListPolicies\",\n                \"iam:GetPolicy\",\n                \"iam:CreatePolicy\",\n                \"iam:DeletePolicy\",\n                \"iam:AttachUserPolicy\",\n                \"iam:DetachUserPolicy\",\n                \"iam:AttachRolePolicy\",\n                \"iam:DetachRolePolicy\",\n                \"iam:ListAttachedUserPolicies\",\n                \"iam:ListAttachedRolePolicies\",\n                \"iam:ListUserPolicies\",\n                \"iam:ListRolePolicies\",\n                \"iam:GetUserPolicy\",\n                \"iam:GetRolePolicy\",\n                \"iam:PutUserPolicy\",\n                \"iam:PutRolePolicy\",\n                \"iam:GetGroupsForUser\",\n                \"iam:ListAccessKeys\",\n                \"iam:CreateAccessKey\",\n                \"iam:DeleteAccessKey\",\n                \"iam:SimulatePrincipalPolicy\",\n                \"iam:RemoveUserFromGroup\",\n                \"iam:DeleteUserPolicy\",\n                \"iam:DeleteRolePolicy\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre>"},{"location":"servers/iam-mcp-server/#mcp-client-configuration","title":"MCP Client Configuration","text":""},{"location":"servers/iam-mcp-server/#amazon-q-cli","title":"Amazon Q CLI","text":"<p>Add to your <code>~/.aws/amazonq/mcp.json</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.iam-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.iam-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/iam-mcp-server/#cline","title":"Cline","text":"<p>Add to your <code>cline_mcp_settings.json</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.iam-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.iam-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/iam-mcp-server/#cursor","title":"Cursor","text":"<p>Add to your <code>.cursor/mcp.json</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.iam-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.iam-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/iam-mcp-server/#read-only-mode","title":"Read-Only Mode","text":"<p>The server supports a read-only mode that prevents all mutating operations while still allowing read operations. This is useful for:</p> <ul> <li>Safety: Preventing accidental modifications in production environments</li> <li>Testing: Allowing safe exploration of IAM resources without risk of changes</li> <li>Auditing: Running the server in environments where only read access should be allowed</li> </ul>"},{"location":"servers/iam-mcp-server/#enabling-read-only-mode","title":"Enabling Read-Only Mode","text":"<p>Add the <code>--readonly</code> flag when starting the server:</p> <pre><code># Using uvx\nuvx awslabs.iam-mcp-server@latest --readonly\n\n# Or if installed locally\npython -m awslabs.iam_mcp_server.server --readonly\n</code></pre>"},{"location":"servers/iam-mcp-server/#mcp-client-configuration-with-read-only-mode","title":"MCP Client Configuration with Read-Only Mode","text":""},{"location":"servers/iam-mcp-server/#amazon-q-cli_1","title":"Amazon Q CLI","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.iam-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.iam-mcp-server@latest\", \"--readonly\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/iam-mcp-server/#other-mcp-clients","title":"Other MCP Clients","text":"<p>Simply add <code>\"--readonly\"</code> to the args array in your MCP configuration.</p>"},{"location":"servers/iam-mcp-server/#operations-blocked-in-read-only-mode","title":"Operations Blocked in Read-Only Mode","text":"<p>When read-only mode is enabled, the following operations will return an error: - <code>create_user</code> - <code>delete_user</code> - <code>create_role</code> - <code>attach_user_policy</code> - <code>detach_user_policy</code> - <code>create_access_key</code> - <code>delete_access_key</code></p>"},{"location":"servers/iam-mcp-server/#operations-available-in-read-only-mode","title":"Operations Available in Read-Only Mode","text":"<p>These operations continue to work normally: - <code>list_users</code> - <code>get_user</code> - <code>list_roles</code> - <code>list_policies</code> - <code>simulate_principal_policy</code></p>"},{"location":"servers/iam-mcp-server/#available-tools","title":"Available Tools","text":""},{"location":"servers/iam-mcp-server/#user-management","title":"User Management","text":""},{"location":"servers/iam-mcp-server/#list_users","title":"<code>list_users</code>","text":"<p>List IAM users in the account with optional filtering.</p> <p>Parameters: - <code>path_prefix</code> (optional): Path prefix to filter users (e.g., \"/division_abc/\") - <code>max_items</code> (optional): Maximum number of users to return (default: 100)</p>"},{"location":"servers/iam-mcp-server/#get_user","title":"<code>get_user</code>","text":"<p>Get detailed information about a specific IAM user including attached policies, groups, and access keys.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user to retrieve</p>"},{"location":"servers/iam-mcp-server/#create_user","title":"<code>create_user</code>","text":"<p>Create a new IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the new IAM user - <code>path</code> (optional): The path for the user (default: \"/\") - <code>permissions_boundary</code> (optional): ARN of the permissions boundary policy</p>"},{"location":"servers/iam-mcp-server/#delete_user","title":"<code>delete_user</code>","text":"<p>Delete an IAM user with optional force cleanup.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user to delete - <code>force</code> (optional): Force delete by removing all attached resources first (default: false)</p>"},{"location":"servers/iam-mcp-server/#role-management","title":"Role Management","text":""},{"location":"servers/iam-mcp-server/#list_roles","title":"<code>list_roles</code>","text":"<p>List IAM roles in the account with optional filtering.</p> <p>Parameters: - <code>path_prefix</code> (optional): Path prefix to filter roles (e.g., \"/service-role/\") - <code>max_items</code> (optional): Maximum number of roles to return (default: 100)</p>"},{"location":"servers/iam-mcp-server/#create_role","title":"<code>create_role</code>","text":"<p>Create a new IAM role with a trust policy.</p> <p>Parameters: - <code>role_name</code>: The name of the new IAM role - <code>assume_role_policy_document</code>: The trust policy document in JSON format - <code>path</code> (optional): The path for the role (default: \"/\") - <code>description</code> (optional): Description of the role - <code>max_session_duration</code> (optional): Maximum session duration in seconds (default: 3600) - <code>permissions_boundary</code> (optional): ARN of the permissions boundary policy</p>"},{"location":"servers/iam-mcp-server/#group-management","title":"Group Management","text":""},{"location":"servers/iam-mcp-server/#list_groups","title":"<code>list_groups</code>","text":"<p>List IAM groups in the account with optional filtering.</p> <p>Parameters: - <code>path_prefix</code> (optional): Path prefix to filter groups (e.g., \"/division_abc/\") - <code>max_items</code> (optional): Maximum number of groups to return (default: 100)</p>"},{"location":"servers/iam-mcp-server/#get_group","title":"<code>get_group</code>","text":"<p>Get detailed information about a specific IAM group including members, attached policies, and inline policies.</p> <p>Parameters: - <code>group_name</code>: The name of the IAM group to retrieve</p>"},{"location":"servers/iam-mcp-server/#create_group","title":"<code>create_group</code>","text":"<p>Create a new IAM group.</p> <p>Parameters: - <code>group_name</code>: The name of the new IAM group - <code>path</code> (optional): The path for the group (default: \"/\")</p>"},{"location":"servers/iam-mcp-server/#delete_group","title":"<code>delete_group</code>","text":"<p>Delete an IAM group with optional force cleanup.</p> <p>Parameters: - <code>group_name</code>: The name of the IAM group to delete - <code>force</code> (optional): Force delete by removing all members and policies first (default: false)</p>"},{"location":"servers/iam-mcp-server/#add_user_to_group","title":"<code>add_user_to_group</code>","text":"<p>Add a user to an IAM group.</p> <p>Parameters: - <code>group_name</code>: The name of the IAM group - <code>user_name</code>: The name of the IAM user</p>"},{"location":"servers/iam-mcp-server/#remove_user_from_group","title":"<code>remove_user_from_group</code>","text":"<p>Remove a user from an IAM group.</p> <p>Parameters: - <code>group_name</code>: The name of the IAM group - <code>user_name</code>: The name of the IAM user</p>"},{"location":"servers/iam-mcp-server/#attach_group_policy","title":"<code>attach_group_policy</code>","text":"<p>Attach a managed policy to an IAM group.</p> <p>Parameters: - <code>group_name</code>: The name of the IAM group - <code>policy_arn</code>: The ARN of the policy to attach</p>"},{"location":"servers/iam-mcp-server/#detach_group_policy","title":"<code>detach_group_policy</code>","text":"<p>Detach a managed policy from an IAM group.</p> <p>Parameters: - <code>group_name</code>: The name of the IAM group - <code>policy_arn</code>: The ARN of the policy to detach</p>"},{"location":"servers/iam-mcp-server/#policy-management","title":"Policy Management","text":""},{"location":"servers/iam-mcp-server/#list_policies","title":"<code>list_policies</code>","text":"<p>List IAM policies in the account.</p> <p>Parameters: - <code>scope</code> (optional): Scope of policies to list: \"All\", \"AWS\", or \"Local\" (default: \"Local\") - <code>only_attached</code> (optional): Only return policies that are attached (default: false) - <code>path_prefix</code> (optional): Path prefix to filter policies - <code>max_items</code> (optional): Maximum number of policies to return (default: 100)</p>"},{"location":"servers/iam-mcp-server/#attach_user_policy","title":"<code>attach_user_policy</code>","text":"<p>Attach a managed policy to an IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user - <code>policy_arn</code>: The ARN of the policy to attach</p>"},{"location":"servers/iam-mcp-server/#detach_user_policy","title":"<code>detach_user_policy</code>","text":"<p>Detach a managed policy from an IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user - <code>policy_arn</code>: The ARN of the policy to detach</p>"},{"location":"servers/iam-mcp-server/#access-key-management","title":"Access Key Management","text":""},{"location":"servers/iam-mcp-server/#create_access_key","title":"<code>create_access_key</code>","text":"<p>Create a new access key for an IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user</p> <p>\u26a0\ufe0f Security Warning: The secret access key is only returned once and cannot be retrieved again.</p>"},{"location":"servers/iam-mcp-server/#delete_access_key","title":"<code>delete_access_key</code>","text":"<p>Delete an access key for an IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user - <code>access_key_id</code>: The access key ID to delete</p>"},{"location":"servers/iam-mcp-server/#security-analysis","title":"Security Analysis","text":""},{"location":"servers/iam-mcp-server/#simulate_principal_policy","title":"<code>simulate_principal_policy</code>","text":"<p>Simulate IAM policy evaluation for a principal to test permissions.</p> <p>Parameters: - <code>policy_source_arn</code>: ARN of the user or role to simulate - <code>action_names</code>: List of actions to simulate - <code>resource_arns</code> (optional): List of resource ARNs to test against - <code>context_entries</code> (optional): Context entries for the simulation</p>"},{"location":"servers/iam-mcp-server/#inline-policy-management","title":"Inline Policy Management","text":""},{"location":"servers/iam-mcp-server/#put_user_policy","title":"<code>put_user_policy</code>","text":"<p>Create or update an inline policy for an IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user - <code>policy_name</code>: The name of the inline policy - <code>policy_document</code>: The policy document in JSON format (string or dict)</p>"},{"location":"servers/iam-mcp-server/#get_user_policy","title":"<code>get_user_policy</code>","text":"<p>Retrieve an inline policy for an IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user - <code>policy_name</code>: The name of the inline policy</p>"},{"location":"servers/iam-mcp-server/#delete_user_policy","title":"<code>delete_user_policy</code>","text":"<p>Delete an inline policy from an IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user - <code>policy_name</code>: The name of the inline policy to delete</p>"},{"location":"servers/iam-mcp-server/#list_user_policies","title":"<code>list_user_policies</code>","text":"<p>List all inline policies for an IAM user.</p> <p>Parameters: - <code>user_name</code>: The name of the IAM user</p>"},{"location":"servers/iam-mcp-server/#put_role_policy","title":"<code>put_role_policy</code>","text":"<p>Create or update an inline policy for an IAM role.</p> <p>Parameters: - <code>role_name</code>: The name of the IAM role - <code>policy_name</code>: The name of the inline policy - <code>policy_document</code>: The policy document in JSON format (string or dict)</p>"},{"location":"servers/iam-mcp-server/#get_role_policy","title":"<code>get_role_policy</code>","text":"<p>Retrieve an inline policy for an IAM role.</p> <p>Parameters: - <code>role_name</code>: The name of the IAM role - <code>policy_name</code>: The name of the inline policy</p>"},{"location":"servers/iam-mcp-server/#delete_role_policy","title":"<code>delete_role_policy</code>","text":"<p>Delete an inline policy from an IAM role.</p> <p>Parameters: - <code>role_name</code>: The name of the IAM role - <code>policy_name</code>: The name of the inline policy to delete</p>"},{"location":"servers/iam-mcp-server/#list_role_policies","title":"<code>list_role_policies</code>","text":"<p>List all inline policies for an IAM role.</p> <p>Parameters: - <code>role_name</code>: The name of the IAM role</p>"},{"location":"servers/iam-mcp-server/#usage-examples","title":"Usage Examples","text":""},{"location":"servers/iam-mcp-server/#basic-user-management","title":"Basic User Management","text":"<pre><code># List all users\nusers = await list_users()\n\n# Get specific user details\nuser_details = await get_user(user_name=\"john.doe\")\n\n# Create a new user\nnew_user = await create_user(\n    user_name=\"jane.smith\",\n    path=\"/developers/\"\n)\n\n# Delete a user (with force cleanup)\nawait delete_user(user_name=\"old.user\", force=True)\n</code></pre>"},{"location":"servers/iam-mcp-server/#role-management_1","title":"Role Management","text":"<pre><code># Create a role for EC2 instances\ntrust_policy = {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\"Service\": \"ec2.amazonaws.com\"},\n            \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n\nrole = await create_role(\n    role_name=\"EC2-S3-Access-Role\",\n    assume_role_policy_document=json.dumps(trust_policy),\n    description=\"Role for EC2 instances to access S3\"\n)\n</code></pre>"},{"location":"servers/iam-mcp-server/#group-management_1","title":"Group Management","text":"<pre><code># Create a new group\ngroup = await create_group(\n    group_name=\"Developers\",\n    path=\"/teams/\"\n)\n\n# Add users to the group\nawait add_user_to_group(\n    group_name=\"Developers\",\n    user_name=\"john.doe\"\n)\n\n# Attach a policy to the group\nawait attach_group_policy(\n    group_name=\"Developers\",\n    policy_arn=\"arn:aws:iam::123456789012:policy/DeveloperPolicy\"\n)\n\n# Get group details including members\ngroup_details = await get_group(group_name=\"Developers\")\n</code></pre>"},{"location":"servers/iam-mcp-server/#policy-management_1","title":"Policy Management","text":"<pre><code># List customer managed policies\npolicies = await list_policies(scope=\"Local\", only_attached=True)\n\n# Attach a policy to a user\nawait attach_user_policy(\n    user_name=\"developer\",\n    policy_arn=\"arn:aws:iam::123456789012:policy/DeveloperPolicy\"\n)\n</code></pre>"},{"location":"servers/iam-mcp-server/#security-testing","title":"Security Testing","text":"<pre><code># Test if a user can perform specific actions\nsimulation = await simulate_principal_policy(\n    policy_source_arn=\"arn:aws:iam::123456789012:user/developer\",\n    action_names=[\"s3:GetObject\", \"s3:PutObject\"],\n    resource_arns=[\"arn:aws:s3:::my-bucket/*\"]\n)\n</code></pre>"},{"location":"servers/iam-mcp-server/#inline-policy-management_1","title":"Inline Policy Management","text":"<pre><code># Create an inline policy for a user\npolicy_document = {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\"s3:GetObject\", \"s3:PutObject\"],\n            \"Resource\": \"arn:aws:s3:::my-bucket/*\"\n        }\n    ]\n}\n\nawait put_user_policy(\n    user_name=\"developer\",\n    policy_name=\"S3AccessPolicy\",\n    policy_document=policy_document\n)\n\n# Retrieve an inline policy\npolicy = await get_user_policy(\n    user_name=\"developer\",\n    policy_name=\"S3AccessPolicy\"\n)\n\n# List all inline policies for a user\npolicies = await list_user_policies(user_name=\"developer\")\n\n# Create an inline policy for a role\nawait put_role_policy(\n    role_name=\"EC2-S3-Access-Role\",\n    policy_name=\"S3ReadOnlyPolicy\",\n    policy_document={\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": \"s3:GetObject\",\n                \"Resource\": \"*\"\n            }\n        ]\n    }\n)\n\n# Delete an inline policy\nawait delete_user_policy(\n    user_name=\"developer\",\n    policy_name=\"S3AccessPolicy\"\n)\n</code></pre>"},{"location":"servers/iam-mcp-server/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Principle of Least Privilege: Always grant the minimum permissions necessary</li> <li>Use Roles for Applications: Prefer IAM roles over users for applications</li> <li>Regular Access Reviews: Periodically review and clean up unused users and permissions</li> <li>Access Key Rotation: Regularly rotate access keys</li> <li>Enable MFA: Use multi-factor authentication where possible</li> <li>Permissions Boundaries: Use permissions boundaries to set maximum permissions</li> <li>Policy Simulation: Test policies before applying them to production</li> <li>Prefer Managed Policies: Use managed policies over inline policies for reusable permissions</li> <li>Inline Policy Guidelines: Use inline policies only for permissions unique to a single identity</li> </ol>"},{"location":"servers/iam-mcp-server/#error-handling","title":"Error Handling","text":"<p>The server provides comprehensive error handling with descriptive messages:</p> <ul> <li>Authentication Errors: Clear messages for credential issues</li> <li>Permission Errors: Specific information about missing permissions</li> <li>Resource Not Found: Helpful messages when resources don't exist</li> <li>Validation Errors: Detailed feedback on invalid parameters</li> </ul>"},{"location":"servers/iam-mcp-server/#development","title":"Development","text":""},{"location":"servers/iam-mcp-server/#running-tests","title":"Running Tests","text":"<pre><code># Install development dependencies\nuv sync --dev\n\n# Run tests\nuv run pytest\n\n# Run tests with coverage\nuv run pytest --cov=awslabs.iam_mcp_server\n</code></pre>"},{"location":"servers/iam-mcp-server/#local-development","title":"Local Development","text":"<pre><code># Install in development mode\nuv pip install -e .\n\n# Run the server directly\npython -m awslabs.iam_mcp_server.server\n</code></pre>"},{"location":"servers/iam-mcp-server/#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see the main repository's CONTRIBUTING.md for guidelines.</p>"},{"location":"servers/iam-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0. See the LICENSE file for details.</p>"},{"location":"servers/iam-mcp-server/#support","title":"Support","text":"<p>For issues and questions: 1. Check the AWS IAM documentation 2. Review the MCP specification 3. Open an issue in the GitHub repository</p>"},{"location":"servers/iam-mcp-server/#changelog","title":"Changelog","text":"<p>See CHANGELOG.md for version history and changes.</p>"},{"location":"servers/kendra-index-mcp-server/","title":"AWS Labs Amazon Kendra Index MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Amazon Kendra. This MCP server allows you to use Kendra Indices as additional context for RAG.</p>"},{"location":"servers/kendra-index-mcp-server/#features","title":"Features:","text":"<ul> <li>Enhance your existing MCP-enabled ChatBot with additional RAG indices</li> <li>Enhance the responses from coding assistants such as Cline, Cursor, Windsurf, Amazon Q Developer, etc.</li> </ul>"},{"location":"servers/kendra-index-mcp-server/#pre-requisites","title":"Pre-Requisites:","text":"<ol> <li>Sign-Up for an AWS account</li> <li>Create an Amazon Kendra Index with your RAG documentation</li> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/kendra-index-mcp-server/#tools","title":"Tools:","text":""},{"location":"servers/kendra-index-mcp-server/#kendraquerytool","title":"KendraQueryTool","text":"<ul> <li>The KendraQueryTool takes the query specified by the user and queries a Kendra index to gain additional context for the response. This queries either the default index, or an index specified in the users prompt.</li> <li>Required Parameters: query (str)</li> <li>Optional Parameters: indexId (str), region (str)</li> <li>Example:<ul> <li><code>Can you help me understand how to implement a progress event in the CreateHandler using Java? Use the KendraQueryTool to gain additional context.</code></li> <li><code>Can you use the test-kendra-index to help answer the following questions...</code></li> </ul> </li> </ul>"},{"location":"servers/kendra-index-mcp-server/#kendralistindexestool","title":"KendraListIndexesTool","text":"<ul> <li>The KendraListIndexesTool lists the Kendra Indexes in your account. By default it will list all the indices in the regions provided as environment variables to the mcp config file. Otherwise the region can be specified in the prompt.</li> <li>Optional Parameters: region (str)</li> <li>Example:<ul> <li><code>Can you list the Kendra Indexes in my account in the us-west-2 region</code></li> </ul> </li> </ul>"},{"location":"servers/kendra-index-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/kendra-index-mcp-server/#iam-configuration","title":"IAM Configuration","text":"<ol> <li>Provision a user in your AWS account IAM</li> <li>Attach a policy that contains at a minimum the <code>kendra:Query</code> and <code>kendra:ListIndices</code> permissions. Alternatively the AWS Managed <code>AmazonKendraFullAccess</code> policy can be attached. Always follow the principal or least privilege when granting users permissions. See the documentation for more information on IAM permissions for Amazon Kendra.</li> <li>Use <code>aws configure</code> on your environment to configure the credentials (access ID and access key)</li> </ol>"},{"location":"servers/kendra-index-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <p><pre><code>{\n      \"mcpServers\": {\n            \"awslabs.amazon-kendra-index-mcp-server\": {\n                  \"command\": \"uvx\",\n                  \"args\": [\"awslabs.amazon-kendra-index-mcp-server\"],\n                  \"env\": {\n                    \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n                    \"KENDRA_INDEX_ID\": \"[Your Kendra Index Id]\",\n                    \"AWS_PROFILE\": \"[Your AWS Profile Name]\",\n                    \"AWS_REGION\": \"[Region where your Kendra Index resides]\"\n                  },\n                  \"disabled\": false,\n                  \"autoApprove\": []\n                }\n      }\n}\n</code></pre> or docker after a successful <code>docker build -t awslabs/amazon-kendra-index-mcp-server.</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n</code></pre> <p><pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.amazon-kendra-index-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/amazon-kendra-index-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/kendra-index-mcp-server/#best-practices","title":"Best Practices","text":"<ul> <li>Follow the principle of least privilege when setting up IAM permissions</li> <li>Use separate AWS profiles for different environments (dev, test, prod)</li> <li>Monitor broker metrics and logs for performance and issues</li> <li>Implement proper error handling in your client applications</li> </ul>"},{"location":"servers/kendra-index-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, consider:</p> <ul> <li>This MCP server needs permissions to query and list Amazon Kendra Indexes</li> <li>This MCP server cannot create, modify, or delete resources in your account</li> </ul>"},{"location":"servers/kendra-index-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter permission errors, verify your IAM user has the correct policies attached</li> <li>For connection issues, check network configurations and security groups</li> <li>If resource modification fails with a tag validation error, it means the resource was not created by the MCP server</li> <li>For general Amazon Kendra issues, consult the Amazon Kendra developer guide</li> </ul>"},{"location":"servers/kendra-index-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 0.0.0</p>"},{"location":"servers/lambda-tool-mcp-server/","title":"AWS Lambda Tool MCP Server","text":"<p>A Model Context Protocol (MCP) server for AWS Lambda to select and run Lambda function as MCP tools without code changes.</p>"},{"location":"servers/lambda-tool-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and AWS Lambda functions, allowing generative AI models to access and run Lambda functions as tools. This is useful, for example, to access private resources such as internal applications and databases without the need to provide public network access. This approach allows the model to use other AWS services, private networks, and the public internet.</p> <pre><code>graph LR\n    A[Model] &lt;--&gt; B[MCP Client]\n    B &lt;--&gt; C[\"MCP2Lambda&lt;br&gt;(MCP Server)\"]\n    C &lt;--&gt; D[Lambda Function]\n    D &lt;--&gt; E[Other AWS Services]\n    D &lt;--&gt; F[Internet]\n    D &lt;--&gt; G[VPC]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:4px\n    style D fill:#fbb,stroke:#333,stroke-width:2px\n    style E fill:#fbf,stroke:#333,stroke-width:2px\n    style F fill:#dff,stroke:#333,stroke-width:2px\n    style G fill:#ffd,stroke:#333,stroke-width:2px</code></pre> <p>From a security perspective, this approach implements segregation of duties by allowing the model to invoke the Lambda functions but not to access the other AWS services directly. The client only needs AWS credentials to invoke the Lambda functions. The Lambda functions can then interact with other AWS services (using the function role) and access public or private networks.</p>"},{"location":"servers/lambda-tool-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/lambda-tool-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.lambda-tool-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.lambda-tool-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FUNCTION_PREFIX\": \"your-function-prefix\",\n        \"FUNCTION_LIST\": \"your-first-function, your-second-function\",\n        \"FUNCTION_TAG_KEY\": \"your-tag-key\",\n        \"FUNCTION_TAG_VALUE\": \"your-tag-value\",\n        \"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY\": \"your-function-tag-for-input-schema\"\n      }\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/bedrock-kb-retrieval-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.lambda-tool-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env\",\n          \"FUNCTION_PREFIX=your-function-prefix\",\n          \"--env\",\n          \"FUNCTION_LIST=your-first-function,your-second-function\",\n          \"--env\",\n          \"FUNCTION_TAG_KEY=your-tag-key\",\n          \"--env\",\n          \"FUNCTION_TAG_VALUE=your-tag-value\",\n          \"--env\",\n          \"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY=your-function-tag-for-input-schema\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/lambda-tool-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p> <p>The <code>AWS_PROFILE</code> and the <code>AWS_REGION</code> are optional, their default values are <code>default</code> and <code>us-east-1</code>.</p> <p>You can specify <code>FUNCTION_PREFIX</code>, <code>FUNCTION_LIST</code>, or both. If both are empty, all functions pass the name check. After the name check, if both <code>FUNCTION_TAG_KEY</code> and <code>FUNCTION_TAG_VALUE</code> are set, functions are further filtered by tag (with key=value). If only one of <code>FUNCTION_TAG_KEY</code> and <code>FUNCTION_TAG_VALUE</code>, then no function is selected and a warning is displayed.</p> <p>IMPORTANT: The function name is used as MCP tool name. The function description in AWS Lambda is used as MCP tool description. The function description should clarify when to use the function (what it provides) and how (which parameters). For example, a function that gives access to an internal Customer Relationship Management (CRM) system can use this description: <pre><code>Retrieve customer status on the CRM system based on { 'customerId' } or { 'customerEmail' }\n</code></pre></p> <p>The lambda function parameters can also be provided through the EventBridge Schema Registry, which provides formal JSON Schema. See Schema Support below.</p> <p>Sample functions that can be deployed via AWS SAM are provided in the <code>examples</code> folder.</p>"},{"location":"servers/lambda-tool-mcp-server/#schema-support","title":"Schema Support","text":"<p>The Lambda MCP Server supports input schema through AWS EventBridge Schema Registry. This provides formal JSON Schema documentation for your Lambda function inputs.</p>"},{"location":"servers/lambda-tool-mcp-server/#configuration","title":"Configuration","text":"<p>To use schema validation:</p> <ol> <li>Create your schema in EventBridge Schema Registry</li> <li>Tag your Lambda function with the schema ARN:    <pre><code>Key: FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY (configurable)\nValue: arn:aws:schemas:region:account:schema/registry-name/schema-name\n</code></pre></li> <li>Configure the MCP server with the tag key:    <pre><code>{\n  \"env\": {\n    \"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY\": \"your-schema-arn-tag-key\"\n  }\n}\n</code></pre></li> </ol> <p>When a Lambda function has a schema tag, the MCP server will: 1. Fetch the schema from EventBridge Schema Registry 2. Add the schema to the tool's documentation</p> <p>This provides better documentation compared to describing parameters in the function description.</p>"},{"location":"servers/lambda-tool-mcp-server/#best-practices","title":"Best practices","text":"<ul> <li>Use the <code>FUNCTION_LIST</code> to specify the functions that are available as MCP tools.</li> <li>Use the <code>FUNCTION_PREFIX</code> to specify the prefix of the functions that are available as MCP tools.</li> <li>Use the <code>FUNCTION_TAG_KEY</code> and <code>FUNCTION_TAG_VALUE</code> to specify the tag key and value of the functions that are available as MCP tools.</li> <li>AWS Lambda <code>Description</code> property: the description of the function is used as MCP tool description, so it should be very detailed to help the model understand when and how to use the function</li> <li>Use EventBridge Schema Registry to provide formal input validation:</li> <li>Create JSON Schema definitions for your function inputs</li> <li>Tag functions with their schema ARNs</li> <li>Configure <code>FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY</code> in the MCP server</li> </ul>"},{"location":"servers/lambda-tool-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider:</p> <ul> <li>Only Lambda functions that are in the provided list or with a name starting with the prefix are imported as MCP tools.</li> <li>The MCP server needs permissions to invoke the Lambda functions.</li> <li>Each Lambda function has its own permissions to optionally access other AWS resources.</li> </ul>"},{"location":"servers/memcached-mcp-server/","title":"Amazon ElastiCache Memcached MCP Server","text":"<p>MCP server for interacting with Amazon ElastiCache Memcached through a secure and reliable connection</p>"},{"location":"servers/memcached-mcp-server/#features","title":"Features","text":""},{"location":"servers/memcached-mcp-server/#complete-memcached-protocol-support","title":"Complete Memcached Protocol Support","text":"<ul> <li>Full support for all standard Memcached operations</li> <li>Secure communication with SSL/TLS encryption</li> <li>Automatic connection management and pooling</li> <li>Built-in retry mechanism for failed operations</li> <li>Readonly mode to prevent write operations</li> </ul>"},{"location":"servers/memcached-mcp-server/#readonly-mode","title":"Readonly Mode","text":"<p>The server can be started in readonly mode, which prevents any write operations from being performed. This is useful for scenarios where you want to ensure that no data is modified, such as:</p> <ul> <li>Read-only replicas</li> <li>Production environments where writes should be restricted</li> <li>Debugging and monitoring without risk of data modification</li> </ul> <p>When readonly mode is enabled, any attempt to perform a write operation (set, add, replace, delete, etc.) will return an error message.</p>"},{"location":"servers/memcached-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Access to a Memcached server.</li> <li>For instructions to connect to an Amazon ElastiCache Memcached cache click here</li> </ol>"},{"location":"servers/memcached-mcp-server/#installation","title":"Installation","text":"<p>Here are some ways you can work with MCP (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.memcached-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.memcached-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"MEMCACHED_HOST\": \"your-memcached-host\",\n        \"MEMCACHED_PORT\": \"11211\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>To run in readonly mode:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.memcached-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.memcached-mcp-server@latest\", \"--readonly\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"MEMCACHED_HOST\": \"your-memcached-host\",\n        \"MEMCACHED_PORT\": \"11211\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/memcached-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.memcached-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"MEMCACHED_HOST=your-memcached-host\",\n        \"--env\",\n        \"MEMCACHED_PORT=11211\",\n        \"awslabs/memcached-mcp-server:latest\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>To run in readonly mode with Docker:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.memcached-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"MEMCACHED_HOST=your-memcached-host\",\n        \"--env\",\n        \"MEMCACHED_PORT=11211\",\n        \"awslabs/memcached-mcp-server:latest\",\n        \"--readonly\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/memcached-mcp-server/#configuration","title":"Configuration","text":""},{"location":"servers/memcached-mcp-server/#basic-connection-settings","title":"Basic Connection Settings","text":"<p>Configure the connection using these environment variables:</p> <pre><code># Basic settings\nMEMCACHED_HOST=127.0.0.1          # Memcached server hostname\nMEMCACHED_PORT=11211              # Memcached server port\nMEMCACHED_TIMEOUT=1              # Operation timeout in seconds\nMEMCACHED_CONNECT_TIMEOUT=5      # Connection timeout in seconds\nMEMCACHED_RETRY_TIMEOUT=1        # Retry delay in seconds\nMEMCACHED_MAX_RETRIES=3         # Maximum number of retry attempts\n</code></pre>"},{"location":"servers/memcached-mcp-server/#ssltls-configuration","title":"SSL/TLS Configuration","text":"<p>Enable and configure SSL/TLS support with these variables:</p> <pre><code># SSL/TLS settings\nMEMCACHED_USE_TLS=true                           # Enable SSL/TLS\nMEMCACHED_TLS_CERT_PATH=/path/to/client-cert.pem # Client certificate\nMEMCACHED_TLS_KEY_PATH=/path/to/client-key.pem   # Client private key\nMEMCACHED_TLS_CA_CERT_PATH=/path/to/ca-cert.pem  # CA certificate\nMEMCACHED_TLS_VERIFY=true                        # Enable cert verification\n</code></pre> <p>The server automatically handles: - Connection establishment and management - SSL/TLS encryption when enabled - Automatic retrying of failed operations - Timeout enforcement and error handling</p>"},{"location":"servers/memcached-mcp-server/#development","title":"Development","text":""},{"location":"servers/memcached-mcp-server/#running-tests","title":"Running Tests","text":"<pre><code>uv venv\nsource .venv/bin/activate\nuv sync\nuv run --frozen pytest\n</code></pre>"},{"location":"servers/memcached-mcp-server/#building-docker-image","title":"Building Docker Image","text":"<pre><code>docker build -t awslabs/memcached-mcp-server .\n</code></pre>"},{"location":"servers/memcached-mcp-server/#running-docker-container","title":"Running Docker Container","text":"<pre><code>docker run -p 8080:8080 \\\n  -e MEMCACHED_HOST=host.docker.internal \\\n  -e MEMCACHED_PORT=11211 \\\n  awslabs/memcached-mcp-server\n</code></pre> <p>To run in readonly mode: <pre><code>docker run -p 8080:8080 \\\n  -e MEMCACHED_HOST=host.docker.internal \\\n  -e MEMCACHED_PORT=11211 \\\n  awslabs/memcached-mcp-server --readonly\n</code></pre></p>"},{"location":"servers/mysql-mcp-server/","title":"AWS Labs MySQL MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Aurora MySQL</p>"},{"location":"servers/mysql-mcp-server/#features","title":"Features","text":""},{"location":"servers/mysql-mcp-server/#natural-language-to-mysql-sql-query","title":"Natural language to MySQL SQL query","text":"<ul> <li>Converting human-readable questions and commands into structured MySQL-compatible SQL queries and executing them against the configured Aurora MySQL database.</li> </ul>"},{"location":"servers/mysql-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Aurora MySQL Cluster with MySQL username and password stored in AWS Secrets Manager</li> <li>Enable RDS Data API for your Aurora MySQL Cluster, see instructions here</li> <li>This MCP server can only be run locally on the same host as your LLM client.</li> <li>Docker runtime</li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/mysql-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.mysql-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.mysql-mcp-server@latest\",\n        \"--resource_arn\", \"[your data]\",\n        \"--secret_arn\", \"[your data]\",\n        \"--database\", \"[your data]\",\n        \"--region\", \"[your data]\",\n        \"--readonly\", \"True\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/mysql-mcp-server/#build-and-install-docker-image-locally-on-the-same-host-of-your-llm-client","title":"Build and install docker image locally on the same host of your LLM client","text":"<ol> <li>'git clone https://github.com/awslabs/mcp.git'</li> <li>Go to sub-directory 'src/mysql-mcp-server/'</li> <li>Run 'docker build -t awslabs/mysql-mcp-server:latest .'</li> </ol>"},{"location":"servers/mysql-mcp-server/#add-or-update-your-llm-clients-config-with-following","title":"Add or update your LLM client's config with following:","text":"<pre><code>\n{\n  \"mcpServers\": {\n    \"awslabs.mysql-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"AWS_ACCESS_KEY_ID=[your data]\",\n        \"-e\", \"AWS_SECRET_ACCESS_KEY=[your data]\",\n        \"-e\", \"AWS_REGION=[your data]\",\n        \"awslabs/mysql-mcp-server:latest\",\n        \"--resource_arn\", \"[your data]\",\n        \"--secret_arn\", \"[your data]\",\n        \"--database\", \"[your data]\",\n        \"--region\", \"[your data]\",\n        \"--readonly\", \"True\"\n      ]\n    }\n  }\n}\n</code></pre> <p>NOTE: By default, only read-only queries are allowed and it is controlled by --readonly parameter above. Set it to False if you also want to allow writable DML or DDL.</p>"},{"location":"servers/mysql-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access the RDS data API, and the secret from AWS Secrets Manager. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for accessing AWS services.</p>"},{"location":"servers/nova-canvas-mcp-server/","title":"Amazon Nova Canvas MCP Server","text":"<p>MCP server for generating images using Amazon Nova Canvas</p>"},{"location":"servers/nova-canvas-mcp-server/#features","title":"Features","text":""},{"location":"servers/nova-canvas-mcp-server/#text-based-image-generation","title":"Text-based image generation","text":"<ul> <li>Create images from text prompts with <code>generate_image</code></li> <li>Customizable dimensions (320-4096px), quality options, and negative prompting</li> <li>Supports multiple image generation (1-5) in single request</li> <li>Adjustable parameters like cfg_scale (1.1-10.0) and seeded generation</li> </ul>"},{"location":"servers/nova-canvas-mcp-server/#color-guided-image-generation","title":"Color-guided image generation","text":"<ul> <li>Generate images with specific color palettes using <code>generate_image_with_colors</code></li> <li>Define up to 10 hex color values to influence the image style and mood</li> <li>Same customization options as text-based generation</li> </ul>"},{"location":"servers/nova-canvas-mcp-server/#workspace-integration","title":"Workspace integration","text":"<ul> <li>Images saved to user-specified workspace directories with automatic folder creation</li> </ul>"},{"location":"servers/nova-canvas-mcp-server/#aws-authentication","title":"AWS authentication","text":"<ul> <li>Uses AWS profiles for secure access to Amazon Nova Canvas services</li> </ul>"},{"location":"servers/nova-canvas-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to Amazon Bedrock and Nova Canvas</li> <li>You need an AWS account with Amazon Bedrock and Amazon Nova Canvas enabled</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to use Amazon Bedrock and Nova Canvas</li> </ol>"},{"location":"servers/nova-canvas-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.nova-canvas-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.nova-canvas-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/nova-canvas-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.nova-canvas-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/nova-canvas-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/nova-canvas-mcp-server/#installing-via-smithery","title":"Installing via Smithery","text":"<p>To install Amazon Nova Canvas MCP Server for Claude Desktop automatically via Smithery:</p> <pre><code>npx -y @smithery/cli install @awslabs/nova-canvas-mcp-server --client claude\n</code></pre>"},{"location":"servers/nova-canvas-mcp-server/#aws-authentication_1","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\",\n  \"AWS_REGION\": \"us-east-1\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access Amazon Bedrock and Amazon Nova Canvas. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for using the Amazon Bedrock model APIs.</p>"},{"location":"servers/openapi-mcp-server/","title":"AWS Labs OpenAPI MCP Server","text":"<p>This project is a server that dynamically creates Model Context Protocol (MCP) tools and resources from OpenAPI specifications. It allows Large Language Models (LLMs) to interact with APIs through the Model Context Protocol.</p>"},{"location":"servers/openapi-mcp-server/#features","title":"Features","text":"<ul> <li>Dynamic Tool Generation: Automatically creates MCP tools from OpenAPI endpoints</li> <li>Intelligent Route Mapping: Maps GET operations with query parameters to TOOLS instead of RESOURCES</li> <li>Makes API operations with query parameters easier for LLMs to understand and use</li> <li>Improves usability of search and filtering endpoints</li> <li>Configurable via the route_patch module</li> <li>Dynamic Prompt Generation: Creates helpful prompts based on API structure</li> <li>Operation-Specific Prompts: Generates natural language prompts for each API operation</li> <li>API Documentation Prompts: Creates comprehensive API documentation prompts</li> <li>Prompt Optimization: Implements token efficiency strategies to reduce costs and enhance clarity<ul> <li>Follows MCP-compliant structure with name, description, arguments, and metadata</li> <li>Achieves 70-75% reduction in token usage while maintaining functionality</li> <li>Uses concise descriptions with essential information for better developer experience</li> </ul> </li> <li>Transport Options: Supports stdio transport</li> <li>Flexible Configuration: Configure via environment variables or command line arguments</li> <li>OpenAPI Support: Works with OpenAPI 3.x specifications in JSON or YAML format</li> <li>OpenAPI Specification Validation: Validates specifications without failing startup if issues detected, logging warnings instead to work with specs having minor issues or non-standard extensions</li> <li>Authentication Support: Supports multiple authentication methods (Basic, Bearer Token, API Key, Cognito)</li> <li>AWS Best Practices: Implements AWS best practices for caching, resilience, and observability</li> <li>Comprehensive Testing: Includes extensive unit and integration tests with high code coverage</li> <li>Metrics Collection: Tracks API calls, tool usage, errors, and performance metrics</li> </ul>"},{"location":"servers/openapi-mcp-server/#installation","title":"Installation","text":""},{"location":"servers/openapi-mcp-server/#from-pypi","title":"From PyPI","text":"<pre><code>pip install \"awslabs.openapi-mcp-server\"\n</code></pre>"},{"location":"servers/openapi-mcp-server/#optional-dependencies","title":"Optional Dependencies","text":"<p>The package supports several optional dependencies:</p> <pre><code># For YAML OpenAPI specification support\npip install \"awslabs.openapi-mcp-server[yaml]\"\n\n# For Prometheus metrics support\npip install \"awslabs.openapi-mcp-server[prometheus]\"\n\n# For testing\npip install \"awslabs.openapi-mcp-server[test]\"\n\n# For all optional dependencies\npip install \"awslabs.openapi-mcp-server[all]\"\n</code></pre>"},{"location":"servers/openapi-mcp-server/#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/awslabs/mcp.git\ncd mcp/src/openapi-mcp-server\npip install -e .\n</code></pre>"},{"location":"servers/openapi-mcp-server/#using-mcp-configuration","title":"Using MCP Configuration","text":"<p>Here are some ways you can work with MCP across AWS (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.openapi-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.openapi-mcp-server@latest\"],\n      \"env\": {\n        \"API_NAME\": \"your-api-name\",\n        \"API_BASE_URL\": \"https://api.example.com\",\n          \"API_SPEC_URL\": \"https://api.example.com/openapi.json\",\n          \"LOG_LEVEL\": \"ERROR\",\n          \"ENABLE_PROMETHEUS\": \"false\",\n          \"ENABLE_OPERATION_PROMPTS\": \"true\",\n          \"UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN\": \"5.0\",\n          \"UVICORN_GRACEFUL_SHUTDOWN\": \"true\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/openapi-mcp-server/#usage","title":"Usage","text":""},{"location":"servers/openapi-mcp-server/#basic-usage","title":"Basic Usage","text":"<pre><code># Start with Petstore API example\nawslabs.openapi-mcp-server --api-name petstore --api-url https://petstore3.swagger.io/api/v3 --spec-url https://petstore3.swagger.io/api/v3/openapi.json\n</code></pre>"},{"location":"servers/openapi-mcp-server/#custom-api","title":"Custom API","text":"<pre><code># Use a different API\nawslabs.openapi-mcp-server --api-name myapi --api-url https://api.example.com --spec-url https://api.example.com/openapi.json\n</code></pre>"},{"location":"servers/openapi-mcp-server/#authenticated-api","title":"Authenticated API","text":"<pre><code># Basic Authentication\nawslabs.openapi-mcp-server --api-url https://api.example.com --spec-url https://api.example.com/openapi.json --auth-type basic --auth-username YOUR_USERNAME --auth-password YOUR_PASSWORD # pragma: allowlist secret\n\n# Bearer Token Authentication\nawslabs.openapi-mcp-server --api-url https://api.example.com --spec-url https://api.example.com/openapi.json --auth-type bearer --auth-token YOUR_TOKEN # pragma: allowlist secret\n\n# API Key Authentication (in header)\nawslabs.openapi-mcp-server --api-url https://api.example.com --spec-url https://api.example.com/openapi.json --auth-type api_key --auth-api-key YOUR_API_KEY --auth-api-key-name X-API-Key --auth-api-key-in header # pragma: allowlist secret\n</code></pre> <p>For detailed information about authentication methods, configuration options, and examples, see AUTHENTICATION.md.</p>"},{"location":"servers/openapi-mcp-server/#local-openapi-specification","title":"Local OpenAPI Specification","text":"<pre><code># Use a local OpenAPI specification file\nawslabs.openapi-mcp-server --spec-path ./openapi.json\n</code></pre>"},{"location":"servers/openapi-mcp-server/#yaml-openapi-specification","title":"YAML OpenAPI Specification","text":"<pre><code># Use a YAML OpenAPI specification file (requires pyyaml)\npip install \"awslabs.openapi-mcp-server[yaml]\"\nawslabs.openapi-mcp-server --spec-path ./openapi.yaml\n</code></pre>"},{"location":"servers/openapi-mcp-server/#local-development-and-testing","title":"Local Development and Testing","text":"<p>For local development and testing, you can use the <code>uvx</code> command with the <code>--refresh</code> and <code>--from</code> options:</p> <pre><code># Run the server from the local directory with the Petstore API\nuvx --refresh --from . awslabs.openapi-mcp-server --api-url https://petstore3.swagger.io/api/v3 --spec-url https://petstore3.swagger.io/api/v3/openapi.json --log-level DEBUG\n</code></pre> <p>Command Options Explained:</p> <ul> <li><code>uvx</code> - The uv package manager's execution tool for running Python packages</li> <li><code>--refresh</code> - Refreshes the package cache to ensure the latest version is used (important during development)</li> <li><code>--from .</code> - Uses the package from the current directory instead of installing from PyPI</li> <li><code>awslabs.openapi-mcp-server</code> - The package name to run</li> <li><code>--api-url</code> - The base URL of the API</li> <li><code>--spec-url</code> - The URL of the OpenAPI specification</li> <li> <p><code>--log-level DEBUG</code> - Sets the logging level to DEBUG for more detailed logs (useful for development) When to Use These Options:</p> </li> <li> <p>Use <code>--refresh</code> when you've made changes to your code and want to ensure the latest version is used</p> </li> <li>Use <code>--log-level DEBUG</code> when you need detailed logs for troubleshooting or development</li> </ul> <p>Note: The Petstore API is a standard OpenAPI schema endpoint that can be used for simple testing without any API authentication configuration. It's perfect for testing your MCP server implementation without setting up your own API.</p>"},{"location":"servers/openapi-mcp-server/#configuration","title":"Configuration","text":""},{"location":"servers/openapi-mcp-server/#environment-variables","title":"Environment Variables","text":"<pre><code># Server configuration\nexport SERVER_NAME=\"My API Server\"\nexport SERVER_DEBUG=true\nexport SERVER_MESSAGE_TIMEOUT=60\nexport SERVER_HOST=\"0.0.0.0\"\nexport SERVER_PORT=8000\nexport SERVER_TRANSPORT=\"stdio\"  # Option: stdio\nexport LOG_LEVEL=\"INFO\"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL\n\n# Metrics and monitoring configuration\nexport ENABLE_PROMETHEUS=\"false\"  # Enable/disable Prometheus metrics (default: false)\nexport PROMETHEUS_PORT=9090  # Port for Prometheus metrics server\nexport ENABLE_OPERATION_PROMPTS=\"true\"  # Enable/disable operation-specific prompts (default: true)\n\n# Graceful shutdown configuration\nexport UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=5.0  # Timeout for graceful shutdown in seconds\nexport UVICORN_GRACEFUL_SHUTDOWN=true  # Enable/disable graceful shutdown\n\n# API configuration\nexport API_NAME=\"myapi\"\nexport API_BASE_URL=\"https://api.example.com\"\nexport API_SPEC_URL=\"https://api.example.com/openapi.json\"\nexport API_SPEC_PATH=\"/path/to/local/openapi.json\"  # Optional: local file path\n\n# Authentication configuration\nexport AUTH_TYPE=\"none\"  # Options: none, basic, bearer, api_key\nexport AUTH_USERNAME=\"PLACEHOLDER_USERNAME\"  # For basic authentication # pragma: allowlist secret\nexport AUTH_PASSWORD=\"PLACEHOLDER_PASSWORD\"  # For basic authentication # pragma: allowlist secret\nexport AUTH_TOKEN=\"PLACEHOLDER_TOKEN\"  # For bearer token authentication # pragma: allowlist secret\nexport AUTH_API_KEY=\"PLACEHOLDER_API_KEY\"  # For API key authentication # pragma: allowlist secret\nexport AUTH_API_KEY_NAME=\"X-API-Key\"  # Name of the API key (default: api_key)\nexport AUTH_API_KEY_IN=\"header\"  # Where to place the API key (options: header, query, cookie)\n</code></pre>"},{"location":"servers/openapi-mcp-server/#documentation","title":"Documentation","text":"<p>The OpenAPI MCP Server includes comprehensive documentation to help you get started and make the most of its features:</p> <ul> <li>AUTHENTICATION.md: Detailed information about authentication methods, configuration options, and troubleshooting</li> <li>DEPLOYMENT.md: Guidelines for deploying the server in various environments, including Docker and AWS</li> <li>AWS_BEST_PRACTICES.md: AWS best practices implemented in the server for resilience, caching, and efficiency</li> <li>OBSERVABILITY.md: Information about metrics, logging, and monitoring capabilities</li> <li>tests/README.md: Overview of the test structure and strategy</li> </ul>"},{"location":"servers/openapi-mcp-server/#aws-best-practices","title":"AWS Best Practices","text":"<p>The OpenAPI MCP Server implements AWS best practices for building resilient, observable, and efficient cloud applications. These include:</p> <ul> <li>Caching: Robust caching system with multiple backend options</li> <li>Resilience: Patterns to handle transient failures and ensure high availability</li> <li>Observability: Comprehensive monitoring, metrics, and logging features</li> </ul> <p>For detailed information about these features, including implementation details and configuration options, see AWS_BEST_PRACTICES.md.</p>"},{"location":"servers/openapi-mcp-server/#docker-deployment","title":"Docker Deployment","text":"<p>The project includes a Dockerfile for containerized deployment. To build and run:</p> <pre><code># Build the Docker image\ndocker build -t openapi-mcp-server:latest .\n\n# Run with default settings\ndocker run -p 8000:8000 openapi-mcp-server:latest\n\n# Run with custom configuration\ndocker run -p 8000:8000 \\\n  -e API_NAME=myapi \\\n  -e API_BASE_URL=https://api.example.com \\\n  -e API_SPEC_URL=https://api.example.com/openapi.json \\\n  -e SERVER_TRANSPORT=stdio \\\n  -e ENABLE_PROMETHEUS=false \\\n  -e ENABLE_OPERATION_PROMPTS=true \\\n  -e UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=5.0 \\\n  -e UVICORN_GRACEFUL_SHUTDOWN=true \\\n  openapi-mcp-server:latest\n</code></pre> <p>For detailed information about Docker deployment, AWS service integration, and transport considerations, see the DEPLOYMENT.md file.</p>"},{"location":"servers/openapi-mcp-server/#testing","title":"Testing","text":"<p>The project includes a comprehensive test suite covering unit tests, integration tests, and API functionality tests.</p>"},{"location":"servers/openapi-mcp-server/#running-tests","title":"Running Tests","text":"<pre><code># Install test dependencies\npip install \"awslabs.openapi-mcp-server[test]\"\n\n# Run all tests\npytest\n\n# Run tests with coverage\npytest --cov=awslabs\n\n# Run specific test modules\npytest tests/api/\npytest tests/utils/\n</code></pre> <p>The test suite covers:</p> <ol> <li>API Configuration: Tests for API configuration handling and validation</li> <li>API Discovery: Tests for API endpoint discovery and tool generation</li> <li>Caching: Tests for the caching system and providers</li> <li>HTTP Client: Tests for the HTTP client with resilience features</li> <li>Metrics: Tests for metrics collection and reporting</li> <li>OpenAPI Validation: Tests for OpenAPI specification validation</li> </ol> <p>For more information about the test structure and strategy, see the tests/README.md file.</p>"},{"location":"servers/openapi-mcp-server/#instructions","title":"Instructions","text":"<p>This server acts as a bridge between OpenAPI specifications and LLMs, allowing models to have a better understanding of available API capabilities without requiring manual tool definitions. The server creates structured MCP tools that LLMs can use to understand and interact with your API endpoints, parameters, and response formats.</p>"},{"location":"servers/openapi-mcp-server/#key-features","title":"Key Features","text":"<ol> <li>Dynamic Tool Generation: Automatically creates MCP tools from your API endpoints</li> <li>Operation-Specific Prompts: Generates natural language prompts for each API operation</li> <li>API Documentation: Creates comprehensive documentation prompts for the entire API</li> <li>Authentication Support: Works with Basic Auth, Bearer Token, API Key, and Cognito authentication</li> </ol>"},{"location":"servers/openapi-mcp-server/#getting-started","title":"Getting Started","text":"<ol> <li>Point the server to your API by providing:</li> <li>API name</li> <li>API base URL</li> <li>OpenAPI specification URL or local file path</li> <li>Set up appropriate authentication if your API requires it</li> <li>Configure the stdio transport option</li> </ol>"},{"location":"servers/openapi-mcp-server/#monitoring-and-metrics","title":"Monitoring and Metrics","text":"<p>The server includes built-in monitoring capabilities: - Prometheus metrics (disabled by default) - Detailed logging of API calls and tool usage - Performance tracking for API operations</p>"},{"location":"servers/openapi-mcp-server/#testing-with-amazon-q","title":"Testing with Amazon Q","text":"<p>To test the OpenAPI MCP Server with Amazon Q, you need to configure Amazon Q to use your MCP server. Here's how:</p> <ol> <li>Configure Amazon Q MCP Integration</li> </ol> <p>Create or edit the MCP configuration file:</p> <pre><code>mkdir -p ~/.aws/amazonq\nnano ~/.aws/amazonq/mcp.json\n</code></pre> <p>Add the following configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.openapi-mcp-server\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"awslabs.openapi_mcp_server\"],\n      \"cwd\": \"/path/to/your/openapi-mcp-server\",\n      \"env\": {\n        \"API_NAME\": \"petstore\",\n        \"API_BASE_URL\": \"https://petstore3.swagger.io/api/v3\",\n        \"API_SPEC_URL\": \"https://petstore3.swagger.io/api/v3/openapi.json\",\n        \"LOG_LEVEL\": \"INFO\",\n        \"ENABLE_PROMETHEUS\": \"false\",\n        \"ENABLE_OPERATION_PROMPTS\": \"true\",\n        \"UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN\": \"5.0\",\n        \"UVICORN_GRACEFUL_SHUTDOWN\": \"true\",\n        \"PYTHONPATH\": \"/path/to/your/openapi-mcp-server\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <ol> <li>Start Amazon Q CLI</li> </ol> <p>Launch the Amazon Q CLI:</p> <pre><code>q chat\n</code></pre> <ol> <li>Test the Operation Prompts</li> </ol> <p>Once connected, you can test the operation prompts by asking Amazon Q to help you with specific API operations:</p> <pre><code>I need to find a pet by ID using the Petstore API\n</code></pre> <p>Amazon Q should respond with guidance using the natural language prompt.</p>"},{"location":"servers/postgres-mcp-server/","title":"AWS Labs postgres MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Aurora Postgres</p>"},{"location":"servers/postgres-mcp-server/#features","title":"Features","text":""},{"location":"servers/postgres-mcp-server/#natural-language-to-postgres-sql-query","title":"Natural language to Postgres SQL query","text":"<ul> <li>Converting human-readable questions and commands into structured Postgres-compatible SQL queries and executing them against the configured Aurora Postgres database.</li> </ul>"},{"location":"servers/postgres-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Aurora Postgres Cluster with Postgres username and password stored in AWS Secrets Manager</li> <li>Enable RDS Data API for your Aurora Postgres Cluster, see instructions here</li> <li>This MCP server can only be run locally on the same host as your LLM client.</li> <li>Docker runtime</li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/postgres-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.postgres-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.postgres-mcp-server@latest\",\n        \"--resource_arn\", \"[your data]\",\n        \"--secret_arn\", \"[your data]\",\n        \"--database\", \"[your data]\",\n        \"--region\", \"[your data]\",\n        \"--readonly\", \"True\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/postgres-mcp-server/#build-and-install-docker-image-locally-on-the-same-host-of-your-llm-client","title":"Build and install docker image locally on the same host of your LLM client","text":"<ol> <li>'git clone https://github.com/awslabs/mcp.git'</li> <li>Go to sub-directory 'src/postgres-mcp-server/'</li> <li>Run 'docker build -t awslabs/postgres-mcp-server:latest .'</li> </ol>"},{"location":"servers/postgres-mcp-server/#add-or-update-your-llm-clients-config-with-following","title":"Add or update your LLM client's config with following:","text":"<pre><code>\n{\n  \"mcpServers\": {\n    \"awslabs.postgres-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"AWS_ACCESS_KEY_ID=[your data]\",\n        \"-e\", \"AWS_SECRET_ACCESS_KEY=[your data]\",\n        \"-e\", \"AWS_REGION=[your data]\",\n        \"awslabs/postgres-mcp-server:latest\",\n        \"--resource_arn\", \"[your data]\",\n        \"--secret_arn\", \"[your data]\",\n        \"--database\", \"[your data]\",\n        \"--region\", \"[your data]\",\n        \"--readonly\", \"True\"\n      ]\n    }\n  }\n}\n</code></pre> <p>NOTE: By default, only read-only queries are allowed and it is controlled by --readonly parameter above. Set it to False if you also want to allow writable DML or DDL.</p>"},{"location":"servers/postgres-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access the RDS data API, and the secret from AWS Secrets Manager. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for accessing AWS services.</p>"},{"location":"servers/prometheus-mcp-server/","title":"Prometheus MCP Server","text":"<p>The Prometheus MCP Server provides a robust interface for interacting with AWS Managed Prometheus, enabling users to execute PromQL queries, list metrics, and retrieve server information with AWS SigV4 authentication support.</p> <p>This MCP server is designed to be fully compatible with Amazon Q developer CLI, allowing seamless integration of Prometheus monitoring capabilities into your Amazon Q workflows. You can load the server directly into Amazon Q to leverage its powerful querying and metric analysis features through the familiar Q interface.</p>"},{"location":"servers/prometheus-mcp-server/#features","title":"Features","text":"<ul> <li>Execute instant PromQL queries against AWS Managed Prometheus</li> <li>Execute range queries with start time, end time, and step interval</li> <li>List all available metrics in your Prometheus instance</li> <li>Get server configuration information</li> <li>AWS SigV4 authentication for secure access</li> <li>Automatic retries with exponential backoff</li> </ul>"},{"location":"servers/prometheus-mcp-server/#installation","title":"Installation","text":""},{"location":"servers/prometheus-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>AWS credentials configured with appropriate permissions</li> <li>AWS Managed Prometheus workspace</li> </ul>"},{"location":"servers/prometheus-mcp-server/#configuration","title":"Configuration","text":"<p>The server is configured through the Amazon Q MCP configuration file as shown in the Usage section below.</p>"},{"location":"servers/prometheus-mcp-server/#usage-with-amazon-q","title":"Usage with Amazon Q","text":"<p>Here are some ways you can work with MCP across AWS, and we'll be adding support to more products including Amazon Q Developer CLI soon:</p> <ol> <li> <p>Create a configuration file: <pre><code>mkdir -p ~/.aws/amazonq/\n</code></pre></p> </li> <li> <p>Add the following to <code>~/.aws/amazonq/mcp.json</code>:</p> </li> </ol>"},{"location":"servers/prometheus-mcp-server/#basic-configuration","title":"Basic Configuration","text":"<pre><code>{\n  \"mcpServers\": {\n    \"prometheus\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.prometheus-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"DEBUG\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/prometheus-mcp-server/#configuration-with-optional-arguments","title":"Configuration with Optional Arguments","text":"<pre><code>{\n  \"mcpServers\": {\n    \"prometheus\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.prometheus-mcp-server@latest\",\n        \"--url\",\n        \"https://aps-workspaces.&lt;AWS Region&gt;.amazonaws.com/workspaces/ws-&lt;Workspace ID&gt;\",\n        \"--region\",\n        \"&lt;Your AWS Region&gt;\",\n        \"--profile\",\n        \"&lt;Your CLI Profile&gt;\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"DEBUG\"\n      }\n    }\n  }\n}\n</code></pre> <ol> <li>In Amazon Q, you can now use the Prometheus MCP server to query your metrics.</li> </ol>"},{"location":"servers/prometheus-mcp-server/#available-tools","title":"Available Tools","text":"<ol> <li>GetAvailableWorkspaces</li> <li>List all available Prometheus workspaces in the specified region</li> <li>Parameters: region (optional)</li> <li> <p>Returns: List of workspaces with IDs, aliases, and status</p> </li> <li> <p>ExecuteQuery</p> </li> <li>Execute instant PromQL queries against Prometheus</li> <li> <p>Parameters: workspace_id (required), query (required), time (optional), region (optional)</p> </li> <li> <p>ExecuteRangeQuery</p> </li> <li>Execute PromQL queries over a time range</li> <li> <p>Parameters: workspace_id (required), query, start time, end time, step interval, region (optional)</p> </li> <li> <p>ListMetrics</p> </li> <li>Retrieve all available metric names from Prometheus</li> <li>Parameters: workspace_id (required), region (optional)</li> <li> <p>Returns: Sorted list of metric names</p> </li> <li> <p>GetServerInfo</p> </li> <li>Retrieve server configuration details</li> <li>Parameters: workspace_id (required), region (optional)</li> <li>Returns: URL, region, profile, and service information</li> </ol>"},{"location":"servers/prometheus-mcp-server/#example-queries","title":"Example Queries","text":"<pre><code># Get available workspaces\nworkspaces = await get_available_workspaces()\nfor ws in workspaces['workspaces']:\n    print(f\"ID: {ws['workspace_id']}, Alias: {ws['alias']}, Status: {ws['status']}\")\n\n# Execute an instant query\nresult = await execute_query(\n    workspace_id=\"ws-12345678-abcd-1234-efgh-123456789012\",\n    query=\"up\"\n)\n\n# Execute a range query\ndata = await execute_range_query(\n    workspace_id=\"ws-12345678-abcd-1234-efgh-123456789012\",\n    query=\"rate(node_cpu_seconds_total[5m])\",\n    start=\"2023-01-01T00:00:00Z\",\n    end=\"2023-01-01T01:00:00Z\",\n    step=\"1m\"\n)\n\n# List available metrics\nmetrics = await list_metrics(\n    workspace_id=\"ws-12345678-abcd-1234-efgh-123456789012\"\n)\n\n# Get server information\ninfo = await get_server_info(\n    workspace_id=\"ws-12345678-abcd-1234-efgh-123456789012\"\n)\n</code></pre>"},{"location":"servers/prometheus-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li>AWS Credentials Not Found</li> <li>Check ~/.aws/credentials</li> <li>Set AWS_PROFILE environment variable</li> <li> <p>Verify IAM permissions</p> </li> <li> <p>Connection Errors</p> </li> <li>Verify Prometheus URL is correct</li> <li>Check network connectivity</li> <li> <p>Ensure AWS VPC access is configured correctly</p> </li> <li> <p>Authentication Failures</p> </li> <li>Verify AWS credentials are current</li> <li>Check system clock synchronization</li> <li>Ensure correct AWS region is specified</li> </ol>"},{"location":"servers/prometheus-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"servers/redshift-mcp-server/","title":"Amazon Redshift MCP Server","text":"<p>Model Context Protocol (MCP) server for Amazon Redshift.</p> <p>This MCP server provides tools to discover, explore, and query Amazon Redshift clusters and serverless workgroups. It enables AI assistants to interact with Redshift resources safely and efficiently through a comprehensive set of discovery and query execution tools.</p>"},{"location":"servers/redshift-mcp-server/#features","title":"Features","text":"<ul> <li>Cluster Discovery: Automatically discover both provisioned Redshift clusters and serverless workgroups</li> <li>Metadata Exploration: Browse databases, schemas, tables, and columns</li> <li>Safe Query Execution: Execute SQL queries in a READ ONLY mode (a safe READ WRITE support is planned to be implemnted in the future versions)</li> <li>Multi-Cluster Support: Work with multiple clusters and workgroups simultaneously</li> </ul>"},{"location":"servers/redshift-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/redshift-mcp-server/#installation-requirements","title":"Installation Requirements","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python 3.10 or newer using <code>uv python install 3.10</code> (or a more recent version)</li> </ol>"},{"location":"servers/redshift-mcp-server/#aws-client-requirements","title":"AWS Client Requirements","text":"<ol> <li>Credentials: Configure AWS credentials via AWS CLI, or environment variables</li> <li>Permissions: Ensure your AWS credentials have the required permissions (see Permissions section)</li> </ol>"},{"location":"servers/redshift-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.redshift-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.redshift-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/redshift-mcp-server:latest .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.redshift-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\", \"AWS_ACCESS_KEY_ID=[your data]\",\n        \"--env\", \"AWS_SECRET_ACCESS_KEY=[your data]\",\n        \"--env\", \"AWS_REGION=[your data]\",\n        \"awslabs/redshift-mcp-server:latest\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"servers/redshift-mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>AWS_REGION</code>: AWS region to use (default: <code>us-east-1</code>)</li> <li><code>AWS_PROFILE</code>: AWS profile to use (optional, uses default if not specified)</li> <li><code>FASTMCP_LOG_LEVEL</code>: Logging level (<code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>)</li> <li><code>LOG_FILE</code>: Path to log file (optional, logs to stdout if not specified)</li> </ul>"},{"location":"servers/redshift-mcp-server/#basic-usage","title":"Basic Usage","text":""},{"location":"servers/redshift-mcp-server/#discovery-workflow","title":"Discovery Workflow","text":"<ol> <li>Discover Clusters: Find available Redshift resources</li> <li>List Databases: Explore databases in a specific cluster</li> <li>Browse Database Structures: Navigate through schemas, tables, columns</li> <li>Query Data: Execute SQL queries safely with a natural language prompt</li> </ol>"},{"location":"servers/redshift-mcp-server/#simple-examples","title":"Simple Examples","text":"<ul> <li>\"Show me all available Redshift clusters\"</li> <li>\"List databases in cluster 'my-redshift-cluster'\"</li> <li>\"What tables are in the 'public' schema of database 'analytics'?\"</li> <li>\"Execute: SELECT COUNT(*) FROM users WHERE created_date &gt; '2024-01-01'\"</li> </ul>"},{"location":"servers/redshift-mcp-server/#advanced-examples","title":"Advanced Examples","text":""},{"location":"servers/redshift-mcp-server/#natural-language-data-request","title":"Natural Language Data Request","text":"<pre><code>&gt; Show me the last 3 sales from the analytics Redshift cluster.\nI'll help you retrieve the last 3 sales from your analytics Redshift cluster. Let me start by discovering your available Redshift clusters and then\nexplore the database structure to find the sales data.\n\n...skipping the auto-discovery logs...\n\nHere are the last 3 sales from your analytics Redshift cluster:\n\nMost Recent Sales (from tickit.sales table):\n\n1. Sale ID 102373 - December 31, 2008 at 12:58:19\n   \u2022 Price paid: $1,008.00\n   \u2022 Seller ID: 26190, Buyer ID: 35491\n\n2. Sale ID 75861 - December 31, 2008 at 12:50:02\n   \u2022 Price paid: $372.00\n   \u2022 Seller ID: 43402, Buyer ID: 39545\n\n3. Sale ID 56302 - December 31, 2008 at 12:08:14\n   \u2022 Price paid: $372.00\n   \u2022 Seller ID: 5760, Buyer ID: 5797\n\nThe data shows ticket sales from the TICKIT sample dataset, which appears to be for event ticket transactions. All three sales occurred on December 31, 2008, with the most recent sale being for $1,008 for 4 tickets.\n\n&gt; Briefly describe your actions.\nI performed the following actions to retrieve the last 3 sales from your analytics Redshift cluster:\n\n1. Discovered clusters - Listed all available Redshift clusters and identified redshift-cluster-analytics as your analytics cluster\n2. Explored databases - Found two databases: dev and sample_data_dev\n3. Located schemas - Checked the sample_data_dev database and found the tickit schema containing sample data\n4. Found sales table - Identified the sales table within the tickit schema\n5. Analyzed table structure - Examined the columns in the sales table (salesid, pricepaid, qtysold, saletime, etc.)\n6. Executed query - Ran a SQL query to get the 3 most recent sales ordered by saletime DESC\n\nThe process involved using the Redshift MCP tools to systematically navigate the cluster structure and retrieve the requested sales data from the TICKIT sample dataset.\n\n&gt; Show me the query text which you executed to get the sales.\nHere's the exact SQL query I executed to get the last 3 sales:\n\nsql\nSELECT salesid, listid, sellerid, buyerid, eventid, qtysold, pricepaid, commission, saletime\nFROM tickit.sales\nORDER BY saletime DESC\nLIMIT 3;\n</code></pre>"},{"location":"servers/redshift-mcp-server/#cross-cluster-data-comparison-request","title":"Cross-Cluster Data Comparison Request","text":"<pre><code>&gt; How off is the analytics sales data from the ETL sales data based on the recent records in Redshift?\nI'll help you analyze sales data from your Redshift ETL pipeline. To get started, I need to discover your Redshift environment and understand the data\nstructure.\n\n...skipping auto-discovery logs...\n\n# Sales Data Comparison: Analytics vs ETL\n\n## Executive Summary\nSales data between Analytics cluster and ETL workgroup is perfectly synchronized with zero discrepancies found.\n\n## Environment Overview\n\u2022 **Analytics**: redshift-cluster-analytics (Provisioned, 2x dc2.large nodes)\n\u2022 **ETL**: redshift-workgroup-etl (Serverless)\n\u2022 **Database**: sample_data_dev.tickit.sales\n\n## Data Comparison Results\n\n### High-Level Metrics\n| Metric          | Analytics Cluster | ETL Workgroup     | Status |\n|-----------------|-------------------|-------------------|--------|\n| Total Records   | 172,456           | 172,456           | Match  |\n| Total Revenue   | $110,765,431      | $110,765,431      | Match  |\n| Total Quantity  | 345,349           | 345,349           | Match  |\n| Average Price   | $642.28           | $642.28           | Match  |\n| Date Range      | 2008-01-01 to 2008-12-31 | 2008-01-01 to 2008-12-31 | Match |\n\n### Recent Sales (Q4 2008)\n| Month    | Analytics Revenue | ETL Revenue   | Analytics Txns | ETL Txns | Status |\n|----------|-------------------|---------------|----------------|----------|--------|\n| Dec 2008 | $4,521,806        | $4,521,806    | 7,059          | 7,059    | Match  |\n| Nov 2008 | $9,044,905        | $9,044,905    | 14,261         | 14,261   | Match  |\n| Oct 2008 | $10,726,368       | $10,726,368   | 16,741         | 16,741   | Match  |\n\n## Key Findings\n\u2022 Data Integrity: Perfect synchronization across all metrics\n\u2022 Verification: Transaction-level details match exactly (verified 10 recent records)\n\n&gt; Briefly describe your actions.\nI analyzed sales data from your Redshift environments by:\n\n1. Discovered Infrastructure: Found 3 Redshift environments (analytics cluster, marketing cluster, ETL workgroup)\n2. Explored Data Structure: Located sales data in sample_data_dev.tickit.sales table with 10 columns including salesid, pricepaid, qtysold, and saletime\n3. Compared High-Level Metrics: Ran aggregate queries on both analytics cluster and ETL workgroup to compare total records (172,456), revenue ($110M), and date ranges\n4. Analyzed Recent Data: Examined Q4 2008 monthly sales trends and verified the 10 most recent transactions from Dec 30-31, 2008\n5. Performance Testing: Measured query execution times across different query types (6.7-19.5 seconds range)\n6. Generated Report: Created a comprehensive comparison showing perfect data synchronization between environments with performance insights and recommendations\n\n&gt; Show me the text of the SQL queries you used.\nHere are the SQL queries I executed during the analysis:\n\n## 1. High-Level Metrics Query\nsql\nSELECT\n    COUNT(*) as total_records,\n    MIN(saletime) as earliest_sale,\n    MAX(saletime) as latest_sale,\n    SUM(pricepaid) as total_revenue,\n    SUM(qtysold) as total_quantity,\n    AVG(pricepaid) as avg_price\nFROM tickit.sales;\n\n## 2. Recent Monthly Sales Analysis\nsql\nSELECT\n    DATE_TRUNC('month', saletime) as sale_month,\n    COUNT(*) as transaction_count,\n    SUM(pricepaid) as monthly_revenue,\n    SUM(qtysold) as monthly_quantity,\n    AVG(pricepaid) as avg_transaction_value\nFROM tickit.sales\nWHERE saletime &gt;= '2008-10-01'\nGROUP BY DATE_TRUNC('month', saletime)\nORDER BY sale_month DESC\nLIMIT 10;\n\n## 3. Recent Transaction Details\nsql\nSELECT\n    salesid,\n    listid,\n    sellerid,\n    buyerid,\n    eventid,\n    qtysold,\n    pricepaid,\n    commission,\n    saletime\nFROM tickit.sales\nWHERE saletime &gt;= '2008-12-30'\nORDER BY saletime DESC, salesid DESC\nLIMIT 10;\n</code></pre>"},{"location":"servers/redshift-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/redshift-mcp-server/#list_clusters","title":"list_clusters","text":"<p>Discovers all available Amazon Redshift clusters and serverless workgroups.</p> <pre><code>list_clusters() -&gt; list[RedshiftCluster]\n</code></pre> <p>Returns: List of cluster information including:</p> <ul> <li>Cluster identifier and type (provisioned/serverless)</li> <li>Status and connection details</li> <li>Configuration information (node type, encryption, etc.)</li> <li>Tags and metadata</li> </ul>"},{"location":"servers/redshift-mcp-server/#list_databases","title":"list_databases","text":"<p>Lists all databases in a specified Redshift cluster.</p> <pre><code>list_databases(cluster_identifier: str, database_name: str = \"dev\") -&gt; list[RedshiftDatabase]\n</code></pre> <p>Parameters:</p> <ul> <li><code>cluster_identifier</code>: The cluster identifier from <code>list_clusters</code></li> <li><code>database_name</code>: Database to connect to for querying (default: \"dev\")</li> </ul> <p>Returns: List of database information including:</p> <ul> <li>Database name and owner</li> <li>Database type (local/shared)</li> <li>Access control information</li> <li>Isolation level</li> </ul>"},{"location":"servers/redshift-mcp-server/#list_schemas","title":"list_schemas","text":"<p>Lists all schemas in a specified database.</p> <pre><code>list_schemas(cluster_identifier: str, schema_database_name: str) -&gt; list[RedshiftSchema]\n</code></pre> <p>Parameters:</p> <ul> <li><code>cluster_identifier</code>: The cluster identifier from <code>list_clusters</code></li> <li><code>schema_database_name</code>: Database name to list schemas for</li> </ul> <p>Returns: List of schema information including:</p> <ul> <li>Schema name and owner</li> <li>Schema type (local/external/shared)</li> <li>Access permissions</li> <li>External schema details (if applicable)</li> </ul>"},{"location":"servers/redshift-mcp-server/#list_tables","title":"list_tables","text":"<p>Lists all tables in a specified schema.</p> <pre><code>list_tables(cluster_identifier: str, table_database_name: str, table_schema_name: str) -&gt; list[RedshiftTable]\n</code></pre> <p>Parameters:</p> <ul> <li><code>cluster_identifier</code>: The cluster identifier from <code>list_clusters</code></li> <li><code>table_database_name</code>: Database name containing the schema</li> <li><code>table_schema_name</code>: Schema name to list tables for</li> </ul> <p>Returns: List of table information including:</p> <ul> <li>Table name and type (TABLE/VIEW/EXTERNAL TABLE)</li> <li>Access permissions</li> <li>Remarks and metadata</li> </ul>"},{"location":"servers/redshift-mcp-server/#list_columns","title":"list_columns","text":"<p>Lists all columns in a specified table.</p> <pre><code>list_columns(\n    cluster_identifier: str,\n    column_database_name: str,\n    column_schema_name: str,\n    column_table_name: str\n) -&gt; list[RedshiftColumn]\n</code></pre> <p>Parameters:</p> <ul> <li><code>cluster_identifier</code>: The cluster identifier from <code>list_clusters</code></li> <li><code>column_database_name</code>: Database name containing the table</li> <li><code>column_schema_name</code>: Schema name containing the table</li> <li><code>column_table_name</code>: Table name to list columns for</li> </ul> <p>Returns: List of column information including:</p> <ul> <li>Column name and data type</li> <li>Nullable status and default values</li> <li>Numeric precision and scale</li> <li>Character length limits</li> <li>Ordinal position and remarks</li> </ul>"},{"location":"servers/redshift-mcp-server/#execute_query","title":"execute_query","text":"<p>Executes a SQL query against a Redshift cluster with safety protections.</p> <pre><code>execute_query(cluster_identifier: str, database_name: str, sql: str) -&gt; QueryResult\n</code></pre> <p>Parameters:</p> <ul> <li><code>cluster_identifier</code>: The cluster identifier from <code>list_clusters</code></li> <li><code>database_name</code>: Database to execute the query against</li> <li><code>sql</code>: SQL statement to execute (SELECT statements recommended)</li> </ul> <p>Returns: Query result including:</p> <ul> <li>Column names and data types</li> <li>Result rows with proper type conversion</li> <li>Row count and execution time</li> <li>Query ID for reference</li> </ul>"},{"location":"servers/redshift-mcp-server/#permissions","title":"Permissions","text":""},{"location":"servers/redshift-mcp-server/#aws-iam-permissions","title":"AWS IAM Permissions","text":"<p>Your AWS credentials need the following IAM permissions:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"redshift:DescribeClusters\",\n        \"redshift-serverless:ListWorkgroups\",\n        \"redshift-serverless:GetWorkgroup\",\n        \"redshift-data:ExecuteStatement\",\n        \"redshift-data:BatchExecuteStatement\",\n        \"redshift-data:DescribeStatement\",\n        \"redshift-data:GetStatementResult\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"servers/redshift-mcp-server/#database-permissions","title":"Database Permissions","text":"<p>In addition to AWS IAM permissions, you need appropriate database-level permissions:</p> <ul> <li>Read Access: <code>SELECT</code> permissions on tables/views you want to query</li> <li>Schema Access: <code>USAGE</code> permissions on schemas you want to explore</li> <li>Database Access: Connection permissions to databases you want to access</li> </ul>"},{"location":"servers/stepfunctions-tool-mcp-server/","title":"AWS Step Functions Tool MCP Server","text":"<p>A Model Context Protocol (MCP) server for AWS Step Functions to select and run state machines as MCP tools without code changes.</p>"},{"location":"servers/stepfunctions-tool-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and AWS Step Functions state machines, allowing generative AI models to access and run state machines as tools. This enables seamless integration with existing Step Function workflows without requiring any modifications to their definitions. Through this bridge, AI models can execute and manage complex, multi-step business processes that coordinate operations across multiple AWS services.</p> <p>The server supports both Standard and Express workflows, adapting to different execution needs. Standard workflows excel at long-running processes where status tracking is essential, while Express workflows handle high-volume, short-duration tasks with synchronous execution. This flexibility ensures optimal handling of various workflow patterns and requirements.</p> <p>To ensure data quality and provide clear documentation, the server integrates with EventBridge Schema Registry for input validation. It combines schema information with state machine definitions to generate comprehensive tool documentation, helping AI models understand both the purpose and technical requirements of each workflow.</p> <p>From a security perspective, the server implements IAM-based authentication and authorization, creating a clear separation of duties. While models can invoke state machines through the MCP server, they don't have direct access to other AWS services. Instead, the state machines themselves handle AWS service interactions using their own IAM roles, maintaining robust security boundaries while enabling powerful workflow capabilities.</p> <pre><code>graph LR\n    A[Model] &lt;--&gt; B[MCP Client]\n    B &lt;--&gt; C[\"MCP2StepFunctions&lt;br&gt;(MCP Server)\"]\n    C &lt;--&gt; D[State Machine]\n    D &lt;--&gt; E[Other AWS Services]\n    D &lt;--&gt; F[Internet]\n    D &lt;--&gt; G[VPC]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:4px\n    style D fill:#fbb,stroke:#333,stroke-width:2px\n    style E fill:#fbf,stroke:#333,stroke-width:2px\n    style F fill:#dff,stroke:#333,stroke-width:2px\n    style G fill:#ffd,stroke:#333,stroke-width:2px</code></pre>"},{"location":"servers/stepfunctions-tool-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/stepfunctions-tool-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.stepfunctions-tool-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.stepfunctions-tool-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"STATE_MACHINE_PREFIX\": \"your-state-machine-prefix\",\n        \"STATE_MACHINE_LIST\": \"your-first-state-machine, your-second-state-machine\",\n        \"STATE_MACHINE_TAG_KEY\": \"your-tag-key\",\n        \"STATE_MACHINE_TAG_VALUE\": \"your-tag-value\",\n        \"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY\": \"your-state-machine-tag-for-input-schema\"\n      }\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/stepfunctions-tool-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.stepfunctions-tool-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env\",\n          \"STATE_MACHINE_PREFIX=your-state-machine-prefix\",\n          \"--env\",\n          \"STATE_MACHINE_LIST=your-first-state-machine,your-second-state-machine\",\n          \"--env\",\n          \"STATE_MACHINE_TAG_KEY=your-tag-key\",\n          \"--env\",\n          \"STATE_MACHINE_TAG_VALUE=your-tag-value\",\n          \"--env\",\n          \"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY=your-state-machine-tag-for-input-schema\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/stepfunctions-tool-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p> <p>The <code>AWS_PROFILE</code> and the <code>AWS_REGION</code> are optional, their default values are <code>default</code> and <code>us-east-1</code>.</p> <p>You can specify <code>STATE_MACHINE_PREFIX</code>, <code>STATE_MACHINE_LIST</code>, or both. If both are empty, all state machines pass the name check. After the name check, if both <code>STATE_MACHINE_TAG_KEY</code> and <code>STATE_MACHINE_TAG_VALUE</code> are set, state machines are further filtered by tag (with key=value). If only one of <code>STATE_MACHINE_TAG_KEY</code> and <code>STATE_MACHINE_TAG_VALUE</code>, then no state machine is selected and a warning is displayed.</p>"},{"location":"servers/stepfunctions-tool-mcp-server/#tool-documentation","title":"Tool Documentation","text":"<p>The MCP server builds comprehensive tool documentation by combining multiple sources of information to help AI models understand and use state machines effectively.</p> <ol> <li> <p>State Machine Description: The state machine's description field provides the base tool description. For example:    <pre><code>Retrieve customer status on the CRM system based on { 'customerId' } or { 'customerEmail' }\n</code></pre></p> </li> <li> <p>Workflow Description: The Comment field from the state machine definition adds workflow context. For example:    <pre><code>{\n  \"Comment\": \"This workflow first looks up a customer ID from email, then retrieves their info\",\n  \"StartAt\": \"GetCustomerId\",\n  \"States\": { ... }\n}\n</code></pre></p> </li> <li> <p>Input Schema: The server integrates with EventBridge Schema Registry to provide formal JSON Schema documentation for state machine inputs. To enable schema support:</p> </li> <li>Create your schema in EventBridge Schema Registry</li> <li>Tag your state machine with the schema ARN:      <pre><code>Key: STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY (configurable)\nValue: arn:aws:schemas:region:account:schema/registry-name/schema-name\n</code></pre></li> <li>Configure the MCP server:      <pre><code>{\n  \"env\": {\n    \"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY\": \"your-schema-arn-tag-key\"\n  }\n}\n</code></pre></li> </ol> <p>The server combines these sources into a unified documentation format: <pre><code>[State Machine Description]\n\nWorkflow Description: [Comment from state machine definition]\n\nInput Schema:\n[JSON Schema from EventBridge Schema Registry]\n</code></pre></p> <p>This comprehensive documentation helps AI models understand both the purpose and technical requirements of each state machine, with formal schema support ensuring correct input formatting.</p>"},{"location":"servers/stepfunctions-tool-mcp-server/#best-practices","title":"Best practices","text":"<ul> <li>Use the <code>STATE_MACHINE_LIST</code> to specify the state machines that are available as MCP tools.</li> <li>Use the <code>STATE_MACHINE_PREFIX</code> to specify the prefix of the state machines that are available as MCP tools.</li> <li>Use the <code>STATE_MACHINE_TAG_KEY</code> and <code>STATE_MACHINE_TAG_VALUE</code> to specify the tag key and value of the state machines that are available as MCP tools.</li> <li>AWS Step Functions <code>Description</code> property: the description of the state machine is used as MCP tool description, so it should be very detailed to help the model understand when and how to use the state machine</li> <li>Add workflow documentation using the <code>Comment</code> field in state machine definitions:</li> <li>Describe the workflow's purpose and steps</li> <li>Explain any important logic or conditions</li> <li>Document expected inputs and outputs</li> <li>Use EventBridge Schema Registry to provide formal input definition:</li> <li>Create JSON Schema definitions for your state machine inputs</li> <li>Tag state machines with their schema ARNs</li> <li>Configure <code>STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY</code> in the MCP server</li> </ul>"},{"location":"servers/stepfunctions-tool-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider:</p> <ul> <li>Only state machines that are in the provided list or with a name starting with the prefix are imported as MCP tools.</li> <li>The MCP server needs permissions to invoke the state machines.</li> <li>Each state machine has its own permissions to optionally access other AWS resources.</li> </ul>"},{"location":"servers/syntheticdata-mcp-server/","title":"Synthetic Data MCP Server","text":"<p>A Model Context Protocol (MCP) server for generating, validating, and managing synthetic data.</p>"},{"location":"servers/syntheticdata-mcp-server/#overview","title":"Overview","text":"<p>This MCP server provides tools for generating synthetic data based on business descriptions, executing pandas code safely, validating data structures, and loading data to storage systems like S3.</p>"},{"location":"servers/syntheticdata-mcp-server/#features","title":"Features","text":"<ul> <li>Business-Driven Generation: Generate synthetic data instructions based on business descriptions</li> <li>Data Generation Instructions: Generate structured data generation instructions from business descriptions</li> <li>Safe Pandas Code Execution: Run pandas code in a restricted environment with automatic DataFrame detection</li> <li>JSON Lines Validation: Validate and convert JSON Lines data to CSV format</li> <li>Data Validation: Validate data structure, referential integrity, and save as CSV files</li> <li>Referential Integrity Checking: Validate relationships between tables</li> <li>Data Quality Assessment: Identify potential issues in data models (3NF validation)</li> <li>Storage Integration: Load data to various storage targets (S3) with support for:</li> <li>Multiple file formats (CSV, JSON, Parquet)</li> <li>Partitioning options</li> <li>Storage class configuration</li> <li>Encryption settings</li> </ul>"},{"location":"servers/syntheticdata-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/syntheticdata-mcp-server/#installation","title":"Installation","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.syntheticdata-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.syntheticdata-mcp-server\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/syntheticdata-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre>"},{"location":"servers/syntheticdata-mcp-server/#usage","title":"Usage","text":""},{"location":"servers/syntheticdata-mcp-server/#getting-data-generation-instructions","title":"Getting Data Generation Instructions","text":"<pre><code>response = await server.get_data_gen_instructions(\n    business_description=\"An e-commerce platform with customers, orders, and products\"\n)\n</code></pre>"},{"location":"servers/syntheticdata-mcp-server/#executing-pandas-code","title":"Executing Pandas Code","text":"<pre><code>response = await server.execute_pandas_code(\n    code=\"your_pandas_code_here\",\n    workspace_dir=\"/path/to/workspace\",\n    output_dir=\"data\"\n)\n</code></pre>"},{"location":"servers/syntheticdata-mcp-server/#validating-and-saving-data","title":"Validating and Saving Data","text":"<pre><code>response = await server.validate_and_save_data(\n    data={\n        \"customers\": [{\"id\": 1, \"name\": \"John\"}],\n        \"orders\": [{\"id\": 101, \"customer_id\": 1}]\n    },\n    workspace_dir=\"/path/to/workspace\",\n    output_dir=\"data\"\n)\n</code></pre>"},{"location":"servers/syntheticdata-mcp-server/#loading-to-storage","title":"Loading to Storage","text":"<pre><code>response = await server.load_to_storage(\n    data={\n        \"customers\": [{\"id\": 1, \"name\": \"John\"}]\n    },\n    targets=[{\n        \"type\": \"s3\",\n        \"config\": {\n            \"bucket\": \"my-bucket\",\n            \"prefix\": \"data/\",\n            \"format\": \"parquet\"\n        }\n    }]\n)\n</code></pre>"},{"location":"servers/terraform-mcp-server/","title":"AWS Terraform MCP Server","text":"<p>MCP server for Terraform on AWS best practices, infrastructure as code patterns, and security compliance with Checkov.</p>"},{"location":"servers/terraform-mcp-server/#features","title":"Features","text":"<ul> <li>Terraform Best Practices - Get prescriptive Terraform advice for building applications on AWS</li> <li>AWS Well-Architected guidance for Terraform configurations</li> <li>Security and compliance recommendations</li> <li> <p>AWSCC provider prioritization for consistent API behavior</p> </li> <li> <p>Security-First Development Workflow - Follow a structured process for creating secure code</p> </li> <li>Step-by-step guidance for validation and security scanning</li> <li>Integration of Checkov at the right stages of development</li> <li> <p>Clear handoff points between AI assistance and developer deployment</p> </li> <li> <p>Checkov Integration - Work with Checkov for security and compliance scanning</p> </li> <li>Run security scans on Terraform code to identify vulnerabilities</li> <li>Automatically fix identified security issues when possible</li> <li> <p>Get detailed remediation guidance for compliance issues</p> </li> <li> <p>AWS Provider Documentation - Search for AWS and AWSCC provider resources</p> </li> <li>Find documentation for specific resources and attributes</li> <li>Get example snippets and implementation guidance</li> <li> <p>Compare AWS and AWSCC provider capabilities</p> </li> <li> <p>AWS-IA GenAI Modules - Access specialized modules for AI/ML workloads</p> </li> <li>Amazon Bedrock module for generative AI applications</li> <li>OpenSearch Serverless for vector search capabilities</li> <li>SageMaker endpoint deployment for ML model hosting</li> <li> <p>Serverless Streamlit application deployment for AI interfaces</p> </li> <li> <p>Terraform Registry Module Analysis - Analyze Terraform Registry modules</p> </li> <li>Search for modules by URL or identifier</li> <li>Extract input variables, output variables, and README content</li> <li>Understand module usage and configuration options</li> <li> <p>Analyze module structure and dependencies</p> </li> <li> <p>Terraform Workflow Execution - Run Terraform commands directly</p> </li> <li>Initialize, plan, validate, apply, and destroy operations</li> <li>Pass variables and specify AWS regions</li> <li> <p>Get formatted command output for analysis</p> </li> <li> <p>Terragrunt Workflow Execution - Run Terragrunt commands directly</p> </li> <li>Initialize, plan, validate, apply, run-all and destroy operations</li> <li>Pass variables and specify AWS regions</li> <li>Configure terragrunt-config and and include/exclude paths flags</li> <li>Get formatted command output for analysis</li> </ul>"},{"location":"servers/terraform-mcp-server/#tools-and-resources","title":"Tools and Resources","text":"<ul> <li>Terraform Development Workflow: Follow security-focused development process via <code>terraform://workflow_guide</code></li> <li>AWS Best Practices: Access AWS-specific guidance via <code>terraform://aws_best_practices</code></li> <li>AWS Provider Resources: Access resource listings via <code>terraform://aws_provider_resources_listing</code></li> <li>AWSCC Provider Resources: Access resource listings via <code>terraform://awscc_provider_resources_listing</code></li> </ul>"},{"location":"servers/terraform-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install Terraform CLI for workflow execution</li> <li>Install Checkov for security scanning</li> </ol>"},{"location":"servers/terraform-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.terraform-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.terraform-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/terraform-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.terraform-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/terraform-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/terraform-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider: - Following the structured development workflow that integrates validation and security scanning - Reviewing all Checkov warnings and errors manually - Fixing security issues rather than ignoring them whenever possible - Documenting clear justifications for any necessary exceptions - Using the RunCheckovScan tool regularly to verify security compliance - Preferring the AWSCC provider for its consistent API behavior and better security defaults</p> <p>Before applying Terraform changes to production environments, you should conduct your own independent assessment to ensure that your infrastructure would comply with your own specific security and quality control practices and standards, as well as the local laws, rules, and regulations that govern you and your content.</p>"},{"location":"servers/timestream-for-influxdb-mcp-server/","title":"AWS Labs Timestream for InfluxDB MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Timestream for InfluxDB. This server provides tools to interact with AWS Timestream for InfluxDB APIs, allowing you to create and manage database instances, clusters, parameter groups, and more. It also includes tools to interact with InfluxDB's write and query APIs.</p>"},{"location":"servers/timestream-for-influxdb-mcp-server/#features","title":"Features","text":"<ul> <li>Create, update, list, describe, and delete Timestream for InfluxDB database instances</li> <li>Create, update, list, describe, and delete Timestream for InfluxDB database clusters</li> <li>Manage DB parameter groups</li> <li>Tag management for Timestream for InfluxDB resources</li> <li>Write and query data using InfluxDB's APIs</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#pre-requisites","title":"Pre-requisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services<ul> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Consider starting with Read-only permission if you don't want the LLM to modify any resources</li> </ul> </li> </ol>"},{"location":"servers/timestream-for-influxdb-mcp-server/#installation","title":"Installation","text":"<p>You can modify the settings of your MCP client to run your local server (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>)</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.timestream-for-influxdb-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.timestream-for-influxdb-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/timestream-for-influxdb-mcp-server/#available-tools","title":"Available Tools","text":"<p>The Timestream for InfluxDB MCP server provides the following tools:</p>"},{"location":"servers/timestream-for-influxdb-mcp-server/#aws-timestream-for-influxdb-management","title":"AWS Timestream for InfluxDB Management","text":""},{"location":"servers/timestream-for-influxdb-mcp-server/#database-cluster-management","title":"Database Cluster Management","text":"<ul> <li><code>CreateDbCluster</code>: Create a new Timestream for InfluxDB database cluster</li> <li><code>GetDbCluster</code>: Retrieve information about a specific DB cluster</li> <li><code>DeleteDbCluster</code>: Delete a Timestream for InfluxDB database cluster</li> <li><code>ListDbClusters</code>: List all Timestream for InfluxDB database clusters</li> <li><code>UpdateDbCluster</code>: Update a Timestream for InfluxDB database cluster</li> <li><code>ListDbClusters</code>: List all Timestream for InfluxDB database clusters</li> <li><code>ListDbInstancesForCluster</code>: List DB instances belonging to a specific cluster</li> <li><code>ListClustersByStatus</code>: List DB clusters filtered by status</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#database-instance-management","title":"Database Instance Management","text":"<ul> <li><code>CreateDbInstance</code>: Create a new Timestream for InfluxDB database instance</li> <li><code>GetDbInstance</code>: Retrieve information about a specific DB instance</li> <li><code>DeleteDbInstance</code>: Delete a Timestream for InfluxDB database instance</li> <li><code>ListDbInstances</code>: List all Timestream for InfluxDB database instances</li> <li><code>UpdateDbInstance</code>: Update a Timestream for InfluxDB database instance</li> <li><code>ListDbInstancesByStatus</code>: List DB instances filtered by status</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#parameter-group-management","title":"Parameter Group Management","text":"<ul> <li><code>CreateDbParamGroup</code>: Create a new DB parameter group</li> <li><code>GetDbParameterGroup</code>: Retrieve information about a specific DB parameter group</li> <li><code>ListDbParamGroups</code>: List all DB parameter groups</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#tag-management","title":"Tag Management","text":"<ul> <li><code>ListTagsForResource</code>: List all tags on a Timestream for InfluxDB resource</li> <li><code>TagResource</code>: Add tags to a Timestream for InfluxDB resource</li> <li><code>UntagResource</code>: Remove tags from a Timestream for InfluxDB resource</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#influxdb-data-operations","title":"InfluxDB Data Operations","text":""},{"location":"servers/timestream-for-influxdb-mcp-server/#write-api","title":"Write API","text":"<ul> <li><code>InfluxDBWritePoints</code>: Write data points to InfluxDB</li> <li><code>InfluxDBWriteLP</code>: Write data in Line Protocol format to InfluxDB</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#query-api","title":"Query API","text":"<ul> <li><code>InfluxDBQuery</code>: Query data from InfluxDB using Flux query language</li> </ul>"},{"location":"servers/valkey-mcp-server/","title":"Amazon ElastiCache/MemoryDB Valkey MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Amazon ElastiCache Valkey datastores.</p>"},{"location":"servers/valkey-mcp-server/#features","title":"Features","text":"<p>This MCP server provides tools to operate on Valkey data types. For example, it allows an agent to operate with Valkey Strings using commands such as SET, SETRANGE, GET, GETRANGE, APPEND, INCREMENT and more.</p>"},{"location":"servers/valkey-mcp-server/#supported-data-types","title":"Supported Data Types","text":"<ul> <li><code>Strings</code>- Store, retrieve, append, increment, decrement, length and more.</li> <li><code>Lists</code>- Manage List collections with push/pop operations.</li> <li><code>Sets and Sorted Sets</code>- Store and retrieve items from Sets.</li> <li><code>Hashes</code>- Store and retrieve items in Hashes. Check for existence of items in a hash, increment item values in a Hash, and more.</li> <li><code>Streams</code>- Store, retrieve, trim items in Streams.</li> <li><code>Bitmaps</code>- Bitmaps let you perform bitwise operations on strings.</li> <li><code>JSONs</code>- Store and retrieve JSON documents with path-based access.</li> <li><code>HyperLogLog</code>- Store and count items in HyperLogs.</li> </ul>"},{"location":"servers/valkey-mcp-server/#advanced-features","title":"Advanced Features","text":"<ul> <li>Cluster Support: Support for standalone and clustered Valkey deployments.</li> <li>SSL/TLS Security: Configure secure connections using SSL/TLS.</li> <li>Connection Pooling: Pools connections by default to enable efficient connection management.</li> <li>Readonly Mode: Prevent write operations to ensure data safety.</li> </ul>"},{"location":"servers/valkey-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Access to a Valkey datastore.</li> <li>For instructions to connect to an Amazon ElastiCache/MemoryDB Valkey datastore click here.</li> </ol>"},{"location":"servers/valkey-mcp-server/#installation","title":"Installation","text":"<p>Here are some ways you can work with MCP across AWS tools (e.g., for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.valkey-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.valkey-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"VALKEY_HOST\": \"127.0.0.1\",\n        \"VALKEY_PORT\": \"6379\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>To run in readonly mode:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.valkey-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.valkey-mcp-server@latest\",\n        \"--readonly\"\n      ],\n      \"env\": {\n        \"VALKEY_HOST\": \"127.0.0.1\",\n        \"VALKEY_PORT\": \"6379\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>Or using Docker after a successful <code>docker build -t awslabs/valkey-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.valkey-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"VALKEY_HOST=127.0.0.1\",\n        \"--env\",\n        \"VALKEY_PORT=6379\",\n        \"awslabs/valkey-mcp-server:latest\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>To run in readonly mode with Docker:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.valkey-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"VALKEY_HOST=127.0.0.1\",\n        \"--env\",\n        \"VALKEY_PORT=6379\",\n        \"awslabs/valkey-mcp-server:latest\",\n        \"--readonly\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/valkey-mcp-server/#configuration","title":"Configuration","text":"<p>The server can be configured using the following environment variables:</p> Name Description Default Value <code>VALKEY_HOST</code> ElastiCache Primary Endpoint or MemoryDB Cluster Endpoint or Valkey IP or hostname <code>\"127.0.0.1\"</code> <code>VALKEY_PORT</code> Valkey port <code>6379</code> <code>VALKEY_USERNAME</code> Default database username <code>None</code> <code>VALKEY_PWD</code> Default database password <code>\"\"</code> <code>VALKEY_USE_SSL</code> Enables or disables SSL/TLS <code>False</code> <code>VALKEY_CA_PATH</code> CA certificate for verifying server <code>None</code> <code>VALKEY_SSL_KEYFILE</code> Client's private key file <code>None</code> <code>VALKEY_SSL_CERTFILE</code> Client's certificate file <code>None</code> <code>VALKEY_CERT_REQS</code> Server certificate verification <code>\"required\"</code> <code>VALKEY_CA_CERTS</code> Path to trusted CA certificates <code>None</code> <code>VALKEY_CLUSTER_MODE</code> Enable Valkey Cluster mode <code>False</code>"},{"location":"servers/valkey-mcp-server/#example-usage","title":"Example Usage","text":"<p>Here are some example natural language queries that the server can handle:</p> <pre><code>\"Store user profile data in a hash\"\n\"Add this event to the activity stream\"\n\"Cache API response for 5 minutes\"\n\"Store JSON document with nested fields\"\n\"Add score 100 to user123 in leaderboard\"\n\"Get all members of the admins set\"\n</code></pre>"},{"location":"servers/valkey-mcp-server/#development","title":"Development","text":""},{"location":"servers/valkey-mcp-server/#running-tests","title":"Running Tests","text":"<pre><code>uv venv\nsource .venv/bin/activate\nuv sync\nuv run --frozen pytest\n</code></pre>"},{"location":"servers/valkey-mcp-server/#building-docker-image","title":"Building Docker Image","text":"<pre><code>docker build -t awslabs/valkey-mcp-server .\n</code></pre>"},{"location":"servers/valkey-mcp-server/#running-docker-container","title":"Running Docker Container","text":"<pre><code>docker run -p 8080:8080 \\\n  -e VALKEY_HOST=host.docker.internal \\\n  -e VALKEY_PORT=6379 \\\n  awslabs/valkey-mcp-server\n</code></pre> <p>To run in readonly mode: <pre><code>docker run -p 8080:8080 \\\n  -e VALKEY_HOST=host.docker.internal \\\n  -e VALKEY_PORT=6379 \\\n  awslabs/valkey-mcp-server --readonly\n</code></pre></p>"}]}